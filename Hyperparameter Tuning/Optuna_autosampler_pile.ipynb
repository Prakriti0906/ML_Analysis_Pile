{"cells":[{"cell_type":"markdown","metadata":{"id":"cOxzuH_kOfSF"},"source":["# **Start**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23752,"status":"ok","timestamp":1750415657764,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"d5vKr6J_3p22","outputId":"e5a720c2-b077-4ad7-8b14-1672e361efda"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":251445,"status":"ok","timestamp":1750415909199,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"t1jgcsTHOkrm","outputId":"5fd48357-372f-49a0-f6cc-9c336afdbb63"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found existing installation: scikit-learn 1.6.1\n","Uninstalling scikit-learn-1.6.1:\n","  Successfully uninstalled scikit-learn-1.6.1\n","Collecting scikit-learn==1.5.2\n","  Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.5.2) (3.6.0)\n","Downloading scikit_learn-1.5.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m98.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","Successfully installed scikit-learn-1.5.2\n","Collecting bayesian-optimization\n","  Downloading bayesian_optimization-3.0.0-py3-none-any.whl.metadata (10 kB)\n","Collecting colorama<1.0.0,>=0.4.6 (from bayesian-optimization)\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (2.0.2)\n","Requirement already satisfied: scikit-learn<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.5.2)\n","Requirement already satisfied: scipy<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from bayesian-optimization) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0.0,>=1.0.0->bayesian-optimization) (3.6.0)\n","Downloading bayesian_optimization-3.0.0-py3-none-any.whl (36 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama, bayesian-optimization\n","Successfully installed bayesian-optimization-3.0.0 colorama-0.4.6\n","Collecting optuna\n","  Downloading optuna-4.4.0-py3-none-any.whl.metadata (17 kB)\n","Collecting alembic>=1.5.0 (from optuna)\n","  Downloading alembic-1.16.2-py3-none-any.whl.metadata (7.3 kB)\n","Collecting colorlog (from optuna)\n","  Downloading colorlog-6.9.0-py3-none-any.whl.metadata (10 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna) (4.14.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna) (3.2.3)\n","Downloading optuna-4.4.0-py3-none-any.whl (395 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.9/395.9 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading alembic-1.16.2-py3-none-any.whl (242 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.7/242.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading colorlog-6.9.0-py3-none-any.whl (11 kB)\n","Installing collected packages: colorlog, alembic, optuna\n","Successfully installed alembic-1.16.2 colorlog-6.9.0 optuna-4.4.0\n","Collecting gpboost\n","  Downloading gpboost-1.5.8-py3-none-manylinux1_x86_64.whl.metadata (7.9 kB)\n","Requirement already satisfied: wheel in /usr/local/lib/python3.11/dist-packages (from gpboost) (0.45.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from gpboost) (2.0.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from gpboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gpboost) (1.15.3)\n","Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.11/dist-packages (from gpboost) (1.5.2)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from gpboost) (4.4.0)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->gpboost) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn!=0.22.0->gpboost) (3.6.0)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (1.16.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (6.9.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->gpboost) (6.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->gpboost) (2025.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->gpboost) (1.1.3)\n","Requirement already satisfied: typing-extensions>=4.12 in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->gpboost) (4.14.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->gpboost) (1.17.0)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->gpboost) (3.2.3)\n","Downloading gpboost-1.5.8-py3-none-manylinux1_x86_64.whl (5.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: gpboost\n","Successfully installed gpboost-1.5.8\n","Requirement already satisfied: shap in /usr/local/lib/python3.11/dist-packages (0.48.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from shap) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from shap) (1.15.3)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from shap) (1.5.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from shap) (2.2.2)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap) (4.67.1)\n","Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.11/dist-packages (from shap) (24.2)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap) (3.1.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from shap) (4.14.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap) (0.43.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->shap) (2025.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->shap) (3.6.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->shap) (1.17.0)\n","Collecting ngboost\n","  Downloading ngboost-0.5.6-py3-none-any.whl.metadata (4.0 kB)\n","Collecting lifelines>=0.25 (from ngboost)\n","  Downloading lifelines-0.30.0-py3-none-any.whl.metadata (3.2 kB)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (2.0.2)\n","Collecting scikit-learn<2.0,>=1.6 (from ngboost)\n","  Downloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n","Requirement already satisfied: scipy>=1.7.2 in /usr/local/lib/python3.11/dist-packages (from ngboost) (1.15.3)\n","Requirement already satisfied: tqdm>=4.3 in /usr/local/lib/python3.11/dist-packages (from ngboost) (4.67.1)\n","Requirement already satisfied: pandas>=2.1 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (2.2.2)\n","Requirement already satisfied: matplotlib>=3.0 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (3.10.0)\n","Requirement already satisfied: autograd>=1.5 in /usr/local/lib/python3.11/dist-packages (from lifelines>=0.25->ngboost) (1.8.0)\n","Collecting autograd-gamma>=0.3 (from lifelines>=0.25->ngboost)\n","  Downloading autograd-gamma-0.5.0.tar.gz (4.0 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting formulaic>=0.2.2 (from lifelines>=0.25->ngboost)\n","  Downloading formulaic-1.1.1-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.6->ngboost) (3.6.0)\n","Collecting interface-meta>=1.2.0 (from formulaic>=0.2.2->lifelines>=0.25->ngboost)\n","  Downloading interface_meta-1.3.0-py3-none-any.whl.metadata (6.7 kB)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (4.14.0)\n","Requirement already satisfied: wrapt>=1.0 in /usr/local/lib/python3.11/dist-packages (from formulaic>=0.2.2->lifelines>=0.25->ngboost) (1.17.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0->lifelines>=0.25->ngboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.1->lifelines>=0.25->ngboost) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0->lifelines>=0.25->ngboost) (1.17.0)\n","Downloading ngboost-0.5.6-py3-none-any.whl (35 kB)\n","Downloading lifelines-0.30.0-py3-none-any.whl (349 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m349.3/349.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading scikit_learn-1.7.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading formulaic-1.1.1-py3-none-any.whl (115 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.7/115.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading interface_meta-1.3.0-py3-none-any.whl (14 kB)\n","Building wheels for collected packages: autograd-gamma\n","  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for autograd-gamma: filename=autograd_gamma-0.5.0-py3-none-any.whl size=4030 sha256=f79c8a25905bb65530c95747828f76c67391553fbe5a4187a301e2af3f631937\n","  Stored in directory: /root/.cache/pip/wheels/8b/67/f4/2caaae2146198dcb824f31a303833b07b14a5ec863fb3acd7b\n","Successfully built autograd-gamma\n","Installing collected packages: interface-meta, scikit-learn, autograd-gamma, formulaic, lifelines, ngboost\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.5.2\n","    Uninstalling scikit-learn-1.5.2:\n","      Successfully uninstalled scikit-learn-1.5.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sklearn-compat 0.1.3 requires scikit-learn<1.7,>=1.2, but you have scikit-learn 1.7.0 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed autograd-gamma-0.5.0 formulaic-1.1.1 interface-meta-1.3.0 lifelines-0.30.0 ngboost-0.5.6 scikit-learn-1.7.0\n","Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.11/dist-packages (2024.12.1)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.2.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (3.1.1)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2025.3.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (24.2)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (6.0.2)\n","Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (0.12.1)\n","Requirement already satisfied: importlib_metadata>=4.13.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (8.7.0)\n","Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (2.2.2)\n","Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.11/dist-packages (from dask[dataframe]) (1.1.21)\n","Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.11/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (18.1.0)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib_metadata>=4.13.0->dask[dataframe]) (3.23.0)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0->dask[dataframe]) (2025.2)\n","Requirement already satisfied: locket in /usr/local/lib/python3.11/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.0.2)\n","Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n","Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n","Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m97.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n","Requirement already satisfied: lightgbm in /usr/local/lib/python3.11/dist-packages (4.5.0)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lightgbm) (1.15.3)\n","Requirement already satisfied: xgboost in /usr/local/lib/python3.11/dist-packages (2.1.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.0.2)\n","Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.11/dist-packages (from xgboost) (2.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from xgboost) (1.15.3)\n","Collecting lime\n","  Downloading lime-0.2.0.1.tar.gz (275 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from lime) (3.10.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from lime) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from lime) (1.15.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from lime) (4.67.1)\n","Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.11/dist-packages (from lime) (1.7.0)\n","Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.11/dist-packages (from lime) (0.25.2)\n","Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (3.5)\n","Requirement already satisfied: pillow>=10.1 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (11.2.1)\n","Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2.37.0)\n","Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (2025.6.11)\n","Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (24.2)\n","Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.11/dist-packages (from scikit-image>=0.12->lime) (0.4)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18->lime) (3.6.0)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (1.4.8)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->lime) (2.9.0.post0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.17.0)\n","Building wheels for collected packages: lime\n","  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283834 sha256=d141d3ca507b549093f53a39e53f707c2a4604c394691f3b7375711281b296f5\n","  Stored in directory: /root/.cache/pip/wheels/85/fa/a3/9c2d44c9f3cd77cf4e533b58900b2bf4487f2a17e8ec212a3d\n","Successfully built lime\n","Installing collected packages: lime\n","Successfully installed lime-0.2.0.1\n","Collecting interpret\n","  Downloading interpret-0.6.12-py3-none-any.whl.metadata (1.2 kB)\n","Collecting interpret-core==0.6.12 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading interpret_core-0.6.12-py3-none-any.whl.metadata (3.0 kB)\n","Requirement already satisfied: numpy>=1.25 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.0.2)\n","Requirement already satisfied: pandas>=0.19.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.2.2)\n","Requirement already satisfied: scikit-learn>=0.18.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.7.0)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.11/dist-packages (from interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.5.1)\n","Requirement already satisfied: psutil>=5.6.2 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (5.9.5)\n","Requirement already satisfied: ipykernel>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (6.17.1)\n","Requirement already satisfied: ipython>=5.5.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (7.34.0)\n","Requirement already satisfied: plotly>=3.8.1 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (5.24.1)\n","Collecting SALib>=1.3.3 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading salib-1.5.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: shap>=0.28.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.48.0)\n","Requirement already satisfied: dill>=0.2.5 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.3.7)\n","Collecting aplr>=10.6.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading aplr-10.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\n","Collecting dash<3.0.0,>=2.0.0 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading dash-2.18.2-py3-none-any.whl.metadata (10 kB)\n","Collecting dash-cytoscape>=0.1.1 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading dash_cytoscape-1.0.2.tar.gz (4.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting gevent>=1.3.6 (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading gevent-25.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (13 kB)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.32.3)\n","Collecting Flask<3.1,>=1.0.4 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading flask-3.0.3-py3-none-any.whl.metadata (3.2 kB)\n","Collecting Werkzeug<3.1 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n","Collecting dash-html-components==2.0.0 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading dash_html_components-2.0.0-py3-none-any.whl.metadata (3.8 kB)\n","Collecting dash-core-components==2.0.0 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading dash_core_components-2.0.0-py3-none-any.whl.metadata (2.9 kB)\n","Collecting dash-table==5.0.0 (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading dash_table-5.0.0-py3-none-any.whl.metadata (2.4 kB)\n","Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (8.7.0)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (4.14.0)\n","Collecting retrying (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading retrying-1.3.4-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.6.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (75.2.0)\n","Requirement already satisfied: greenlet>=3.2.2 in /usr/local/lib/python3.11/dist-packages (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.2.3)\n","Collecting zope.event (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading zope.event-5.0-py3-none-any.whl.metadata (4.4 kB)\n","Collecting zope.interface (from gevent>=1.3.6->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.8.0)\n","Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (6.1.12)\n","Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.1.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (24.2)\n","Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (24.0.1)\n","Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (6.4.2)\n","Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (5.7.1)\n","Collecting jedi>=0.16 (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret)\n","  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n","Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (4.4.2)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.7.5)\n","Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.0.51)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.19.1)\n","Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.2.0)\n","Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (4.9.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.19.2->interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2025.2)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly>=3.8.1->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (9.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2025.6.15)\n","Requirement already satisfied: matplotlib>=3.5 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.10.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.70.15)\n","Requirement already satisfied: scipy>=1.9.3 in /usr/local/lib/python3.11/dist-packages (from SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.15.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.18.1->interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.6.0)\n","Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (4.67.1)\n","Requirement already satisfied: slicer==0.0.8 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.0.8)\n","Requirement already satisfied: numba>=0.54 in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.60.0)\n","Requirement already satisfied: cloudpickle in /usr/local/lib/python3.11/dist-packages (from shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.1.1)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.1.6)\n","Requirement already satisfied: itsdangerous>=2.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (8.2.1)\n","Requirement already satisfied: blinker>=1.6.2 in /usr/local/lib/python3.11/dist-packages (from Flask<3.1,>=1.0.4->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.9.0)\n","Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.8.4)\n","Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (5.8.1)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.4.8)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.5->SALib>=1.3.3->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.2.3)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.54->shap>=0.28.5->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.43.0)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.7.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=5.5.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (0.2.13)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.19.2->interpret-core==0.6.12->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (1.17.0)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from Werkzeug<3.1->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.0.2)\n","Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata->dash<3.0.0,>=2.0.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (3.23.0)\n","Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel>=4.10.0->interpret-core[aplr,dash,debug,linear,notebook,plotly,sensitivity,shap]==0.6.12->interpret) (4.3.8)\n","Downloading interpret-0.6.12-py3-none-any.whl (1.4 kB)\n","Downloading interpret_core-0.6.12-py3-none-any.whl (16.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/16.5 MB\u001b[0m \u001b[31m66.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading aplr-10.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash-2.18.2-py3-none-any.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dash_core_components-2.0.0-py3-none-any.whl (3.8 kB)\n","Downloading dash_html_components-2.0.0-py3-none-any.whl (4.1 kB)\n","Downloading dash_table-5.0.0-py3-none-any.whl (3.9 kB)\n","Downloading gevent-25.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading salib-1.5.1-py3-none-any.whl (778 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.9/778.9 kB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading flask-3.0.3-py3-none-any.whl (101 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.0/228.0 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Downloading zope.event-5.0-py3-none-any.whl (6.8 kB)\n","Downloading zope.interface-7.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (259 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m259.8/259.8 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hBuilding wheels for collected packages: dash-cytoscape\n","  Building wheel for dash-cytoscape (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for dash-cytoscape: filename=dash_cytoscape-1.0.2-py3-none-any.whl size=4010717 sha256=5beb79b9df3743825b3e808977564289164da6de845026141a83086fdb6294ef\n","  Stored in directory: /root/.cache/pip/wheels/99/b1/ab/6c999ab288b4849d372e23c0a8f6ece7edb7ffeb8c97959ab0\n","Successfully built dash-cytoscape\n","Installing collected packages: dash-table, dash-html-components, dash-core-components, zope.interface, zope.event, Werkzeug, retrying, jedi, aplr, gevent, Flask, SALib, interpret-core, dash, dash-cytoscape, interpret\n","  Attempting uninstall: Werkzeug\n","    Found existing installation: Werkzeug 3.1.3\n","    Uninstalling Werkzeug-3.1.3:\n","      Successfully uninstalled Werkzeug-3.1.3\n","  Attempting uninstall: Flask\n","    Found existing installation: Flask 3.1.1\n","    Uninstalling Flask-3.1.1:\n","      Successfully uninstalled Flask-3.1.1\n","Successfully installed Flask-3.0.3 SALib-1.5.1 Werkzeug-3.0.6 aplr-10.9.0 dash-2.18.2 dash-core-components-2.0.0 dash-cytoscape-1.0.2 dash-html-components-2.0.0 dash-table-5.0.0 gevent-25.5.1 interpret-0.6.12 interpret-core-0.6.12 jedi-0.19.2 retrying-1.3.4 zope.event-5.0 zope.interface-7.2\n","Collecting optunahub\n","  Downloading optunahub-0.3.0-py3-none-any.whl.metadata (6.9 kB)\n","Requirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from optunahub) (4.4.0)\n","Requirement already satisfied: GitPython in /usr/local/lib/python3.11/dist-packages (from optunahub) (3.1.44)\n","Collecting PyGithub>=1.59 (from optunahub)\n","  Downloading PyGithub-2.6.1-py3-none-any.whl.metadata (3.9 kB)\n","Collecting pynacl>=1.4.0 (from PyGithub>=1.59->optunahub)\n","  Downloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl.metadata (8.6 kB)\n","Requirement already satisfied: requests>=2.14.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (2.32.3)\n","Requirement already satisfied: pyjwt>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub>=1.59->optunahub) (2.10.1)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (4.14.0)\n","Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from PyGithub>=1.59->optunahub) (2.4.0)\n","Collecting Deprecated (from PyGithub>=1.59->optunahub)\n","  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from GitPython->optunahub) (4.0.12)\n","Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (1.16.2)\n","Requirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (6.9.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (24.2)\n","Requirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (2.0.41)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (4.67.1)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.11/dist-packages (from optuna->optunahub) (6.0.2)\n","Requirement already satisfied: Mako in /usr/lib/python3/dist-packages (from alembic>=1.5.0->optuna->optunahub) (1.1.3)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->GitPython->optunahub) (5.0.2)\n","Requirement already satisfied: cryptography>=3.4.0 in /usr/local/lib/python3.11/dist-packages (from pyjwt[crypto]>=2.4.0->PyGithub>=1.59->optunahub) (43.0.3)\n","Requirement already satisfied: cffi>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from pynacl>=1.4.0->PyGithub>=1.59->optunahub) (1.17.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (3.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.14.0->PyGithub>=1.59->optunahub) (2025.6.15)\n","Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->optunahub) (3.2.3)\n","Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.11/dist-packages (from Deprecated->PyGithub>=1.59->optunahub) (1.17.2)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.4.1->pynacl>=1.4.0->PyGithub>=1.59->optunahub) (2.22)\n","Downloading optunahub-0.3.0-py3-none-any.whl (12 kB)\n","Downloading PyGithub-2.6.1-py3-none-any.whl (410 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.5/410.5 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading PyNaCl-1.5.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (856 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m856.7/856.7 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n","Installing collected packages: Deprecated, pynacl, PyGithub, optunahub\n","Successfully installed Deprecated-1.2.18 PyGithub-2.6.1 optunahub-0.3.0 pynacl-1.5.0\n","Collecting cmaes\n","  Downloading cmaes-0.11.1-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from cmaes) (2.0.2)\n","Downloading cmaes-0.11.1-py3-none-any.whl (35 kB)\n","Installing collected packages: cmaes\n","Successfully installed cmaes-0.11.1\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (5.24.1)\n","Collecting kaleido\n","  Downloading kaleido-1.0.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly) (9.1.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from plotly) (24.2)\n","Collecting choreographer>=1.0.5 (from kaleido)\n","  Downloading choreographer-1.0.9-py3-none-any.whl.metadata (5.6 kB)\n","Collecting logistro>=1.0.8 (from kaleido)\n","  Downloading logistro-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.11/dist-packages (from kaleido) (3.10.18)\n","Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.11/dist-packages (from choreographer>=1.0.5->kaleido) (3.20.1)\n","Downloading kaleido-1.0.0-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading choreographer-1.0.9-py3-none-any.whl (51 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/51.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading logistro-1.1.0-py3-none-any.whl (7.9 kB)\n","Installing collected packages: logistro, choreographer, kaleido\n","Successfully installed choreographer-1.0.9 kaleido-1.0.0 logistro-1.1.0\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["site"]},"id":"9ee0456622504919afd6957c6aad9e7b"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n","Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n","Requirement already satisfied: kaleido in /usr/local/lib/python3.11/dist-packages (1.0.0)\n","Requirement already satisfied: choreographer>=1.0.5 in /usr/local/lib/python3.11/dist-packages (from kaleido) (1.0.9)\n","Requirement already satisfied: logistro>=1.0.8 in /usr/local/lib/python3.11/dist-packages (from kaleido) (1.1.0)\n","Requirement already satisfied: orjson>=3.10.15 in /usr/local/lib/python3.11/dist-packages (from kaleido) (3.10.18)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from kaleido) (24.2)\n","Requirement already satisfied: simplejson>=3.19.3 in /usr/local/lib/python3.11/dist-packages (from choreographer>=1.0.5->kaleido) (3.20.1)\n","Collecting properscoring\n","  Downloading properscoring-0.1-py2.py3-none-any.whl.metadata (6.2 kB)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from properscoring) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from properscoring) (1.15.3)\n","Downloading properscoring-0.1-py2.py3-none-any.whl (23 kB)\n","Installing collected packages: properscoring\n","Successfully installed properscoring-0.1\n","Collecting XlsxWriter\n","  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n","Downloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: XlsxWriter\n","Successfully installed XlsxWriter-3.2.5\n","Requirement already satisfied: cython in /usr/local/lib/python3.11/dist-packages (3.0.12)\n","Collecting pgbm\n","  Downloading pgbm-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.4 kB)\n","Requirement already satisfied: scikit-learn>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from pgbm) (1.7.0)\n","Collecting ninja>=1.10.2.2 (from pgbm)\n","  Downloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.0 kB)\n","Requirement already satisfied: numba>=0.56 in /usr/local/lib/python3.11/dist-packages (from pgbm) (0.60.0)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.56->pgbm) (0.43.0)\n","Requirement already satisfied: numpy<2.1,>=1.22 in /usr/local/lib/python3.11/dist-packages (from numba>=0.56->pgbm) (2.0.2)\n","Requirement already satisfied: scipy>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.2.0->pgbm) (3.6.0)\n","Downloading pgbm-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ninja-1.11.1.4-py3-none-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (422 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m422.8/422.8 kB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ninja, pgbm\n","Successfully installed ninja-1.11.1.4 pgbm-2.3.0\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Collecting cp\n","  Downloading cp-2020.12.3.tar.gz (1.4 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Building wheels for collected packages: cp\n","  Building wheel for cp (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for cp: filename=cp-2020.12.3-py3-none-any.whl size=1420 sha256=911b6e557e6151a27a36aed2184139dbc525d75ebe6645ddf30cfeaf7cd4bcd9\n","  Stored in directory: /root/.cache/pip/wheels/58/67/10/9ba963c5b021c764015a1463b9bb89a408fc37bbcde7436aa7\n","Successfully built cp\n","Installing collected packages: cp\n","Successfully installed cp-2020.12.3\n","Collecting mapie\n","  Downloading mapie-1.0.1-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: scikit-learn>=1.4 in /usr/local/lib/python3.11/dist-packages (from mapie) (1.7.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from mapie) (1.15.3)\n","Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from mapie) (2.0.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4->mapie) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.4->mapie) (3.6.0)\n","Downloading mapie-1.0.1-py3-none-any.whl (173 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: mapie\n","Successfully installed mapie-1.0.1\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n","Collecting skorch\n","  Downloading skorch-1.1.0-py3-none-any.whl.metadata (11 kB)\n","Collecting puncc\n","  Downloading puncc-0.8.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from skorch) (2.0.2)\n","Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.7.0)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (1.15.3)\n","Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.11/dist-packages (from skorch) (0.9.0)\n","Requirement already satisfied: tqdm>=4.14.0 in /usr/local/lib/python3.11/dist-packages (from skorch) (4.67.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from puncc) (1.5.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from puncc) (3.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from puncc) (2.2.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (3.2.3)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->puncc) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->puncc) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->puncc) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->puncc) (1.17.0)\n","Downloading skorch-1.1.0-py3-none-any.whl (228 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading puncc-0.8.0-py3-none-any.whl (70 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.8/70.8 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: skorch, puncc\n","Successfully installed puncc-0.8.0 skorch-1.1.0\n","Found existing installation: scikit-learn 1.7.0\n","Uninstalling scikit-learn-1.7.0:\n","  Successfully uninstalled scikit-learn-1.7.0\n","Collecting scikit-learn==1.6.1\n","  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.15.3)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (1.5.1)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.6.1) (3.6.0)\n","Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","Successfully installed scikit-learn-1.6.1\n","Collecting numpy==1.26.4\n","  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m87.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: numpy\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 2.0.2\n","    Uninstalling numpy-2.0.2:\n","      Successfully uninstalled numpy-2.0.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed numpy-1.26.4\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy"]},"id":"863b600fdfea4eaea0cf95bd19dd5363"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Collecting catboost\n","  Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.11/dist-packages (from catboost) (0.21)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from catboost) (3.10.0)\n","Requirement already satisfied: numpy<3.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from catboost) (1.26.4)\n","Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.11/dist-packages (from catboost) (2.2.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from catboost) (1.15.3)\n","Requirement already satisfied: plotly in /usr/local/lib/python3.11/dist-packages (from catboost) (5.24.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from catboost) (1.17.0)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24->catboost) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (4.58.4)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (24.2)\n","Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (11.2.1)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->catboost) (3.2.3)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from plotly->catboost) (9.1.2)\n","Downloading catboost-1.2.8-cp311-cp311-manylinux2014_x86_64.whl (99.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: catboost\n","Successfully installed catboost-1.2.8\n"]}],"source":["# Uninstall existing scikit-learn to avoid conflicts\n","!pip uninstall -y scikit-learn\n","# Install specific versions of libraries to avoid conflicts\n","!pip install scikit-learn==1.5.2\n","!pip install bayesian-optimization\n","!pip install optuna\n","!pip install gpboost\n","!pip install shap\n","!pip install ngboost\n","!pip install dask[dataframe]\n","!pip install torch seaborn\n","!pip install lightgbm\n","!pip install xgboost\n","!pip install lime\n","!pip install interpret\n","!pip install optunahub\n","!pip install cmaes\n","!pip install plotly kaleido\n","!pip install openpyxl\n","!pip install -U kaleido\n","!pip install properscoring\n","!pip install XlsxWriter\n","!pip install cython\n","!pip install pgbm\n","!pip install torch\n","!pip install cp\n","!pip install mapie\n","!pip install torch skorch puncc\n","# Reinstall scikit-learn to the version required by ngboost\n","!pip uninstall -y scikit-learn\n","!pip install scikit-learn==1.6.1\n","# Reinstall numpy first\n","!pip install numpy==1.26.4  # Use the version compatible with catboost\n","# Reinstall catboost\n","!pip install catboost"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5QL-bkHqPwKM"},"outputs":[],"source":["# Restart the runtime to apply changes\n","import os\n","os._exit(00)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":59357,"status":"ok","timestamp":1750416219157,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"0kBPL1V9O2sA","colab":{"base_uri":"https://localhost:8080/"},"outputId":"67bce8b9-9ad5-4b03-b401-c1573466cfe3"},"outputs":[{"output_type":"stream","name":"stderr","text":["No CUDA runtime is found, using CUDA_HOME='/usr/local/cuda'\n","Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n","Creating extension directory /root/.cache/torch_extensions/py311_cu124/split_decision...\n","Emitting ninja build file /root/.cache/torch_extensions/py311_cu124/split_decision/build.ninja...\n","Building extension module split_decision...\n","Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n","Loading extension module split_decision...\n","Using /root/.cache/torch_extensions/py311_cu124 as PyTorch extensions root...\n","No modifications detected for re-loaded extension module split_decision, skipping build step...\n","Loading extension module split_decision...\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import ngboost\n","from scipy.stats import randint\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n","from sklearn.base import BaseEstimator, RegressorMixin\n","from sklearn.svm import SVR\n","from xgboost import XGBRegressor\n","from lightgbm import LGBMRegressor\n","from catboost import CatBoostRegressor\n","from gpboost import GPBoostRegressor\n","from ngboost import NGBRegressor\n","import optuna\n","import optunahub\n","from sklearn.experimental import enable_halving_search_cv\n","from sklearn.model_selection import HalvingGridSearchCV\n","from interpret import show\n","from interpret.blackbox import LimeTabular, ShapKernel\n","from optuna.samplers import RandomSampler\n","import random\n","import time\n","from ngboost.distns import Normal\n","from ngboost.scores import LogScore\n","from scipy.stats import norm\n","from interpret import set_visualize_provider\n","from interpret.provider import InlineProvider\n","from interpret.glassbox import ExplainableBoostingRegressor\n","from interpret import show\n","import plotly.express as px\n","from io import BytesIO\n","from openpyxl import Workbook, load_workbook\n","import os\n","from openpyxl.drawing.image import Image as openpyxlImage\n","import warnings\n","import xlsxwriter\n","from openpyxl.drawing.image import Image\n","from pgbm.sklearn import HistGradientBoostingRegressor\n","import torch\n","from pgbm.torch import PGBM\n","import plotly.graph_objects as go\n","warnings.filterwarnings('ignore')\n","import pickle\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3627,"status":"ok","timestamp":1750416222786,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"D_rzxWyr3pKj","outputId":"60719b26-8037-4596-baa9-748d711f0f41"},"outputs":[{"output_type":"stream","name":"stdout","text":["Training data loaded successfully.\n","Test data loaded successfully.\n"]}],"source":["train_data_path = \"./drive/MyDrive/pile_capacity_LOK/full/train.csv\"\n","test_data_path = \"./drive/MyDrive/pile_capacity_LOK/full/test.csv\"\n","train_data = pd.read_csv(train_data_path)\n","test_data = pd.read_csv(test_data_path)\n","print(\"Training data loaded successfully.\")\n","print(\"Test data loaded successfully.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1750416222813,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"sjMvmRLkPB0x","outputId":"344c24a3-69c2-4176-80b7-bf2060fb53d9"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Shape of training data: (81, 8)\n","First 5 rows of training data:\n","      F1    F2   Zv1   Zv2  phi     Th   L  Total\n","0  4.80  1.21  4.90 -1.87  0.5  0.125  32   5.55\n","1  4.34  1.09  4.36 -1.95  0.5  0.125  45   6.07\n","2  4.71  0.81  5.10 -1.49  0.5  0.125  42   6.06\n","3  5.55  1.04  5.30 -1.46  0.5  0.125  38   5.94\n","4  3.08  0.95  2.82 -1.60  0.4  0.097  36   3.88\n","\n","Shape of test data: (24, 8)\n","First 5 rows of test data:\n","      F1    F2   Zv1   Zv2  phi     Th   L  Total\n","0  4.69  1.06  4.70 -1.82  0.5  0.125  42   6.12\n","1  3.52  0.64  3.55 -1.03  0.4  0.097  45   4.26\n","2  3.70  0.49  3.43 -1.13  0.5  0.100  44   4.78\n","3  4.17  1.45  4.44 -0.21  0.5  0.125  16   5.78\n","4  4.33  2.04  4.75 -1.66  0.5  0.125  32   5.84\n"]}],"source":["print(\"\\nShape of training data:\", train_data.shape)\n","print(\"First 5 rows of training data:\\n\", train_data.head(5))\n","print(\"\\nShape of test data:\", test_data.shape)\n","print(\"First 5 rows of test data:\\n\", test_data.head(5))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":53,"status":"ok","timestamp":1750416222876,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"1YOqfRGLPLjK","outputId":"d136a871-c138-4dd9-e4ea-70006d894cec"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Shape of X_train: (81, 7)\n","Shape of y_train: (81,)\n","Shape of X_test: (24, 7)\n","Shape of y_test: (24,)\n"]}],"source":["X_train = train_data.iloc[:, :-1]\n","y_train = train_data.iloc[:, -1]\n","X_test = test_data.iloc[:, :-1]\n","y_test = test_data.iloc[:, -1]\n","x_test= X_test\n","print(\"\\nShape of X_train:\", X_train.shape)\n","print(\"Shape of y_train:\", y_train.shape)\n","print(\"Shape of X_test:\", X_test.shape)\n","print(\"Shape of y_test:\", y_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25,"status":"ok","timestamp":1750416222903,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"},"user_tz":-330},"id":"8Uw5ISznPMaa","outputId":"ef50fa03-9859-4bd1-9441-a9e3ec243ef7"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","First five rows of normalized X_train:\n","[[ 0.006145   -0.12114279  0.17814132 -0.04043083 -0.57071458  0.40496686\n","  -0.73776147]\n"," [-0.37545934 -0.27898568 -0.27593219 -0.10402107 -0.57071458  0.40496686\n","   0.23089542]\n"," [-0.06851672 -0.64728574  0.3463167   0.2616228  -0.57071458  0.40496686\n","   0.00735922]\n"," [ 0.62832598 -0.34475355  0.51449207  0.28546914 -0.57071458  0.40496686\n","  -0.29068906]\n"," [-1.42072338 -0.46313571 -1.57088258  0.17418622 -2.53785844 -2.27277321\n","  -0.4397132 ]]\n","\n","First five rows of normalized X_test:\n","[[-8.51082130e-02 -3.18446397e-01  9.96594816e-03 -6.86931582e-04\n","  -5.70714577e-01  4.04966863e-01  7.35921670e-03]\n"," [-1.05571054e+00 -8.70896496e-01 -9.57042459e-01  6.27266667e-01\n","  -2.53785844e+00 -2.27277321e+00  2.30895424e-01]\n"," [-9.06387106e-01 -1.06820010e+00 -1.05794768e+00  5.47778870e-01\n","  -5.70714577e-01 -1.98587249e+00  1.56383355e-01]\n"," [-5.16487026e-01  1.94542980e-01 -2.08662040e-01  1.27906661e+00\n","  -5.70714577e-01  4.04966863e-01 -1.92995458e+00]\n"," [-3.83755083e-01  9.70603833e-01  5.20097920e-02  1.26493544e-01\n","  -5.70714577e-01  4.04966863e-01 -7.37761474e-01]]\n"]}],"source":["# Apply z-score normalization\n","scaler = StandardScaler()\n","X_train = scaler.fit_transform(X_train)\n","X_test = scaler.transform(X_test)\n","\n","# Print the first five rows of the normalized data\n","print(\"\\nFirst five rows of normalized X_train:\")\n","print(X_train[:5])\n","\n","print(\"\\nFirst five rows of normalized X_test:\")\n","print(X_test[:5])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PHT6BWytPScM"},"outputs":[],"source":["# Define the model classes\n","model_classes = {\n","    'Random Forest': RandomForestRegressor,\n","    'Gradient Boosting': GradientBoostingRegressor,\n","    'XGBoost': XGBRegressor,\n","    'LightGBM': LGBMRegressor,\n","    'GPBoost': GPBoostRegressor,\n","    'CatBoost': CatBoostRegressor,\n","    'NGBoost': NGBRegressor\n","}\n","\n","feature_names = ['F1', 'F2', 'Zv1', 'Zv2', 'phi', 'th', 'L']\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iM8V0dbeWGr2"},"outputs":[],"source":["def plot_best_scores(best_scores_ran, excel_file_path):\n","    # Extract the best pruner for each model based on RMSE and correlation coefficient\n","    best_rmse_scores = {}\n","    best_corr_coef_scores = {}\n","\n","    for (model_name, pruner_name), scores in best_scores_ran.items():\n","        # Initialize if not already present\n","        if model_name not in best_rmse_scores:\n","            best_rmse_scores[model_name] = (scores['test_rmse'], pruner_name)\n","        if model_name not in best_corr_coef_scores:\n","            best_corr_coef_scores[model_name] = (scores['test_corr_coef'], pruner_name)\n","\n","        # Update if better scores are found\n","        if scores['test_rmse'] < best_rmse_scores[model_name][0]:\n","            best_rmse_scores[model_name] = (scores['test_rmse'], pruner_name)\n","        if scores['test_corr_coef'] > best_corr_coef_scores[model_name][0]:\n","            best_corr_coef_scores[model_name] = (scores['test_corr_coef'], pruner_name)\n","\n","    # Prepare data for plotting\n","    model_names_rmse = [f\"{model} ({pruner})\" for model, (rmse, pruner) in best_rmse_scores.items()]\n","    rmse_values = [rmse for rmse, _ in best_rmse_scores.values()]\n","\n","    model_names_corr = [f\"{model} ({pruner})\" for model, (corr, pruner) in best_corr_coef_scores.items()]\n","    corr_values = [corr for corr, _ in best_corr_coef_scores.values()]\n","\n","    # Plot RMSE\n","    plt.figure(figsize=(12, 6))\n","    bars_rmse = plt.bar(model_names_rmse, rmse_values, color='skyblue')\n","\n","    # Highlight the best model\n","    best_rmse_index = np.argmin(rmse_values)\n","    bars_rmse[best_rmse_index].set_color('orange')\n","\n","    # Annotate the bars with the RMSE scores\n","    for i, bar in enumerate(bars_rmse):\n","        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05,\n","                 f'{rmse_values[i]:.5f}', ha='center', va='bottom', color='black')\n","\n","    # Add labels and title for the RMSE bar chart\n","    plt.xlabel('Model (Pruner)')\n","    plt.ylabel('Test RMSE')\n","    plt.title('Best Test RMSE for Each Model')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    rmse_image_path = 'rmse_plot.png'\n","    plt.savefig(rmse_image_path)\n","    plt.close()\n","\n","    # Plot Correlation Coefficient\n","    plt.figure(figsize=(12, 6))\n","    bars_corr = plt.bar(model_names_corr, corr_values, color='lightgreen')\n","\n","    # Highlight the best model\n","    best_corr_index = np.argmax(corr_values)\n","    bars_corr[best_corr_index].set_color('orange')\n","\n","    # Annotate the bars with the correlation coefficient scores\n","    for i, bar in enumerate(bars_corr):\n","        plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height() - 0.05,\n","                 f'{corr_values[i]:.5f}', ha='center', va='bottom', color='black')\n","\n","    # Add labels and title for the correlation coefficient bar chart\n","    plt.xlabel('Model (Pruner)')\n","    plt.ylabel('Correlation Coefficient')\n","    plt.title('Best Correlation Coefficient for Each Model')\n","    plt.xticks(rotation=45, ha='right')\n","    plt.tight_layout()\n","    corr_image_path = 'corr_plot.png'\n","    plt.savefig(corr_image_path)\n","    plt.close()\n","\n","    # Load the existing Excel file\n","    workbook = load_workbook(excel_file_path)\n","\n","    # Create a new sheet for the plots\n","    sheet_name = 'Best Models Plots'\n","    if sheet_name in workbook.sheetnames:\n","        sheet = workbook[sheet_name]\n","    else:\n","        sheet = workbook.create_sheet(title=sheet_name)\n","\n","    # Insert images into the new Excel sheet\n","    img_rmse = Image(rmse_image_path)\n","    img_corr = Image(corr_image_path)\n","\n","    # Insert images\n","    sheet.add_image(img_rmse, 'A1')\n","    sheet.add_image(img_corr, 'A20')  # Adjust the position as needed\n","\n","    # Save the workbook\n","    workbook.save(excel_file_path)\n","\n","    # Clean up the image files\n","    os.remove(rmse_image_path)\n","    os.remove(corr_image_path)\n","\n","# Example usage\n","# plot_best_scores(best_scores_ran, 'path_to_your_excel_file.xlsx')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v9rnFhjC3pKl"},"outputs":[],"source":["def generate_interpretml_explanations_summary_pruners(\n","    results_dict, X_train, y_train, X_test, feature_names, instance_indices=None, excel_file_path=None\n","):\n","    if instance_indices is None:\n","        instance_indices = range(len(X_test))\n","    elif isinstance(instance_indices, int):\n","        instance_indices = [instance_indices]\n","\n","    valid_indices = [idx for idx in instance_indices if 0 <= idx < len(X_test)]\n","    if not valid_indices:\n","        print(\"No valid instance indices provided.\")\n","        return\n","\n","    if isinstance(X_test, pd.DataFrame):\n","        instances_to_explain = X_test.iloc[valid_indices]\n","    else:\n","        instances_to_explain = X_test[valid_indices]\n","\n","    best_model_pruners = {}\n","    for model_key, model_info in results_dict.items():\n","        if isinstance(model_key, tuple):\n","            model_name, pruner_name = model_key\n","        else:\n","            model_name = model_key\n","            pruner_name = None\n","\n","        best_score = model_info.get('best_score')\n","        if best_score is None:\n","            print(f\"No 'best_score' found for {model_key}. Skipping this combination.\")\n","            continue\n","\n","        if model_name not in best_model_pruners:\n","            best_model_pruners[model_name] = {\n","                'pruner_name': pruner_name,\n","                'model_info': model_info,\n","                'best_score': best_score\n","            }\n","        else:\n","            current_best_score = best_model_pruners[model_name]['best_score']\n","            if best_score < current_best_score:\n","                best_model_pruners[model_name] = {\n","                    'pruner_name': pruner_name,\n","                    'model_info': model_info,\n","                    'best_score': best_score\n","                }\n","\n","    for model_name, info in best_model_pruners.items():\n","        pruner_name = info['pruner_name']\n","        model_info = info['model_info']\n","        best_params = model_info['best_params']\n","        model_class = model_classes.get(model_name)\n","\n","        if model_class is None:\n","            print(f\"Model {model_name} is not supported or not available.\")\n","            continue\n","\n","        if model_name == 'CatBoost':\n","            best_params['verbose'] = 0\n","\n","        model = model_class(**best_params)\n","        model.fit(X_train, y_train)\n","\n","        def predict_fn(data):\n","            return model.predict(data)\n","\n","        if isinstance(X_train, pd.DataFrame):\n","            data_for_explainer = X_train.values\n","        else:\n","            data_for_explainer = X_train\n","\n","        if isinstance(instances_to_explain, pd.DataFrame):\n","            data_for_explanation = instances_to_explain.values\n","        else:\n","            data_for_explanation = instances_to_explain\n","\n","        # Generate LIME explanations\n","        lime_explainer = LimeTabular(\n","            predict_fn,\n","            data=data_for_explainer,\n","            feature_names=feature_names,\n","            random_state=1,\n","            mode='regression'\n","        )\n","        lime_explanation = lime_explainer.explain_local(data_for_explanation)\n","\n","        feature_importances_lime = {}\n","        num_instances = len(valid_indices)\n","\n","        for idx in range(num_instances):\n","            explanation = lime_explanation.data(idx)\n","            for feature_name, feature_score in zip(explanation['names'], explanation['scores']):\n","                feature_importances_lime[feature_name] = feature_importances_lime.get(feature_name, 0) + abs(feature_score)\n","\n","        feature_importances_lime = {k: v / num_instances for k, v in feature_importances_lime.items()}\n","        feature_importances_lime = {k: round(v, 3) for k, v in feature_importances_lime.items()}\n","\n","        # Generate SHAP explanations using ShapKernel\n","        try:\n","            shap_explainer = ShapKernel(predict_fn, data_for_explainer, feature_names=feature_names)\n","            shap_explanation = shap_explainer.explain_local(data_for_explanation)\n","\n","            feature_importances_shap = {}\n","            for idx in range(num_instances):\n","                explanation = shap_explanation.data(idx)\n","                for feature_name, feature_score in zip(explanation['names'], explanation['scores']):\n","                    feature_importances_shap[feature_name] = feature_importances_shap.get(feature_name, 0) + abs(feature_score)\n","\n","            feature_importances_shap = {k: v / num_instances for k, v in feature_importances_shap.items()}\n","            feature_importances_shap = {k: round(v, 3) for k, v in feature_importances_shap.items()}\n","        except Exception as e:\n","            print(f\"Could not compute SHAP values for model {model_name}: {e}\")\n","            continue\n","\n","        # Plot LIME and SHAP feature importances side by side\n","        fig, axes = plt.subplots(1, 2, figsize=(34, 36))\n","\n","        # Plot LIME feature importances\n","        lime_importances_df = pd.DataFrame.from_dict(\n","            feature_importances_lime, orient='index', columns=['importance']\n","        )\n","        lime_importances_df.sort_values(by='importance', ascending=False, inplace=True)\n","        lime_importances_df.plot(kind='bar', legend=False, color='skyblue', ax=axes[0])\n","        axes[0].set_title(f\"LIME Feature Importances for {model_name}\")\n","        axes[0].set_ylabel(\"Average Absolute Importance Score\")\n","        axes[0].set_xlabel(\"Features\")\n","        axes[0].tick_params(axis='x', rotation=45)\n","\n","        for p in axes[0].patches:\n","            height = p.get_height()\n","            axes[0].annotate(f'{height:.3f}',\n","                             (p.get_x() + p.get_width() / 2., height),\n","                             ha='center', va='bottom', fontsize=8)\n","\n","        # Plot SHAP feature importances\n","        shap_importances_df = pd.DataFrame.from_dict(\n","            feature_importances_shap, orient='index', columns=['importance']\n","        )\n","        shap_importances_df.sort_values(by='importance', ascending=False, inplace=True)\n","        shap_importances_df.plot(kind='bar', legend=False, color='orange', ax=axes[1])\n","        axes[1].set_title(f\"SHAP Feature Importances for {model_name}\")\n","        axes[1].set_ylabel(\"Average Absolute SHAP Value\")\n","        axes[1].set_xlabel(\"Features\")\n","        axes[1].tick_params(axis='x', rotation=45)\n","\n","        for p in axes[1].patches:\n","            height = p.get_height()\n","            axes[1].annotate(f'{height:.3f}',\n","                             (p.get_x() + p.get_width() / 2., height),\n","                             ha='center', va='bottom', fontsize=8)\n","\n","        plt.tight_layout()\n","\n","        # Save plots as images\n","        image_path = f'feature_importances_{model_name}.png'\n","        fig.savefig(image_path)\n","        plt.close(fig)\n","\n","        # Optionally insert images and scores into an Excel file\n","        if excel_file_path:\n","            workbook = load_workbook(excel_file_path)\n","            sheet_name = f'{model_name} Explanations'\n","            if sheet_name in workbook.sheetnames:\n","                sheet = workbook[sheet_name]\n","            else:\n","                sheet = workbook.create_sheet(title=sheet_name)\n","\n","            # Insert images into the new Excel sheet\n","            img = Image(image_path)\n","            sheet.add_image(img, 'A1')\n","\n","            # Create a new sheet for feature importance scores\n","            scores_sheet_name = f'{model_name} Scores'\n","            if scores_sheet_name in workbook.sheetnames:\n","                scores_sheet = workbook[scores_sheet_name]\n","            else:\n","                scores_sheet = workbook.create_sheet(title=scores_sheet_name)\n","\n","            # Write LIME scores\n","            scores_sheet.append(['Feature', 'LIME Importance'])\n","            for feature, importance in feature_importances_lime.items():\n","                scores_sheet.append([feature, importance])\n","\n","            # Write SHAP scores\n","            scores_sheet.append(['Feature', 'SHAP Importance'])\n","            for feature, importance in feature_importances_shap.items():\n","                scores_sheet.append([feature, importance])\n","\n","            # Save the workbook\n","            workbook.save(excel_file_path)\n","\n","            # Clean up the image file\n","            os.remove(image_path)"]},{"cell_type":"markdown","metadata":{"id":"Z_-QSaTL3pKm"},"source":["# **Autosampler by Optuna**"]},{"cell_type":"code","source":["# Suppress Optuna's verbose output\n","optuna.logging.set_verbosity(optuna.logging.WARNING)\n","\n","# Define objective and metric functions for PGBM\n","def mseloss_objective(yhat, y, sample_weight=None):\n","    if not torch.is_tensor(yhat):\n","        yhat = torch.from_numpy(np.array(yhat)).float()\n","    if not torch.is_tensor(y):\n","        y = torch.from_numpy(np.array(y)).float()\n","    gradient = yhat - y\n","    hessian = torch.ones_like(yhat)\n","    return gradient, hessian\n","\n","def rmseloss_metric(yhat, y, sample_weight=None):\n","    if not torch.is_tensor(yhat):\n","        yhat = torch.from_numpy(np.array(yhat)).float()\n","    if not torch.is_tensor(y):\n","        y = torch.from_numpy(np.array(y)).float()\n","    loss = torch.sqrt(torch.mean((yhat - y) ** 2))\n","    return loss\n","\n","def hyperparameter_tuning_all(X_train, y_train, X_test, y_test, excel_path):\n","    X_train = np.array(X_train)\n","    y_train = np.array(y_train)\n","    X_test = np.array(X_test)\n","    y_test = np.array(y_test)\n","\n","    models = {\n","        'Random Forest': (RandomForestRegressor, {\n","            'n_estimators': [100, 200, 300, 500, 700],\n","            'criterion': ['squared_error', 'absolute_error', 'friedman_mse', 'poisson'],\n","            'max_depth': [None, 10, 20, 30, 40],\n","            'min_samples_split': [2, 5, 10, 0.01],\n","            'min_samples_leaf': [1, 3, 5, 0.01],\n","            'min_weight_fraction_leaf': [0.0, 0.01, 0.1, 0.2],\n","            'max_features': [1.0, 'sqrt', 'log2', 0.3, 0.5],\n","            'max_leaf_nodes': [None, 50, 100, 200],\n","            'min_impurity_decrease': [0.0, 0.01, 0.1, 0.2],\n","            'n_jobs': [-1],\n","            'random_state': [42],\n","            'verbose': [0],\n","            'warm_start': [False],\n","            'ccp_alpha': [0.0, 0.001, 0.01, 0.05, 0.1]\n","        }),\n","        'Gradient Boosting': (GradientBoostingRegressor, {\n","            'loss': ['squared_error', 'absolute_error', 'huber', 'quantile'],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","            'n_estimators': [100, 200, 300, 500, 700],\n","            'subsample': [1.0, 0.9, 0.7, 0.5],\n","            'criterion': ['friedman_mse', 'squared_error'],\n","            'min_samples_split': [2, 5, 10, 0.01],\n","            'min_samples_leaf': [1, 3, 5, 0.01],\n","            'min_weight_fraction_leaf': [0.0, 0.01, 0.05, 0.1],\n","            'max_depth': [3, 5, 7, 10],\n","            'min_impurity_decrease': [0.0, 0.01, 0.1],\n","            'init': [None],\n","            'random_state': [42],\n","            'max_features': [None, 'sqrt', 'log2', 0.5],\n","            'alpha': [0.9, 0.5, 0.1],\n","            'verbose': [0],\n","            'max_leaf_nodes': [None, 10, 30, 50],\n","            'warm_start': [False],\n","            'validation_fraction': [0.1],\n","            'n_iter_no_change': [None, 10, 20],\n","            'tol': [1e-4, 1e-3],\n","            'ccp_alpha': [0.0, 0.001, 0.01]\n","        }),\n","        'XGBoost': (XGBRegressor, {\n","            'n_estimators': [100, 200, 300, 400, 500],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'max_depth': [3, 5, 7],\n","            'min_child_weight': [1, 3, 5],\n","            'gamma': [0, 0.1, 0.5, 1],\n","            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9],\n","            'colsample_bytree': [0.5, 0.7, 0.9],\n","            'colsample_bylevel': [0.5, 0.7, 0.9],\n","            'reg_alpha': [0, 0.01, 0.1, 1],\n","            'reg_lambda': [0.1, 1, 5, 10],\n","            'objective': ['reg:squarederror'],\n","            'random_state': [42],\n","            'n_jobs': [-1]\n","        }),\n","        'LightGBM': (LGBMRegressor, {\n","            'n_estimators': [100, 200, 300, 400, 500],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'num_leaves': [15, 31, 63],\n","            'max_depth': [3, 5, 7, -1],\n","            'min_child_samples': [1, 5, 10, 20],\n","            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n","            'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n","            'reg_alpha': [0, 0.01, 0.1, 1],\n","            'reg_lambda': [0, 0.1, 1, 10],\n","            'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1],\n","            'bagging_freq': [0, 1, 5],\n","            'objective': ['regression'],\n","            'random_state': [42],\n","            'n_jobs': [-1],\n","            'verbose': [-1]\n","        }),\n","        'GPBoost': (GPBoostRegressor, {\n","            'n_estimators': [100, 200, 300, 400, 500],\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'max_depth': [3, 5, 7, -1],\n","            'num_leaves': [15, 31, 63],\n","            'min_child_samples': [1, 5, 10, 20],\n","            'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n","            'colsample_bytree': [0.5, 0.7, 0.9, 1.0],\n","            'reg_alpha': [0, 0.1, 0.5, 1.0],\n","            'reg_lambda': [0, 0.1, 0.5, 1.0],\n","            'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1],\n","            'random_state': [42],\n","            'n_jobs': [-1],\n","            'verbose': [-1]\n","        }),\n","        'CatBoost': (CatBoostRegressor, {\n","            'iterations': [200, 500, 1000],\n","            'learning_rate': [0.01, 0.03, 0.05, 0.1],\n","            'depth': [4, 6, 8, 10],\n","            'l2_leaf_reg': [1, 3, 5, 7, 9],\n","            'border_count': [32, 64, 128],\n","            'min_data_in_leaf': [1, 5, 10, 20],\n","            'rsm': [0.6, 0.8, 1.0],\n","            'bagging_temperature': [0, 1, 10],\n","            'random_seed': [42],\n","            'verbose': [0]\n","        }),\n","        'NGBoost': (NGBRegressor, {\n","            'n_estimators': [200, 500, 1000],\n","            'learning_rate': [0.01, 0.03, 0.05, 0.1],\n","            'natural_gradient': [True, False],\n","            'minibatch_frac': [0.5, 0.7, 0.9, 1.0],\n","            'col_sample': [0.5, 0.7, 0.9, 1.0],\n","            'Dist': [Normal],\n","            'Score': [LogScore],\n","            'random_state': [42],\n","            'verbose': [0]\n","        }),\n","        'HistGradientBoosting': (HistGradientBoostingRegressor, {\n","            'learning_rate': [0.01, 0.05, 0.1, 0.15],\n","            'max_iter': [100, 200, 300, 400, 500],\n","            'max_depth': [3, 5, 7, None],\n","            'min_samples_leaf': [5, 10, 20],\n","            'max_leaf_nodes': [15, 31, 63, None],\n","            'l2_regularization': [0.0, 0.1, 0.5, 1.0],\n","            'max_bins': [64, 128, 255],\n","            'early_stopping': [True, False],\n","            'validation_fraction': [0.1, 0.2],\n","            'n_iter_no_change': [5, 10, 15],\n","            'loss': ['squared_error'],\n","            'random_state': [42],\n","            'verbose': [0]\n","        }),\n","        'PGBM': (PGBM, {}) # PGBM is handled separately\n","    }\n","\n","\n","    pruners = [\n","        optuna.pruners.MedianPruner(),\n","        optuna.pruners.NopPruner(),\n","        optuna.pruners.PatientPruner(optuna.pruners.MedianPruner(), patience=3),\n","        optuna.pruners.PercentilePruner(25.0),\n","        optuna.pruners.SuccessiveHalvingPruner(),\n","        optuna.pruners.HyperbandPruner(),\n","        optuna.pruners.ThresholdPruner(lower=0.1),\n","        optuna.pruners.WilcoxonPruner()\n","    ]\n","\n","    best_scores = {}\n","    predictions_df = pd.DataFrame({'Actual': y_test})\n","\n","    for model_name, (model_class, param_space) in models.items():\n","        for pruner in pruners:\n","            pruner_name = pruner.__class__.__name__\n","            print(f\"Running Optuna for {model_name} with {pruner_name}...\")\n","            try:\n","                sampler = optunahub.load_module(\"samplers/auto_sampler\").AutoSampler()\n","                study = optuna.create_study(direction='minimize', sampler=sampler, pruner=pruner)\n","\n","                if model_name == 'PGBM':\n","                    def pgbm_objective(trial):\n","                        params = {\n","                            'n_estimators': trial.suggest_categorical('n_estimators', [100, 200, 300, 500]),\n","                            'learning_rate': trial.suggest_categorical('learning_rate', [0.01, 0.05, 0.1, 0.15]),\n","                            'max_leaves': trial.suggest_int('max_leaves', 15, 63),\n","                            'min_split_gain': trial.suggest_categorical('min_split_gain', [0.0, 0.1, 0.5, 1.0]),\n","                            'reg_lambda': trial.suggest_categorical('reg_lambda', [0.1, 1.0, 5.0, 10.0]),\n","                            'feature_fraction': trial.suggest_categorical('feature_fraction', [0.5, 0.7, 0.9, 1.0]),\n","                            'bagging_fraction': trial.suggest_categorical('bagging_fraction', [0.5, 0.7, 0.9, 1.0]),\n","                            'tree_correlation': trial.suggest_categorical('tree_correlation', [0.0, 0.1, 0.2, 0.3]),\n","                            'min_data_in_leaf': trial.suggest_categorical('min_data_in_leaf', [3, 5, 10, 20]),\n","                            'max_bin': trial.suggest_categorical('max_bin', [64, 128, 256]),\n","                            'distribution': trial.suggest_categorical('distribution', ['normal', 'studentt', 'laplace']),\n","                            'objective': 'mse',\n","                            'metric': 'rmse',\n","                            'random_state': 42,\n","                            'verbose': 0\n","                        }\n","\n","                        model = PGBM()\n","                        model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=params)\n","                        y_pred = model.predict(X_test)\n","                        mse = mean_squared_error(y_test, y_pred)\n","                        return mse\n","\n","                    study.optimize(pgbm_objective, n_trials=50)\n","                else:\n","                    def objective(trial, model_name, model_class, param_space):\n","                        params = {}\n","                        for key, values in param_space.items():\n","                            if isinstance(values, list):\n","                                params[key] = trial.suggest_categorical(key, values)\n","                            elif isinstance(values, tuple):\n","                                if len(values) == 2:\n","                                    params[key] = trial.suggest_float(key, values[0], values[1])\n","                                elif len(values) == 3 and isinstance(values[2], bool) and values[2]:\n","                                    params[key] = trial.suggest_int(key, values[0], values[1])\n","                                else:\n","                                    raise ValueError(f\"Invalid parameter range for {key}\")\n","\n","                        model = model_class(**params)\n","                        model.fit(X_train, y_train)\n","                        y_pred = model.predict(X_test)\n","                        mse = mean_squared_error(y_test, y_pred)\n","                        return mse\n","\n","                    study.optimize(lambda trial: objective(trial, model_name, model_class, param_space), n_trials=50)\n","\n","                best_params = study.best_params\n","                best_model = model_class(**best_params) if model_name != 'PGBM' else PGBM()\n","                if model_name == 'PGBM':\n","                    best_model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=best_params)\n","                else:\n","                    best_model.fit(X_train, y_train)\n","                y_pred = best_model.predict(X_test)\n","\n","                mse = mean_squared_error(y_test, y_pred)\n","                rmse = np.sqrt(mse)\n","                corr_coef = np.corrcoef(y_test, y_pred)[0, 1]\n","\n","                # Save predictions to DataFrame\n","                predictions_df[f'{model_name}_{pruner_name}_Predicted'] = y_pred\n","\n","                best_scores[(model_name, pruner_name)] = {\n","                    'best_score': mse,\n","                    'best_params': best_params,\n","                    'test_mse': mse,\n","                    'test_rmse': rmse,\n","                    'test_corr_coef': corr_coef,\n","                    'pruner': pruner_name\n","                }\n","                print(f\"Best MSE for {model_name} with {pruner_name}: {mse} with params: {best_params}\")\n","                print(f\"Best RMSE for {model_name} with {pruner_name}: {rmse}\")\n","                print(f\"Correlation Coefficient for {model_name} with {pruner_name}: {corr_coef}\")\n","            except Exception as e:\n","                print(f\"Failed to run Optuna for {model_name} with {pruner_name}. Error: {e}\")\n","\n","    # Write predictions to Excel\n","    with pd.ExcelWriter(excel_path, engine='openpyxl', mode='a') as writer:\n","        predictions_df.to_excel(writer, sheet_name='Predictions', index=False)\n","\n","    if best_scores:\n","        best_model_name, best_pruner_name = min(best_scores, key=lambda k: best_scores[k]['test_mse'])\n","        best_model_info = best_scores[(best_model_name, best_pruner_name)]\n","        print(f\"\\nBest model on test data: {best_model_name} with {best_pruner_name}\")\n","        print(f\"Test MSE: {best_model_info['test_mse']}\")\n","        print(f\"Test RMSE: {best_model_info['test_rmse']}\")\n","        print(f\"Correlation Coefficient: {best_model_info['test_corr_coef']}\")\n","        print(f\"Best Parameters: {best_model_info['best_params']}\")\n","        print(f\"Pruner Used: {best_model_info['pruner']}\")\n","    else:\n","        print(\"No valid model configurations found.\")\n","\n","    return best_scores\n","\n","# Example usage\n","best_scores_autosampler = hyperparameter_tuning_all(X_train, y_train, X_test, y_test, \"./drive/MyDrive/pile_capacity_LOK/full/full_ml/HyperParameter_Tuning/test.xlsx\")"],"metadata":{"id":"cuiOvohCUDm8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"7dbb43b9-a2a4-4062-861f-92c23e8902a9","executionInfo":{"status":"ok","timestamp":1750418890550,"user_tz":-330,"elapsed":2667429,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Running Optuna for Random Forest with MedianPruner...\n","Best MSE for Random Forest with MedianPruner: 0.1277468464583334 with params: {'n_estimators': 100, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.0, 'max_features': 0.3, 'max_leaf_nodes': 50, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.05}\n","Best RMSE for Random Forest with MedianPruner: 0.3574169084673155\n","Correlation Coefficient for Random Forest with MedianPruner: 0.9707276604980959\n","Running Optuna for Random Forest with NopPruner...\n","Best MSE for Random Forest with NopPruner: 0.14842459697916685 with params: {'n_estimators': 300, 'criterion': 'absolute_error', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.01}\n","Best RMSE for Random Forest with NopPruner: 0.3852591296506377\n","Correlation Coefficient for Random Forest with NopPruner: 0.9629339388824938\n","Running Optuna for Random Forest with PatientPruner...\n","Best MSE for Random Forest with PatientPruner: 0.12419639091145714 with params: {'n_estimators': 200, 'criterion': 'absolute_error', 'max_depth': None, 'min_samples_split': 0.01, 'min_samples_leaf': 0.01, 'min_weight_fraction_leaf': 0.01, 'max_features': 'log2', 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.05}\n","Best RMSE for Random Forest with PatientPruner: 0.3524150832632694\n","Correlation Coefficient for Random Forest with PatientPruner: 0.9705007038236941\n","Running Optuna for Random Forest with PercentilePruner...\n","Best MSE for Random Forest with PercentilePruner: 0.12408228778645725 with params: {'n_estimators': 200, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 0.01, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.01, 'max_features': 'sqrt', 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.0, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.05}\n","Best RMSE for Random Forest with PercentilePruner: 0.3522531586607241\n","Correlation Coefficient for Random Forest with PercentilePruner: 0.9705179528060743\n","Running Optuna for Random Forest with SuccessiveHalvingPruner...\n","Best MSE for Random Forest with SuccessiveHalvingPruner: 0.12957015505833472 with params: {'n_estimators': 500, 'criterion': 'absolute_error', 'max_depth': 40, 'min_samples_split': 10, 'min_samples_leaf': 0.01, 'min_weight_fraction_leaf': 0.0, 'max_features': 'log2', 'max_leaf_nodes': 200, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.05}\n","Best RMSE for Random Forest with SuccessiveHalvingPruner: 0.35995854630545265\n","Correlation Coefficient for Random Forest with SuccessiveHalvingPruner: 0.9695351089387991\n","Running Optuna for Random Forest with HyperbandPruner...\n","Best MSE for Random Forest with HyperbandPruner: 0.14123529690104086 with params: {'n_estimators': 200, 'criterion': 'absolute_error', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_features': 'sqrt', 'max_leaf_nodes': 50, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.01}\n","Best RMSE for Random Forest with HyperbandPruner: 0.3758128482383763\n","Correlation Coefficient for Random Forest with HyperbandPruner: 0.9650032328189053\n","Running Optuna for Random Forest with ThresholdPruner...\n","Best MSE for Random Forest with ThresholdPruner: 0.12605156197916648 with params: {'n_estimators': 100, 'criterion': 'absolute_error', 'max_depth': 20, 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.0, 'max_features': 'sqrt', 'max_leaf_nodes': 100, 'min_impurity_decrease': 0.01, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.01}\n","Best RMSE for Random Forest with ThresholdPruner: 0.3550374092672017\n","Correlation Coefficient for Random Forest with ThresholdPruner: 0.9709542703717455\n","Running Optuna for Random Forest with WilcoxonPruner...\n","Best MSE for Random Forest with WilcoxonPruner: 0.16566976091278687 with params: {'n_estimators': 100, 'criterion': 'squared_error', 'max_depth': 20, 'min_samples_split': 0.01, 'min_samples_leaf': 0.01, 'min_weight_fraction_leaf': 0.0, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'min_impurity_decrease': 0.1, 'n_jobs': -1, 'random_state': 42, 'verbose': 0, 'warm_start': False, 'ccp_alpha': 0.001}\n","Best RMSE for Random Forest with WilcoxonPruner: 0.4070255040077794\n","Correlation Coefficient for Random Forest with WilcoxonPruner: 0.9596894196995167\n","Running Optuna for Gradient Boosting with MedianPruner...\n","Best MSE for Gradient Boosting with MedianPruner: 0.1475531564605347 with params: {'loss': 'huber', 'learning_rate': 0.1, 'n_estimators': 500, 'subsample': 0.5, 'criterion': 'friedman_mse', 'min_samples_split': 0.01, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.05, 'max_depth': 7, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': None, 'alpha': 0.9, 'verbose': 0, 'max_leaf_nodes': 30, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.0001, 'ccp_alpha': 0.01}\n","Best RMSE for Gradient Boosting with MedianPruner: 0.3841264849766737\n","Correlation Coefficient for Gradient Boosting with MedianPruner: 0.9594576979885481\n","Running Optuna for Gradient Boosting with NopPruner...\n","Best MSE for Gradient Boosting with NopPruner: 0.11611736736385432 with params: {'loss': 'absolute_error', 'learning_rate': 0.05, 'n_estimators': 700, 'subsample': 0.7, 'criterion': 'squared_error', 'min_samples_split': 2, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.1, 'max_depth': 3, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 'sqrt', 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': 30, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 20, 'tol': 0.001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with NopPruner: 0.34075998498041743\n","Correlation Coefficient for Gradient Boosting with NopPruner: 0.970092988116921\n","Running Optuna for Gradient Boosting with PatientPruner...\n","Best MSE for Gradient Boosting with PatientPruner: 0.11598078071820765 with params: {'loss': 'absolute_error', 'learning_rate': 0.05, 'n_estimators': 100, 'subsample': 0.9, 'criterion': 'squared_error', 'min_samples_split': 2, 'min_samples_leaf': 1, 'min_weight_fraction_leaf': 0.1, 'max_depth': 10, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 0.5, 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': 50, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.001, 'ccp_alpha': 0.01}\n","Best RMSE for Gradient Boosting with PatientPruner: 0.340559511272564\n","Correlation Coefficient for Gradient Boosting with PatientPruner: 0.9738912032521678\n","Running Optuna for Gradient Boosting with PercentilePruner...\n","Best MSE for Gradient Boosting with PercentilePruner: 0.12843508528943917 with params: {'loss': 'quantile', 'learning_rate': 0.01, 'n_estimators': 300, 'subsample': 0.5, 'criterion': 'friedman_mse', 'min_samples_split': 0.01, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.1, 'max_depth': 5, 'min_impurity_decrease': 0.01, 'init': None, 'random_state': 42, 'max_features': None, 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': 10, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 20, 'tol': 0.0001, 'ccp_alpha': 0.01}\n","Best RMSE for Gradient Boosting with PercentilePruner: 0.3583784107468517\n","Correlation Coefficient for Gradient Boosting with PercentilePruner: 0.9760374747143572\n","Running Optuna for Gradient Boosting with SuccessiveHalvingPruner...\n","Best MSE for Gradient Boosting with SuccessiveHalvingPruner: 0.11506432498369613 with params: {'loss': 'quantile', 'learning_rate': 0.01, 'n_estimators': 700, 'subsample': 0.7, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.01, 'max_depth': 3, 'min_impurity_decrease': 0.1, 'init': None, 'random_state': 42, 'max_features': 0.5, 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': 30, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 20, 'tol': 0.0001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with SuccessiveHalvingPruner: 0.3392113279118139\n","Correlation Coefficient for Gradient Boosting with SuccessiveHalvingPruner: 0.9712848440118512\n","Running Optuna for Gradient Boosting with HyperbandPruner...\n","Best MSE for Gradient Boosting with HyperbandPruner: 0.11364424292251485 with params: {'loss': 'huber', 'learning_rate': 0.01, 'n_estimators': 500, 'subsample': 0.7, 'criterion': 'squared_error', 'min_samples_split': 2, 'min_samples_leaf': 5, 'min_weight_fraction_leaf': 0.0, 'max_depth': 10, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 0.5, 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': None, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': None, 'tol': 0.0001, 'ccp_alpha': 0.001}\n","Best RMSE for Gradient Boosting with HyperbandPruner: 0.33711161789904964\n","Correlation Coefficient for Gradient Boosting with HyperbandPruner: 0.9720469551788173\n","Running Optuna for Gradient Boosting with ThresholdPruner...\n","Best MSE for Gradient Boosting with ThresholdPruner: 0.1230870944926456 with params: {'loss': 'absolute_error', 'learning_rate': 0.1, 'n_estimators': 300, 'subsample': 0.9, 'criterion': 'friedman_mse', 'min_samples_split': 10, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.1, 'max_depth': 5, 'min_impurity_decrease': 0.0, 'init': None, 'random_state': 42, 'max_features': 'sqrt', 'alpha': 0.5, 'verbose': 0, 'max_leaf_nodes': 50, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.0001, 'ccp_alpha': 0.01}\n","Best RMSE for Gradient Boosting with ThresholdPruner: 0.35083770392112307\n","Correlation Coefficient for Gradient Boosting with ThresholdPruner: 0.9689207287958194\n","Running Optuna for Gradient Boosting with WilcoxonPruner...\n","Best MSE for Gradient Boosting with WilcoxonPruner: 0.12440493626931852 with params: {'loss': 'huber', 'learning_rate': 0.1, 'n_estimators': 200, 'subsample': 0.5, 'criterion': 'friedman_mse', 'min_samples_split': 0.01, 'min_samples_leaf': 3, 'min_weight_fraction_leaf': 0.1, 'max_depth': 10, 'min_impurity_decrease': 0.01, 'init': None, 'random_state': 42, 'max_features': 'log2', 'alpha': 0.9, 'verbose': 0, 'max_leaf_nodes': 10, 'warm_start': False, 'validation_fraction': 0.1, 'n_iter_no_change': 10, 'tol': 0.001, 'ccp_alpha': 0.0}\n","Best RMSE for Gradient Boosting with WilcoxonPruner: 0.35271083945537957\n","Correlation Coefficient for Gradient Boosting with WilcoxonPruner: 0.9690633574264977\n","Running Optuna for XGBoost with MedianPruner...\n","Best MSE for XGBoost with MedianPruner: 0.17170419710177898 with params: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 7, 'min_child_weight': 3, 'gamma': 1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 10, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with MedianPruner: 0.4143720515452013\n","Correlation Coefficient for XGBoost with MedianPruner: 0.9607256474135085\n","Running Optuna for XGBoost with NopPruner...\n","Best MSE for XGBoost with NopPruner: 0.18490542743528735 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.5, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 10, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with NopPruner: 0.430006310924953\n","Correlation Coefficient for XGBoost with NopPruner: 0.9568726100915124\n","Running Optuna for XGBoost with PatientPruner...\n","Best MSE for XGBoost with PatientPruner: 0.17995853590726996 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 1, 'subsample': 0.6, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.9, 'reg_alpha': 1, 'reg_lambda': 10, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with PatientPruner: 0.42421519999555646\n","Correlation Coefficient for XGBoost with PatientPruner: 0.956980205204565\n","Running Optuna for XGBoost with PercentilePruner...\n","Best MSE for XGBoost with PercentilePruner: 0.20558211819201722 with params: {'n_estimators': 500, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 1, 'gamma': 1, 'subsample': 0.8, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with PercentilePruner: 0.45341164320296984\n","Correlation Coefficient for XGBoost with PercentilePruner: 0.9511658209169824\n","Running Optuna for XGBoost with SuccessiveHalvingPruner...\n","Best MSE for XGBoost with SuccessiveHalvingPruner: 0.1969894230295611 with params: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 7, 'min_child_weight': 1, 'gamma': 0.1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.5, 'reg_alpha': 1, 'reg_lambda': 0.1, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with SuccessiveHalvingPruner: 0.44383490515005813\n","Correlation Coefficient for XGBoost with SuccessiveHalvingPruner: 0.9547894948664724\n","Running Optuna for XGBoost with HyperbandPruner...\n","Best MSE for XGBoost with HyperbandPruner: 0.18140968628433582 with params: {'n_estimators': 400, 'learning_rate': 0.01, 'max_depth': 5, 'min_child_weight': 3, 'gamma': 0.1, 'subsample': 0.5, 'colsample_bytree': 0.5, 'colsample_bylevel': 0.9, 'reg_alpha': 0.1, 'reg_lambda': 5, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with HyperbandPruner: 0.4259221598887945\n","Correlation Coefficient for XGBoost with HyperbandPruner: 0.9572801854066274\n","Running Optuna for XGBoost with ThresholdPruner...\n","Best MSE for XGBoost with ThresholdPruner: 0.18764774972827566 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 3, 'min_child_weight': 5, 'gamma': 1, 'subsample': 0.6, 'colsample_bytree': 0.9, 'colsample_bylevel': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 10, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with ThresholdPruner: 0.43318327498678394\n","Correlation Coefficient for XGBoost with ThresholdPruner: 0.9566386914670973\n","Running Optuna for XGBoost with WilcoxonPruner...\n","Best MSE for XGBoost with WilcoxonPruner: 0.18603178163690948 with params: {'n_estimators': 400, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'gamma': 0.5, 'subsample': 0.5, 'colsample_bytree': 0.7, 'colsample_bylevel': 0.5, 'reg_alpha': 0.01, 'reg_lambda': 5, 'objective': 'reg:squarederror', 'random_state': 42, 'n_jobs': -1}\n","Best RMSE for XGBoost with WilcoxonPruner: 0.43131401743614767\n","Correlation Coefficient for XGBoost with WilcoxonPruner: 0.9572878786872289\n","Running Optuna for LightGBM with MedianPruner...\n","Best MSE for LightGBM with MedianPruner: 0.2083364060730614 with params: {'n_estimators': 200, 'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': -1, 'min_child_samples': 10, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 0, 'min_child_weight': 0.1, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with MedianPruner: 0.4564388305929518\n","Correlation Coefficient for LightGBM with MedianPruner: 0.9498750983478396\n","Running Optuna for LightGBM with NopPruner...\n","Best MSE for LightGBM with NopPruner: 0.193068876020293 with params: {'n_estimators': 400, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 7, 'min_child_samples': 1, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 0, 'reg_lambda': 10, 'min_child_weight': 0.01, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with NopPruner: 0.4393960355081655\n","Correlation Coefficient for LightGBM with NopPruner: 0.9548082997434436\n","Running Optuna for LightGBM with PatientPruner...\n","Best MSE for LightGBM with PatientPruner: 0.1953962186539332 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'num_leaves': 15, 'max_depth': 5, 'min_child_samples': 1, 'subsample': 0.5, 'colsample_bytree': 0.9, 'reg_alpha': 1, 'reg_lambda': 10, 'min_child_weight': 1e-05, 'bagging_freq': 5, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with PatientPruner: 0.44203644493857425\n","Correlation Coefficient for LightGBM with PatientPruner: 0.9508141956595607\n","Running Optuna for LightGBM with PercentilePruner...\n","Best MSE for LightGBM with PercentilePruner: 0.2460844970001943 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 31, 'max_depth': 3, 'min_child_samples': 20, 'subsample': 0.6, 'colsample_bytree': 0.9, 'reg_alpha': 0.01, 'reg_lambda': 0.1, 'min_child_weight': 0.01, 'bagging_freq': 0, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with PercentilePruner: 0.496069044589757\n","Correlation Coefficient for LightGBM with PercentilePruner: 0.9312533658049154\n","Running Optuna for LightGBM with SuccessiveHalvingPruner...\n","Best MSE for LightGBM with SuccessiveHalvingPruner: 0.2036941580271234 with params: {'n_estimators': 400, 'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 5, 'min_child_samples': 1, 'subsample': 0.6, 'colsample_bytree': 0.5, 'reg_alpha': 0, 'reg_lambda': 10, 'min_child_weight': 0.01, 'bagging_freq': 5, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with SuccessiveHalvingPruner: 0.45132489187626623\n","Correlation Coefficient for LightGBM with SuccessiveHalvingPruner: 0.9514856189721617\n","Running Optuna for LightGBM with HyperbandPruner...\n","Best MSE for LightGBM with HyperbandPruner: 0.21148179615800702 with params: {'n_estimators': 200, 'learning_rate': 0.01, 'num_leaves': 63, 'max_depth': -1, 'min_child_samples': 10, 'subsample': 0.9, 'colsample_bytree': 0.5, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 0.01, 'bagging_freq': 5, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with HyperbandPruner: 0.4598714996148457\n","Correlation Coefficient for LightGBM with HyperbandPruner: 0.949662555232054\n","Running Optuna for LightGBM with ThresholdPruner...\n","Best MSE for LightGBM with ThresholdPruner: 0.19382677405571272 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'num_leaves': 15, 'max_depth': 7, 'min_child_samples': 1, 'subsample': 0.6, 'colsample_bytree': 0.7, 'reg_alpha': 1, 'reg_lambda': 10, 'min_child_weight': 0.1, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with ThresholdPruner: 0.44025762237093946\n","Correlation Coefficient for LightGBM with ThresholdPruner: 0.9527311939790231\n","Running Optuna for LightGBM with WilcoxonPruner...\n","Best MSE for LightGBM with WilcoxonPruner: 0.19441841092141496 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'num_leaves': 31, 'max_depth': -1, 'min_child_samples': 5, 'subsample': 0.7, 'colsample_bytree': 1.0, 'reg_alpha': 1, 'reg_lambda': 10, 'min_child_weight': 1e-05, 'bagging_freq': 1, 'objective': 'regression', 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for LightGBM with WilcoxonPruner: 0.4409290316155367\n","Correlation Coefficient for LightGBM with WilcoxonPruner: 0.9504497189384022\n","Running Optuna for GPBoost with MedianPruner...\n","Best MSE for GPBoost with MedianPruner: 0.24538762445047077 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 7, 'num_leaves': 63, 'min_child_samples': 20, 'subsample': 1.0, 'colsample_bytree': 1.0, 'reg_alpha': 0, 'reg_lambda': 0, 'min_child_weight': 0.01, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with MedianPruner: 0.495366151902278\n","Correlation Coefficient for GPBoost with MedianPruner: 0.9315384098485758\n","Running Optuna for GPBoost with NopPruner...\n","Best MSE for GPBoost with NopPruner: 0.2458047001956276 with params: {'n_estimators': 500, 'learning_rate': 0.01, 'max_depth': 3, 'num_leaves': 63, 'min_child_samples': 20, 'subsample': 0.8, 'colsample_bytree': 1.0, 'reg_alpha': 0.1, 'reg_lambda': 0, 'min_child_weight': 1e-05, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with NopPruner: 0.49578695040876947\n","Correlation Coefficient for GPBoost with NopPruner: 0.9312589640936391\n","Running Optuna for GPBoost with PatientPruner...\n","Best MSE for GPBoost with PatientPruner: 0.23924970633895856 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 7, 'num_leaves': 63, 'min_child_samples': 20, 'subsample': 0.8, 'colsample_bytree': 0.5, 'reg_alpha': 0, 'reg_lambda': 0.1, 'min_child_weight': 0.001, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with PatientPruner: 0.4891315838697789\n","Correlation Coefficient for GPBoost with PatientPruner: 0.9335047827151202\n","Running Optuna for GPBoost with PercentilePruner...\n","Best MSE for GPBoost with PercentilePruner: 0.21410524780675688 with params: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 7, 'num_leaves': 31, 'min_child_samples': 10, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.5, 'reg_lambda': 0.5, 'min_child_weight': 0.1, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with PercentilePruner: 0.46271508275261236\n","Correlation Coefficient for GPBoost with PercentilePruner: 0.9482169600842357\n","Running Optuna for GPBoost with SuccessiveHalvingPruner...\n","Best MSE for GPBoost with SuccessiveHalvingPruner: 0.21432952386392556 with params: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 5, 'num_leaves': 31, 'min_child_samples': 10, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.5, 'reg_lambda': 0, 'min_child_weight': 0.1, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with SuccessiveHalvingPruner: 0.4629573672207038\n","Correlation Coefficient for GPBoost with SuccessiveHalvingPruner: 0.9482138594080257\n","Running Optuna for GPBoost with HyperbandPruner...\n","Best MSE for GPBoost with HyperbandPruner: 0.21341642160636554 with params: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 5, 'num_leaves': 31, 'min_child_samples': 10, 'subsample': 0.7, 'colsample_bytree': 0.5, 'reg_alpha': 0.5, 'reg_lambda': 1.0, 'min_child_weight': 0.01, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with HyperbandPruner: 0.4619701522894802\n","Correlation Coefficient for GPBoost with HyperbandPruner: 0.9485463939108688\n","Running Optuna for GPBoost with ThresholdPruner...\n","Best MSE for GPBoost with ThresholdPruner: 0.25151641817016107 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_depth': 3, 'num_leaves': 15, 'min_child_samples': 20, 'subsample': 0.5, 'colsample_bytree': 0.5, 'reg_alpha': 1.0, 'reg_lambda': 0, 'min_child_weight': 1e-05, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with ThresholdPruner: 0.5015141255938471\n","Correlation Coefficient for GPBoost with ThresholdPruner: 0.929405761058553\n","Running Optuna for GPBoost with WilcoxonPruner...\n","Best MSE for GPBoost with WilcoxonPruner: 0.2318601807817072 with params: {'n_estimators': 300, 'learning_rate': 0.01, 'max_depth': 3, 'num_leaves': 15, 'min_child_samples': 10, 'subsample': 0.8, 'colsample_bytree': 0.9, 'reg_alpha': 1.0, 'reg_lambda': 0.1, 'min_child_weight': 1e-05, 'random_state': 42, 'n_jobs': -1, 'verbose': -1}\n","Best RMSE for GPBoost with WilcoxonPruner: 0.4815186193510145\n","Correlation Coefficient for GPBoost with WilcoxonPruner: 0.9428019827117433\n","Running Optuna for CatBoost with MedianPruner...\n","Best MSE for CatBoost with MedianPruner: 0.1876633039227785 with params: {'iterations': 500, 'learning_rate': 0.1, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 32, 'min_data_in_leaf': 20, 'rsm': 1.0, 'bagging_temperature': 0, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with MedianPruner: 0.4332012279793058\n","Correlation Coefficient for CatBoost with MedianPruner: 0.9505985870988952\n","Running Optuna for CatBoost with NopPruner...\n","Best MSE for CatBoost with NopPruner: 0.20786129556860278 with params: {'iterations': 500, 'learning_rate': 0.01, 'depth': 6, 'l2_leaf_reg': 5, 'border_count': 128, 'min_data_in_leaf': 20, 'rsm': 0.6, 'bagging_temperature': 10, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with NopPruner: 0.45591807988782673\n","Correlation Coefficient for CatBoost with NopPruner: 0.9431902327536595\n","Running Optuna for CatBoost with PatientPruner...\n","Best MSE for CatBoost with PatientPruner: 0.21136792731806056 with params: {'iterations': 200, 'learning_rate': 0.03, 'depth': 4, 'l2_leaf_reg': 9, 'border_count': 32, 'min_data_in_leaf': 1, 'rsm': 0.6, 'bagging_temperature': 10, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with PatientPruner: 0.4597476778821842\n","Correlation Coefficient for CatBoost with PatientPruner: 0.9442624292857775\n","Running Optuna for CatBoost with PercentilePruner...\n","Best MSE for CatBoost with PercentilePruner: 0.1876633039227785 with params: {'iterations': 500, 'learning_rate': 0.1, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 32, 'min_data_in_leaf': 20, 'rsm': 1.0, 'bagging_temperature': 0, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with PercentilePruner: 0.4332012279793058\n","Correlation Coefficient for CatBoost with PercentilePruner: 0.9505985870988952\n","Running Optuna for CatBoost with SuccessiveHalvingPruner...\n","Best MSE for CatBoost with SuccessiveHalvingPruner: 0.16955476359331176 with params: {'iterations': 200, 'learning_rate': 0.1, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 64, 'min_data_in_leaf': 20, 'rsm': 0.8, 'bagging_temperature': 0, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with SuccessiveHalvingPruner: 0.411770280123896\n","Correlation Coefficient for CatBoost with SuccessiveHalvingPruner: 0.9545229535961917\n","Running Optuna for CatBoost with HyperbandPruner...\n","Best MSE for CatBoost with HyperbandPruner: 0.18766330467457562 with params: {'iterations': 1000, 'learning_rate': 0.1, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 32, 'min_data_in_leaf': 1, 'rsm': 1.0, 'bagging_temperature': 10, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with HyperbandPruner: 0.43320122884702855\n","Correlation Coefficient for CatBoost with HyperbandPruner: 0.9505985837797406\n","Running Optuna for CatBoost with ThresholdPruner...\n","Best MSE for CatBoost with ThresholdPruner: 0.16958500552464362 with params: {'iterations': 500, 'learning_rate': 0.1, 'depth': 10, 'l2_leaf_reg': 1, 'border_count': 64, 'min_data_in_leaf': 20, 'rsm': 0.8, 'bagging_temperature': 0, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with ThresholdPruner: 0.4118070003346757\n","Correlation Coefficient for CatBoost with ThresholdPruner: 0.9545297513334484\n","Running Optuna for CatBoost with WilcoxonPruner...\n","Best MSE for CatBoost with WilcoxonPruner: 0.2185595484526247 with params: {'iterations': 200, 'learning_rate': 0.03, 'depth': 8, 'l2_leaf_reg': 3, 'border_count': 64, 'min_data_in_leaf': 20, 'rsm': 1.0, 'bagging_temperature': 10, 'random_seed': 42, 'verbose': 0}\n","Best RMSE for CatBoost with WilcoxonPruner: 0.46750352774350773\n","Correlation Coefficient for CatBoost with WilcoxonPruner: 0.9392465923252853\n","Running Optuna for NGBoost with MedianPruner...\n","Best MSE for NGBoost with MedianPruner: 0.09504486262561934 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with MedianPruner: 0.3082934683473189\n","Correlation Coefficient for NGBoost with MedianPruner: 0.9728706600673735\n","Running Optuna for NGBoost with NopPruner...\n","Best MSE for NGBoost with NopPruner: 0.13749530079773292 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with NopPruner: 0.37080358789759965\n","Correlation Coefficient for NGBoost with NopPruner: 0.9634991101104033\n","Running Optuna for NGBoost with PatientPruner...\n","Best MSE for NGBoost with PatientPruner: 0.1190552270631217 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with PatientPruner: 0.3450438045569312\n","Correlation Coefficient for NGBoost with PatientPruner: 0.9679534662898801\n","Running Optuna for NGBoost with PercentilePruner...\n","Best MSE for NGBoost with PercentilePruner: 0.10889296232715207 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with PercentilePruner: 0.3299893366870391\n","Correlation Coefficient for NGBoost with PercentilePruner: 0.9720818248033533\n","Running Optuna for NGBoost with SuccessiveHalvingPruner...\n","Best MSE for NGBoost with SuccessiveHalvingPruner: 0.10532323931129806 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with SuccessiveHalvingPruner: 0.32453542073446784\n","Correlation Coefficient for NGBoost with SuccessiveHalvingPruner: 0.9732927978429206\n","Running Optuna for NGBoost with HyperbandPruner...\n","Best MSE for NGBoost with HyperbandPruner: 0.11685799834435291 with params: {'n_estimators': 200, 'learning_rate': 0.05, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with HyperbandPruner: 0.3418449916911946\n","Correlation Coefficient for NGBoost with HyperbandPruner: 0.9747460538503312\n","Running Optuna for NGBoost with ThresholdPruner...\n","Best MSE for NGBoost with ThresholdPruner: 0.11273045675857192 with params: {'n_estimators': 1000, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with ThresholdPruner: 0.3357535655187774\n","Correlation Coefficient for NGBoost with ThresholdPruner: 0.9715119083891562\n","Running Optuna for NGBoost with WilcoxonPruner...\n","Best MSE for NGBoost with WilcoxonPruner: 0.10902047014845206 with params: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Best RMSE for NGBoost with WilcoxonPruner: 0.3301824800749611\n","Correlation Coefficient for NGBoost with WilcoxonPruner: 0.9702968236904361\n","Running Optuna for HistGradientBoosting with MedianPruner...\n","Best MSE for HistGradientBoosting with MedianPruner: 0.20339129262913583 with params: {'learning_rate': 0.01, 'max_iter': 200, 'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 63, 'l2_regularization': 0.0, 'max_bins': 128, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with MedianPruner: 0.45098923781963557\n","Correlation Coefficient for HistGradientBoosting with MedianPruner: 0.9531686203054556\n","Running Optuna for HistGradientBoosting with NopPruner...\n","Best MSE for HistGradientBoosting with NopPruner: 0.21131535430654258 with params: {'learning_rate': 0.01, 'max_iter': 200, 'max_depth': 5, 'min_samples_leaf': 10, 'max_leaf_nodes': 15, 'l2_regularization': 0.5, 'max_bins': 255, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with NopPruner: 0.45969049838618875\n","Correlation Coefficient for HistGradientBoosting with NopPruner: 0.9511371258201152\n","Running Optuna for HistGradientBoosting with PatientPruner...\n","Best MSE for HistGradientBoosting with PatientPruner: 0.22025310759770758 with params: {'learning_rate': 0.01, 'max_iter': 300, 'max_depth': 7, 'min_samples_leaf': 10, 'max_leaf_nodes': 15, 'l2_regularization': 0.1, 'max_bins': 255, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 10, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with PatientPruner: 0.46931131202828213\n","Correlation Coefficient for HistGradientBoosting with PatientPruner: 0.9525247884036877\n","Running Optuna for HistGradientBoosting with PercentilePruner...\n","Best MSE for HistGradientBoosting with PercentilePruner: 0.2052831927048833 with params: {'learning_rate': 0.01, 'max_iter': 400, 'max_depth': 3, 'min_samples_leaf': 10, 'max_leaf_nodes': 15, 'l2_regularization': 0.0, 'max_bins': 255, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with PercentilePruner: 0.4530818830022707\n","Correlation Coefficient for HistGradientBoosting with PercentilePruner: 0.9541777770389761\n","Running Optuna for HistGradientBoosting with SuccessiveHalvingPruner...\n","Best MSE for HistGradientBoosting with SuccessiveHalvingPruner: 0.20339129262913583 with params: {'learning_rate': 0.01, 'max_iter': 200, 'max_depth': 7, 'min_samples_leaf': 10, 'max_leaf_nodes': 31, 'l2_regularization': 0.0, 'max_bins': 128, 'early_stopping': True, 'validation_fraction': 0.1, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with SuccessiveHalvingPruner: 0.45098923781963557\n","Correlation Coefficient for HistGradientBoosting with SuccessiveHalvingPruner: 0.9531686203054556\n","Running Optuna for HistGradientBoosting with HyperbandPruner...\n","Best MSE for HistGradientBoosting with HyperbandPruner: 0.22459983108232093 with params: {'learning_rate': 0.1, 'max_iter': 500, 'max_depth': 7, 'min_samples_leaf': 10, 'max_leaf_nodes': None, 'l2_regularization': 0.1, 'max_bins': 255, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with HyperbandPruner: 0.4739196462295279\n","Correlation Coefficient for HistGradientBoosting with HyperbandPruner: 0.950340907988903\n","Running Optuna for HistGradientBoosting with ThresholdPruner...\n","Best MSE for HistGradientBoosting with ThresholdPruner: 0.2111932525133927 with params: {'learning_rate': 0.01, 'max_iter': 200, 'max_depth': None, 'min_samples_leaf': 10, 'max_leaf_nodes': 15, 'l2_regularization': 0.0, 'max_bins': 64, 'early_stopping': False, 'validation_fraction': 0.2, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with ThresholdPruner: 0.45955767049783064\n","Correlation Coefficient for HistGradientBoosting with ThresholdPruner: 0.9484835964617143\n","Running Optuna for HistGradientBoosting with WilcoxonPruner...\n","Best MSE for HistGradientBoosting with WilcoxonPruner: 0.20961745590758593 with params: {'learning_rate': 0.01, 'max_iter': 300, 'max_depth': 3, 'min_samples_leaf': 10, 'max_leaf_nodes': 31, 'l2_regularization': 1.0, 'max_bins': 128, 'early_stopping': True, 'validation_fraction': 0.2, 'n_iter_no_change': 5, 'loss': 'squared_error', 'random_state': 42, 'verbose': 0}\n","Best RMSE for HistGradientBoosting with WilcoxonPruner: 0.45783998941506404\n","Correlation Coefficient for HistGradientBoosting with WilcoxonPruner: 0.9531114281829953\n","Running Optuna for PGBM with MedianPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/300, Train metric: 1.2862\n","Estimator 1/300, Train metric: 1.1844\n","Estimator 2/300, Train metric: 1.1112\n","Estimator 3/300, Train metric: 1.0313\n","Estimator 4/300, Train metric: 0.9647\n","Estimator 5/300, Train metric: 0.9150\n","Estimator 6/300, Train metric: 0.8741\n","Estimator 7/300, Train metric: 0.8383\n","Estimator 8/300, Train metric: 0.7923\n","Estimator 9/300, Train metric: 0.7521\n","Estimator 10/300, Train metric: 0.7318\n","Estimator 11/300, Train metric: 0.7007\n","Estimator 12/300, Train metric: 0.6814\n","Estimator 13/300, Train metric: 0.6617\n","Estimator 14/300, Train metric: 0.6405\n","Estimator 15/300, Train metric: 0.6246\n","Estimator 16/300, Train metric: 0.6081\n","Estimator 17/300, Train metric: 0.5935\n","Estimator 18/300, Train metric: 0.5838\n","Estimator 19/300, Train metric: 0.5790\n","Estimator 20/300, Train metric: 0.5705\n","Estimator 21/300, Train metric: 0.5627\n","Estimator 22/300, Train metric: 0.5579\n","Estimator 23/300, Train metric: 0.5538\n","Estimator 24/300, Train metric: 0.5498\n","Estimator 25/300, Train metric: 0.5457\n","Estimator 26/300, Train metric: 0.5415\n","Estimator 27/300, Train metric: 0.5382\n","Estimator 28/300, Train metric: 0.5382\n","Estimator 29/300, Train metric: 0.5351\n","Estimator 30/300, Train metric: 0.5351\n","Estimator 31/300, Train metric: 0.5353\n","Estimator 32/300, Train metric: 0.5352\n","Estimator 33/300, Train metric: 0.5352\n","Estimator 34/300, Train metric: 0.5351\n","Estimator 35/300, Train metric: 0.5314\n","Estimator 36/300, Train metric: 0.5314\n","Estimator 37/300, Train metric: 0.5314\n","Estimator 38/300, Train metric: 0.5314\n","Estimator 39/300, Train metric: 0.5314\n","Estimator 40/300, Train metric: 0.5314\n","Estimator 41/300, Train metric: 0.5314\n","Estimator 42/300, Train metric: 0.5314\n","Estimator 43/300, Train metric: 0.5314\n","Estimator 44/300, Train metric: 0.5314\n","Estimator 45/300, Train metric: 0.5288\n","Estimator 46/300, Train metric: 0.5288\n","Estimator 47/300, Train metric: 0.5288\n","Estimator 48/300, Train metric: 0.5288\n","Estimator 49/300, Train metric: 0.5258\n","Estimator 50/300, Train metric: 0.5257\n","Estimator 51/300, Train metric: 0.5257\n","Estimator 52/300, Train metric: 0.5258\n","Estimator 53/300, Train metric: 0.5258\n","Estimator 54/300, Train metric: 0.5257\n","Estimator 55/300, Train metric: 0.5257\n","Estimator 56/300, Train metric: 0.5257\n","Estimator 57/300, Train metric: 0.5258\n","Estimator 58/300, Train metric: 0.5257\n","Estimator 59/300, Train metric: 0.5257\n","Estimator 60/300, Train metric: 0.5257\n","Estimator 61/300, Train metric: 0.5257\n","Estimator 62/300, Train metric: 0.5257\n","Estimator 63/300, Train metric: 0.5257\n","Estimator 64/300, Train metric: 0.5257\n","Estimator 65/300, Train metric: 0.5257\n","Estimator 66/300, Train metric: 0.5257\n","Estimator 67/300, Train metric: 0.5257\n","Estimator 68/300, Train metric: 0.5257\n","Estimator 69/300, Train metric: 0.5227\n","Estimator 70/300, Train metric: 0.5227\n","Estimator 71/300, Train metric: 0.5227\n","Estimator 72/300, Train metric: 0.5227\n","Estimator 73/300, Train metric: 0.5227\n","Estimator 74/300, Train metric: 0.5227\n","Estimator 75/300, Train metric: 0.5227\n","Estimator 76/300, Train metric: 0.5206\n","Estimator 77/300, Train metric: 0.5206\n","Estimator 78/300, Train metric: 0.5206\n","Estimator 79/300, Train metric: 0.5206\n","Estimator 80/300, Train metric: 0.5206\n","Estimator 81/300, Train metric: 0.5206\n","Estimator 82/300, Train metric: 0.5206\n","Estimator 83/300, Train metric: 0.5206\n","Estimator 84/300, Train metric: 0.5206\n","Estimator 85/300, Train metric: 0.5206\n","Estimator 86/300, Train metric: 0.5206\n","Estimator 87/300, Train metric: 0.5206\n","Estimator 88/300, Train metric: 0.5206\n","Estimator 89/300, Train metric: 0.5206\n","Estimator 90/300, Train metric: 0.5206\n","Estimator 91/300, Train metric: 0.5206\n","Estimator 92/300, Train metric: 0.5206\n","Estimator 93/300, Train metric: 0.5206\n","Estimator 94/300, Train metric: 0.5206\n","Estimator 95/300, Train metric: 0.5206\n","Estimator 96/300, Train metric: 0.5206\n","Estimator 97/300, Train metric: 0.5206\n","Estimator 98/300, Train metric: 0.5206\n","Estimator 99/300, Train metric: 0.5206\n","Estimator 100/300, Train metric: 0.5206\n","Estimator 101/300, Train metric: 0.5206\n","Estimator 102/300, Train metric: 0.5207\n","Estimator 103/300, Train metric: 0.5207\n","Estimator 104/300, Train metric: 0.5207\n","Estimator 105/300, Train metric: 0.5206\n","Estimator 106/300, Train metric: 0.5206\n","Estimator 107/300, Train metric: 0.5207\n","Estimator 108/300, Train metric: 0.5206\n","Estimator 109/300, Train metric: 0.5206\n","Estimator 110/300, Train metric: 0.5206\n","Estimator 111/300, Train metric: 0.5184\n","Estimator 112/300, Train metric: 0.5183\n","Estimator 113/300, Train metric: 0.5183\n","Estimator 114/300, Train metric: 0.5183\n","Estimator 115/300, Train metric: 0.5183\n","Estimator 116/300, Train metric: 0.5184\n","Estimator 117/300, Train metric: 0.5183\n","Estimator 118/300, Train metric: 0.5183\n","Estimator 119/300, Train metric: 0.5183\n","Estimator 120/300, Train metric: 0.5183\n","Estimator 121/300, Train metric: 0.5183\n","Estimator 122/300, Train metric: 0.5183\n","Estimator 123/300, Train metric: 0.5183\n","Estimator 124/300, Train metric: 0.5183\n","Estimator 125/300, Train metric: 0.5183\n","Estimator 126/300, Train metric: 0.5183\n","Estimator 127/300, Train metric: 0.5183\n","Estimator 128/300, Train metric: 0.5183\n","Estimator 129/300, Train metric: 0.5183\n","Estimator 130/300, Train metric: 0.5183\n","Estimator 131/300, Train metric: 0.5183\n","Estimator 132/300, Train metric: 0.5183\n","Estimator 133/300, Train metric: 0.5183\n","Estimator 134/300, Train metric: 0.5183\n","Estimator 135/300, Train metric: 0.5183\n","Estimator 136/300, Train metric: 0.5183\n","Estimator 137/300, Train metric: 0.5183\n","Estimator 138/300, Train metric: 0.5183\n","Estimator 139/300, Train metric: 0.5183\n","Estimator 140/300, Train metric: 0.5183\n","Estimator 141/300, Train metric: 0.5183\n","Estimator 142/300, Train metric: 0.5183\n","Estimator 143/300, Train metric: 0.5183\n","Estimator 144/300, Train metric: 0.5183\n","Estimator 145/300, Train metric: 0.5183\n","Estimator 146/300, Train metric: 0.5183\n","Estimator 147/300, Train metric: 0.5183\n","Estimator 148/300, Train metric: 0.5183\n","Estimator 149/300, Train metric: 0.5183\n","Estimator 150/300, Train metric: 0.5183\n","Estimator 151/300, Train metric: 0.5183\n","Estimator 152/300, Train metric: 0.5183\n","Estimator 153/300, Train metric: 0.5183\n","Estimator 154/300, Train metric: 0.5183\n","Estimator 155/300, Train metric: 0.5183\n","Estimator 156/300, Train metric: 0.5183\n","Estimator 157/300, Train metric: 0.5183\n","Estimator 158/300, Train metric: 0.5183\n","Estimator 159/300, Train metric: 0.5183\n","Estimator 160/300, Train metric: 0.5183\n","Estimator 161/300, Train metric: 0.5183\n","Estimator 162/300, Train metric: 0.5183\n","Estimator 163/300, Train metric: 0.5183\n","Estimator 164/300, Train metric: 0.5183\n","Estimator 165/300, Train metric: 0.5183\n","Estimator 166/300, Train metric: 0.5183\n","Estimator 167/300, Train metric: 0.5183\n","Estimator 168/300, Train metric: 0.5183\n","Estimator 169/300, Train metric: 0.5183\n","Estimator 170/300, Train metric: 0.5184\n","Estimator 171/300, Train metric: 0.5184\n","Estimator 172/300, Train metric: 0.5183\n","Estimator 173/300, Train metric: 0.5183\n","Estimator 174/300, Train metric: 0.5183\n","Estimator 175/300, Train metric: 0.5183\n","Estimator 176/300, Train metric: 0.5183\n","Estimator 177/300, Train metric: 0.5183\n","Estimator 178/300, Train metric: 0.5183\n","Estimator 179/300, Train metric: 0.5183\n","Estimator 180/300, Train metric: 0.5183\n","Estimator 181/300, Train metric: 0.5183\n","Estimator 182/300, Train metric: 0.5183\n","Estimator 183/300, Train metric: 0.5183\n","Estimator 184/300, Train metric: 0.5183\n","Estimator 185/300, Train metric: 0.5183\n","Estimator 186/300, Train metric: 0.5183\n","Estimator 187/300, Train metric: 0.5183\n","Estimator 188/300, Train metric: 0.5183\n","Estimator 189/300, Train metric: 0.5183\n","Estimator 190/300, Train metric: 0.5183\n","Estimator 191/300, Train metric: 0.5183\n","Estimator 192/300, Train metric: 0.5183\n","Estimator 193/300, Train metric: 0.5183\n","Estimator 194/300, Train metric: 0.5183\n","Estimator 195/300, Train metric: 0.5183\n","Estimator 196/300, Train metric: 0.5183\n","Estimator 197/300, Train metric: 0.5183\n","Estimator 198/300, Train metric: 0.5183\n","Estimator 199/300, Train metric: 0.5183\n","Estimator 200/300, Train metric: 0.5183\n","Estimator 201/300, Train metric: 0.5183\n","Estimator 202/300, Train metric: 0.5184\n","Estimator 203/300, Train metric: 0.5183\n","Estimator 204/300, Train metric: 0.5183\n","Estimator 205/300, Train metric: 0.5183\n","Estimator 206/300, Train metric: 0.5184\n","Estimator 207/300, Train metric: 0.5184\n","Estimator 208/300, Train metric: 0.5184\n","Estimator 209/300, Train metric: 0.5184\n","Estimator 210/300, Train metric: 0.5184\n","Estimator 211/300, Train metric: 0.5183\n","Estimator 212/300, Train metric: 0.5183\n","Estimator 213/300, Train metric: 0.5183\n","Estimator 214/300, Train metric: 0.5183\n","Estimator 215/300, Train metric: 0.5183\n","Estimator 216/300, Train metric: 0.5183\n","Estimator 217/300, Train metric: 0.5183\n","Estimator 218/300, Train metric: 0.5183\n","Estimator 219/300, Train metric: 0.5183\n","Estimator 220/300, Train metric: 0.5183\n","Estimator 221/300, Train metric: 0.5183\n","Estimator 222/300, Train metric: 0.5183\n","Estimator 223/300, Train metric: 0.5183\n","Estimator 224/300, Train metric: 0.5183\n","Estimator 225/300, Train metric: 0.5183\n","Estimator 226/300, Train metric: 0.5183\n","Estimator 227/300, Train metric: 0.5183\n","Estimator 228/300, Train metric: 0.5183\n","Estimator 229/300, Train metric: 0.5183\n","Estimator 230/300, Train metric: 0.5183\n","Estimator 231/300, Train metric: 0.5183\n","Estimator 232/300, Train metric: 0.5183\n","Estimator 233/300, Train metric: 0.5183\n","Estimator 234/300, Train metric: 0.5183\n","Estimator 235/300, Train metric: 0.5183\n","Estimator 236/300, Train metric: 0.5183\n","Estimator 237/300, Train metric: 0.5183\n","Estimator 238/300, Train metric: 0.5183\n","Estimator 239/300, Train metric: 0.5183\n","Estimator 240/300, Train metric: 0.5183\n","Estimator 241/300, Train metric: 0.5183\n","Estimator 242/300, Train metric: 0.5183\n","Estimator 243/300, Train metric: 0.5183\n","Estimator 244/300, Train metric: 0.5183\n","Estimator 245/300, Train metric: 0.5183\n","Estimator 246/300, Train metric: 0.5183\n","Estimator 247/300, Train metric: 0.5183\n","Estimator 248/300, Train metric: 0.5183\n","Estimator 249/300, Train metric: 0.5183\n","Estimator 250/300, Train metric: 0.5183\n","Estimator 251/300, Train metric: 0.5183\n","Estimator 252/300, Train metric: 0.5183\n","Estimator 253/300, Train metric: 0.5183\n","Estimator 254/300, Train metric: 0.5157\n","Estimator 255/300, Train metric: 0.5157\n","Estimator 256/300, Train metric: 0.5157\n","Estimator 257/300, Train metric: 0.5157\n","Estimator 258/300, Train metric: 0.5157\n","Estimator 259/300, Train metric: 0.5157\n","Estimator 260/300, Train metric: 0.5157\n","Estimator 261/300, Train metric: 0.5157\n","Estimator 262/300, Train metric: 0.5158\n","Estimator 263/300, Train metric: 0.5157\n","Estimator 264/300, Train metric: 0.5157\n","Estimator 265/300, Train metric: 0.5157\n","Estimator 266/300, Train metric: 0.5157\n","Estimator 267/300, Train metric: 0.5157\n","Estimator 268/300, Train metric: 0.5157\n","Estimator 269/300, Train metric: 0.5157\n","Estimator 270/300, Train metric: 0.5157\n","Estimator 271/300, Train metric: 0.5157\n","Estimator 272/300, Train metric: 0.5157\n","Estimator 273/300, Train metric: 0.5157\n","Estimator 274/300, Train metric: 0.5157\n","Estimator 275/300, Train metric: 0.5157\n","Estimator 276/300, Train metric: 0.5157\n","Estimator 277/300, Train metric: 0.5157\n","Estimator 278/300, Train metric: 0.5158\n","Estimator 279/300, Train metric: 0.5157\n","Estimator 280/300, Train metric: 0.5157\n","Estimator 281/300, Train metric: 0.5157\n","Estimator 282/300, Train metric: 0.5157\n","Estimator 283/300, Train metric: 0.5157\n","Estimator 284/300, Train metric: 0.5157\n","Estimator 285/300, Train metric: 0.5157\n","Estimator 286/300, Train metric: 0.5157\n","Estimator 287/300, Train metric: 0.5157\n","Estimator 288/300, Train metric: 0.5157\n","Estimator 289/300, Train metric: 0.5157\n","Estimator 290/300, Train metric: 0.5157\n","Estimator 291/300, Train metric: 0.5157\n","Estimator 292/300, Train metric: 0.5157\n","Estimator 293/300, Train metric: 0.5157\n","Estimator 294/300, Train metric: 0.5157\n","Estimator 295/300, Train metric: 0.5157\n","Estimator 296/300, Train metric: 0.5157\n","Estimator 297/300, Train metric: 0.5157\n","Estimator 298/300, Train metric: 0.5157\n","Estimator 299/300, Train metric: 0.5157\n","Best MSE for PGBM with MedianPruner: 0.18817443349630766 with params: {'n_estimators': 300, 'learning_rate': 0.15, 'max_leaves': 37, 'min_split_gain': 1.0, 'reg_lambda': 10.0, 'feature_fraction': 0.5, 'bagging_fraction': 0.9, 'tree_correlation': 0.1, 'min_data_in_leaf': 5, 'max_bin': 64, 'distribution': 'normal'}\n","Best RMSE for PGBM with MedianPruner: 0.43379077156655566\n","Correlation Coefficient for PGBM with MedianPruner: 0.9550325886698825\n","Running Optuna for PGBM with NopPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/100, Train metric: 1.3360\n","Estimator 1/100, Train metric: 1.2803\n","Estimator 2/100, Train metric: 1.2291\n","Estimator 3/100, Train metric: 1.1808\n","Estimator 4/100, Train metric: 1.1349\n","Estimator 5/100, Train metric: 1.0938\n","Estimator 6/100, Train metric: 1.0522\n","Estimator 7/100, Train metric: 1.0143\n","Estimator 8/100, Train metric: 0.9779\n","Estimator 9/100, Train metric: 0.9447\n","Estimator 10/100, Train metric: 0.9162\n","Estimator 11/100, Train metric: 0.8882\n","Estimator 12/100, Train metric: 0.8625\n","Estimator 13/100, Train metric: 0.8408\n","Estimator 14/100, Train metric: 0.8154\n","Estimator 15/100, Train metric: 0.7949\n","Estimator 16/100, Train metric: 0.7737\n","Estimator 17/100, Train metric: 0.7514\n","Estimator 18/100, Train metric: 0.7349\n","Estimator 19/100, Train metric: 0.7205\n","Estimator 20/100, Train metric: 0.7031\n","Estimator 21/100, Train metric: 0.6849\n","Estimator 22/100, Train metric: 0.6742\n","Estimator 23/100, Train metric: 0.6615\n","Estimator 24/100, Train metric: 0.6498\n","Estimator 25/100, Train metric: 0.6391\n","Estimator 26/100, Train metric: 0.6302\n","Estimator 27/100, Train metric: 0.6200\n","Estimator 28/100, Train metric: 0.6086\n","Estimator 29/100, Train metric: 0.5998\n","Estimator 30/100, Train metric: 0.5925\n","Estimator 31/100, Train metric: 0.5845\n","Estimator 32/100, Train metric: 0.5775\n","Estimator 33/100, Train metric: 0.5712\n","Estimator 34/100, Train metric: 0.5652\n","Estimator 35/100, Train metric: 0.5585\n","Estimator 36/100, Train metric: 0.5511\n","Estimator 37/100, Train metric: 0.5449\n","Estimator 38/100, Train metric: 0.5398\n","Estimator 39/100, Train metric: 0.5347\n","Estimator 40/100, Train metric: 0.5309\n","Estimator 41/100, Train metric: 0.5240\n","Estimator 42/100, Train metric: 0.5178\n","Estimator 43/100, Train metric: 0.5124\n","Estimator 44/100, Train metric: 0.5092\n","Estimator 45/100, Train metric: 0.5068\n","Estimator 46/100, Train metric: 0.5011\n","Estimator 47/100, Train metric: 0.4972\n","Estimator 48/100, Train metric: 0.4947\n","Estimator 49/100, Train metric: 0.4935\n","Estimator 50/100, Train metric: 0.4908\n","Estimator 51/100, Train metric: 0.4908\n","Estimator 52/100, Train metric: 0.4894\n","Estimator 53/100, Train metric: 0.4882\n","Estimator 54/100, Train metric: 0.4856\n","Estimator 55/100, Train metric: 0.4856\n","Estimator 56/100, Train metric: 0.4856\n","Estimator 57/100, Train metric: 0.4842\n","Estimator 58/100, Train metric: 0.4842\n","Estimator 59/100, Train metric: 0.4829\n","Estimator 60/100, Train metric: 0.4817\n","Estimator 61/100, Train metric: 0.4817\n","Estimator 62/100, Train metric: 0.4817\n","Estimator 63/100, Train metric: 0.4807\n","Estimator 64/100, Train metric: 0.4764\n","Estimator 65/100, Train metric: 0.4764\n","Estimator 66/100, Train metric: 0.4751\n","Estimator 67/100, Train metric: 0.4751\n","Estimator 68/100, Train metric: 0.4751\n","Estimator 69/100, Train metric: 0.4737\n","Estimator 70/100, Train metric: 0.4737\n","Estimator 71/100, Train metric: 0.4727\n","Estimator 72/100, Train metric: 0.4727\n","Estimator 73/100, Train metric: 0.4727\n","Estimator 74/100, Train metric: 0.4727\n","Estimator 75/100, Train metric: 0.4727\n","Estimator 76/100, Train metric: 0.4727\n","Estimator 77/100, Train metric: 0.4727\n","Estimator 78/100, Train metric: 0.4727\n","Estimator 79/100, Train metric: 0.4727\n","Estimator 80/100, Train metric: 0.4727\n","Estimator 81/100, Train metric: 0.4727\n","Estimator 82/100, Train metric: 0.4727\n","Estimator 83/100, Train metric: 0.4727\n","Estimator 84/100, Train metric: 0.4727\n","Estimator 85/100, Train metric: 0.4727\n","Estimator 86/100, Train metric: 0.4727\n","Estimator 87/100, Train metric: 0.4727\n","Estimator 88/100, Train metric: 0.4727\n","Estimator 89/100, Train metric: 0.4727\n","Estimator 90/100, Train metric: 0.4727\n","Estimator 91/100, Train metric: 0.4727\n","Estimator 92/100, Train metric: 0.4717\n","Estimator 93/100, Train metric: 0.4708\n","Estimator 94/100, Train metric: 0.4708\n","Estimator 95/100, Train metric: 0.4708\n","Estimator 96/100, Train metric: 0.4708\n","Estimator 97/100, Train metric: 0.4708\n","Estimator 98/100, Train metric: 0.4708\n","Estimator 99/100, Train metric: 0.4708\n","Best MSE for PGBM with NopPruner: 0.18733663750305285 with params: {'n_estimators': 100, 'learning_rate': 0.05, 'max_leaves': 45, 'min_split_gain': 1.0, 'reg_lambda': 0.1, 'feature_fraction': 0.9, 'bagging_fraction': 0.9, 'tree_correlation': 0.0, 'min_data_in_leaf': 10, 'max_bin': 256, 'distribution': 'normal'}\n","Best RMSE for PGBM with NopPruner: 0.4328240260233399\n","Correlation Coefficient for PGBM with NopPruner: 0.9545861333357423\n","Running Optuna for PGBM with PatientPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/200, Train metric: 1.2787\n","Estimator 1/200, Train metric: 1.1810\n","Estimator 2/200, Train metric: 1.0998\n","Estimator 3/200, Train metric: 1.0198\n","Estimator 4/200, Train metric: 0.9465\n","Estimator 5/200, Train metric: 0.8832\n","Estimator 6/200, Train metric: 0.8371\n","Estimator 7/200, Train metric: 0.7954\n","Estimator 8/200, Train metric: 0.7505\n","Estimator 9/200, Train metric: 0.7099\n","Estimator 10/200, Train metric: 0.6847\n","Estimator 11/200, Train metric: 0.6532\n","Estimator 12/200, Train metric: 0.6272\n","Estimator 13/200, Train metric: 0.6059\n","Estimator 14/200, Train metric: 0.5866\n","Estimator 15/200, Train metric: 0.5616\n","Estimator 16/200, Train metric: 0.5474\n","Estimator 17/200, Train metric: 0.5356\n","Estimator 18/200, Train metric: 0.5292\n","Estimator 19/200, Train metric: 0.5238\n","Estimator 20/200, Train metric: 0.5176\n","Estimator 21/200, Train metric: 0.5125\n","Estimator 22/200, Train metric: 0.5082\n","Estimator 23/200, Train metric: 0.5042\n","Estimator 24/200, Train metric: 0.5009\n","Estimator 25/200, Train metric: 0.4978\n","Estimator 26/200, Train metric: 0.4946\n","Estimator 27/200, Train metric: 0.4918\n","Estimator 28/200, Train metric: 0.4918\n","Estimator 29/200, Train metric: 0.4918\n","Estimator 30/200, Train metric: 0.4893\n","Estimator 31/200, Train metric: 0.4893\n","Estimator 32/200, Train metric: 0.4893\n","Estimator 33/200, Train metric: 0.4893\n","Estimator 34/200, Train metric: 0.4893\n","Estimator 35/200, Train metric: 0.4893\n","Estimator 36/200, Train metric: 0.4893\n","Estimator 37/200, Train metric: 0.4893\n","Estimator 38/200, Train metric: 0.4893\n","Estimator 39/200, Train metric: 0.4893\n","Estimator 40/200, Train metric: 0.4893\n","Estimator 41/200, Train metric: 0.4893\n","Estimator 42/200, Train metric: 0.4893\n","Estimator 43/200, Train metric: 0.4893\n","Estimator 44/200, Train metric: 0.4893\n","Estimator 45/200, Train metric: 0.4893\n","Estimator 46/200, Train metric: 0.4893\n","Estimator 47/200, Train metric: 0.4893\n","Estimator 48/200, Train metric: 0.4893\n","Estimator 49/200, Train metric: 0.4893\n","Estimator 50/200, Train metric: 0.4893\n","Estimator 51/200, Train metric: 0.4893\n","Estimator 52/200, Train metric: 0.4893\n","Estimator 53/200, Train metric: 0.4893\n","Estimator 54/200, Train metric: 0.4893\n","Estimator 55/200, Train metric: 0.4893\n","Estimator 56/200, Train metric: 0.4893\n","Estimator 57/200, Train metric: 0.4893\n","Estimator 58/200, Train metric: 0.4893\n","Estimator 59/200, Train metric: 0.4893\n","Estimator 60/200, Train metric: 0.4893\n","Estimator 61/200, Train metric: 0.4893\n","Estimator 62/200, Train metric: 0.4893\n","Estimator 63/200, Train metric: 0.4893\n","Estimator 64/200, Train metric: 0.4893\n","Estimator 65/200, Train metric: 0.4893\n","Estimator 66/200, Train metric: 0.4893\n","Estimator 67/200, Train metric: 0.4893\n","Estimator 68/200, Train metric: 0.4893\n","Estimator 69/200, Train metric: 0.4893\n","Estimator 70/200, Train metric: 0.4893\n","Estimator 71/200, Train metric: 0.4893\n","Estimator 72/200, Train metric: 0.4893\n","Estimator 73/200, Train metric: 0.4893\n","Estimator 74/200, Train metric: 0.4893\n","Estimator 75/200, Train metric: 0.4893\n","Estimator 76/200, Train metric: 0.4893\n","Estimator 77/200, Train metric: 0.4893\n","Estimator 78/200, Train metric: 0.4893\n","Estimator 79/200, Train metric: 0.4893\n","Estimator 80/200, Train metric: 0.4893\n","Estimator 81/200, Train metric: 0.4893\n","Estimator 82/200, Train metric: 0.4893\n","Estimator 83/200, Train metric: 0.4893\n","Estimator 84/200, Train metric: 0.4893\n","Estimator 85/200, Train metric: 0.4893\n","Estimator 86/200, Train metric: 0.4893\n","Estimator 87/200, Train metric: 0.4893\n","Estimator 88/200, Train metric: 0.4893\n","Estimator 89/200, Train metric: 0.4893\n","Estimator 90/200, Train metric: 0.4893\n","Estimator 91/200, Train metric: 0.4893\n","Estimator 92/200, Train metric: 0.4893\n","Estimator 93/200, Train metric: 0.4893\n","Estimator 94/200, Train metric: 0.4893\n","Estimator 95/200, Train metric: 0.4893\n","Estimator 96/200, Train metric: 0.4893\n","Estimator 97/200, Train metric: 0.4893\n","Estimator 98/200, Train metric: 0.4893\n","Estimator 99/200, Train metric: 0.4893\n","Estimator 100/200, Train metric: 0.4893\n","Estimator 101/200, Train metric: 0.4893\n","Estimator 102/200, Train metric: 0.4893\n","Estimator 103/200, Train metric: 0.4893\n","Estimator 104/200, Train metric: 0.4893\n","Estimator 105/200, Train metric: 0.4893\n","Estimator 106/200, Train metric: 0.4893\n","Estimator 107/200, Train metric: 0.4893\n","Estimator 108/200, Train metric: 0.4893\n","Estimator 109/200, Train metric: 0.4893\n","Estimator 110/200, Train metric: 0.4893\n","Estimator 111/200, Train metric: 0.4893\n","Estimator 112/200, Train metric: 0.4893\n","Estimator 113/200, Train metric: 0.4893\n","Estimator 114/200, Train metric: 0.4893\n","Estimator 115/200, Train metric: 0.4893\n","Estimator 116/200, Train metric: 0.4893\n","Estimator 117/200, Train metric: 0.4893\n","Estimator 118/200, Train metric: 0.4893\n","Estimator 119/200, Train metric: 0.4893\n","Estimator 120/200, Train metric: 0.4893\n","Estimator 121/200, Train metric: 0.4893\n","Estimator 122/200, Train metric: 0.4893\n","Estimator 123/200, Train metric: 0.4893\n","Estimator 124/200, Train metric: 0.4893\n","Estimator 125/200, Train metric: 0.4893\n","Estimator 126/200, Train metric: 0.4893\n","Estimator 127/200, Train metric: 0.4893\n","Estimator 128/200, Train metric: 0.4893\n","Estimator 129/200, Train metric: 0.4893\n","Estimator 130/200, Train metric: 0.4893\n","Estimator 131/200, Train metric: 0.4893\n","Estimator 132/200, Train metric: 0.4893\n","Estimator 133/200, Train metric: 0.4893\n","Estimator 134/200, Train metric: 0.4893\n","Estimator 135/200, Train metric: 0.4893\n","Estimator 136/200, Train metric: 0.4893\n","Estimator 137/200, Train metric: 0.4893\n","Estimator 138/200, Train metric: 0.4893\n","Estimator 139/200, Train metric: 0.4893\n","Estimator 140/200, Train metric: 0.4893\n","Estimator 141/200, Train metric: 0.4893\n","Estimator 142/200, Train metric: 0.4893\n","Estimator 143/200, Train metric: 0.4893\n","Estimator 144/200, Train metric: 0.4893\n","Estimator 145/200, Train metric: 0.4893\n","Estimator 146/200, Train metric: 0.4893\n","Estimator 147/200, Train metric: 0.4893\n","Estimator 148/200, Train metric: 0.4893\n","Estimator 149/200, Train metric: 0.4893\n","Estimator 150/200, Train metric: 0.4893\n","Estimator 151/200, Train metric: 0.4893\n","Estimator 152/200, Train metric: 0.4893\n","Estimator 153/200, Train metric: 0.4893\n","Estimator 154/200, Train metric: 0.4893\n","Estimator 155/200, Train metric: 0.4893\n","Estimator 156/200, Train metric: 0.4893\n","Estimator 157/200, Train metric: 0.4893\n","Estimator 158/200, Train metric: 0.4893\n","Estimator 159/200, Train metric: 0.4893\n","Estimator 160/200, Train metric: 0.4893\n","Estimator 161/200, Train metric: 0.4893\n","Estimator 162/200, Train metric: 0.4893\n","Estimator 163/200, Train metric: 0.4893\n","Estimator 164/200, Train metric: 0.4893\n","Estimator 165/200, Train metric: 0.4893\n","Estimator 166/200, Train metric: 0.4893\n","Estimator 167/200, Train metric: 0.4893\n","Estimator 168/200, Train metric: 0.4893\n","Estimator 169/200, Train metric: 0.4893\n","Estimator 170/200, Train metric: 0.4893\n","Estimator 171/200, Train metric: 0.4893\n","Estimator 172/200, Train metric: 0.4893\n","Estimator 173/200, Train metric: 0.4893\n","Estimator 174/200, Train metric: 0.4893\n","Estimator 175/200, Train metric: 0.4893\n","Estimator 176/200, Train metric: 0.4893\n","Estimator 177/200, Train metric: 0.4893\n","Estimator 178/200, Train metric: 0.4893\n","Estimator 179/200, Train metric: 0.4893\n","Estimator 180/200, Train metric: 0.4893\n","Estimator 181/200, Train metric: 0.4893\n","Estimator 182/200, Train metric: 0.4893\n","Estimator 183/200, Train metric: 0.4893\n","Estimator 184/200, Train metric: 0.4893\n","Estimator 185/200, Train metric: 0.4893\n","Estimator 186/200, Train metric: 0.4893\n","Estimator 187/200, Train metric: 0.4893\n","Estimator 188/200, Train metric: 0.4893\n","Estimator 189/200, Train metric: 0.4893\n","Estimator 190/200, Train metric: 0.4893\n","Estimator 191/200, Train metric: 0.4893\n","Estimator 192/200, Train metric: 0.4893\n","Estimator 193/200, Train metric: 0.4893\n","Estimator 194/200, Train metric: 0.4893\n","Estimator 195/200, Train metric: 0.4893\n","Estimator 196/200, Train metric: 0.4893\n","Estimator 197/200, Train metric: 0.4893\n","Estimator 198/200, Train metric: 0.4893\n","Estimator 199/200, Train metric: 0.4893\n","Best MSE for PGBM with PatientPruner: 0.16692777023205455 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_leaves': 36, 'min_split_gain': 1.0, 'reg_lambda': 0.1, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'tree_correlation': 0.3, 'min_data_in_leaf': 10, 'max_bin': 128, 'distribution': 'normal'}\n","Best RMSE for PGBM with PatientPruner: 0.40856795056887973\n","Correlation Coefficient for PGBM with PatientPruner: 0.9566086213516656\n","Running Optuna for PGBM with PercentilePruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/300, Train metric: 1.2225\n","Estimator 1/300, Train metric: 1.0857\n","Estimator 2/300, Train metric: 0.9782\n","Estimator 3/300, Train metric: 0.8797\n","Estimator 4/300, Train metric: 0.7961\n","Estimator 5/300, Train metric: 0.7315\n","Estimator 6/300, Train metric: 0.6861\n","Estimator 7/300, Train metric: 0.6459\n","Estimator 8/300, Train metric: 0.6103\n","Estimator 9/300, Train metric: 0.5789\n","Estimator 10/300, Train metric: 0.5643\n","Estimator 11/300, Train metric: 0.5441\n","Estimator 12/300, Train metric: 0.5290\n","Estimator 13/300, Train metric: 0.5169\n","Estimator 14/300, Train metric: 0.5102\n","Estimator 15/300, Train metric: 0.5049\n","Estimator 16/300, Train metric: 0.5003\n","Estimator 17/300, Train metric: 0.4967\n","Estimator 18/300, Train metric: 0.4967\n","Estimator 19/300, Train metric: 0.4932\n","Estimator 20/300, Train metric: 0.4932\n","Estimator 21/300, Train metric: 0.4932\n","Estimator 22/300, Train metric: 0.4932\n","Estimator 23/300, Train metric: 0.4932\n","Estimator 24/300, Train metric: 0.4932\n","Estimator 25/300, Train metric: 0.4932\n","Estimator 26/300, Train metric: 0.4932\n","Estimator 27/300, Train metric: 0.4932\n","Estimator 28/300, Train metric: 0.4932\n","Estimator 29/300, Train metric: 0.4932\n","Estimator 30/300, Train metric: 0.4932\n","Estimator 31/300, Train metric: 0.4932\n","Estimator 32/300, Train metric: 0.4932\n","Estimator 33/300, Train metric: 0.4932\n","Estimator 34/300, Train metric: 0.4932\n","Estimator 35/300, Train metric: 0.4932\n","Estimator 36/300, Train metric: 0.4932\n","Estimator 37/300, Train metric: 0.4932\n","Estimator 38/300, Train metric: 0.4932\n","Estimator 39/300, Train metric: 0.4932\n","Estimator 40/300, Train metric: 0.4932\n","Estimator 41/300, Train metric: 0.4932\n","Estimator 42/300, Train metric: 0.4932\n","Estimator 43/300, Train metric: 0.4932\n","Estimator 44/300, Train metric: 0.4932\n","Estimator 45/300, Train metric: 0.4932\n","Estimator 46/300, Train metric: 0.4932\n","Estimator 47/300, Train metric: 0.4932\n","Estimator 48/300, Train metric: 0.4932\n","Estimator 49/300, Train metric: 0.4932\n","Estimator 50/300, Train metric: 0.4932\n","Estimator 51/300, Train metric: 0.4932\n","Estimator 52/300, Train metric: 0.4932\n","Estimator 53/300, Train metric: 0.4932\n","Estimator 54/300, Train metric: 0.4932\n","Estimator 55/300, Train metric: 0.4932\n","Estimator 56/300, Train metric: 0.4932\n","Estimator 57/300, Train metric: 0.4932\n","Estimator 58/300, Train metric: 0.4932\n","Estimator 59/300, Train metric: 0.4932\n","Estimator 60/300, Train metric: 0.4932\n","Estimator 61/300, Train metric: 0.4932\n","Estimator 62/300, Train metric: 0.4932\n","Estimator 63/300, Train metric: 0.4932\n","Estimator 64/300, Train metric: 0.4932\n","Estimator 65/300, Train metric: 0.4932\n","Estimator 66/300, Train metric: 0.4932\n","Estimator 67/300, Train metric: 0.4932\n","Estimator 68/300, Train metric: 0.4932\n","Estimator 69/300, Train metric: 0.4932\n","Estimator 70/300, Train metric: 0.4932\n","Estimator 71/300, Train metric: 0.4932\n","Estimator 72/300, Train metric: 0.4932\n","Estimator 73/300, Train metric: 0.4932\n","Estimator 74/300, Train metric: 0.4932\n","Estimator 75/300, Train metric: 0.4932\n","Estimator 76/300, Train metric: 0.4932\n","Estimator 77/300, Train metric: 0.4932\n","Estimator 78/300, Train metric: 0.4932\n","Estimator 79/300, Train metric: 0.4932\n","Estimator 80/300, Train metric: 0.4932\n","Estimator 81/300, Train metric: 0.4932\n","Estimator 82/300, Train metric: 0.4932\n","Estimator 83/300, Train metric: 0.4932\n","Estimator 84/300, Train metric: 0.4932\n","Estimator 85/300, Train metric: 0.4932\n","Estimator 86/300, Train metric: 0.4932\n","Estimator 87/300, Train metric: 0.4932\n","Estimator 88/300, Train metric: 0.4932\n","Estimator 89/300, Train metric: 0.4932\n","Estimator 90/300, Train metric: 0.4932\n","Estimator 91/300, Train metric: 0.4932\n","Estimator 92/300, Train metric: 0.4932\n","Estimator 93/300, Train metric: 0.4932\n","Estimator 94/300, Train metric: 0.4932\n","Estimator 95/300, Train metric: 0.4932\n","Estimator 96/300, Train metric: 0.4932\n","Estimator 97/300, Train metric: 0.4932\n","Estimator 98/300, Train metric: 0.4932\n","Estimator 99/300, Train metric: 0.4932\n","Estimator 100/300, Train metric: 0.4932\n","Estimator 101/300, Train metric: 0.4932\n","Estimator 102/300, Train metric: 0.4932\n","Estimator 103/300, Train metric: 0.4932\n","Estimator 104/300, Train metric: 0.4932\n","Estimator 105/300, Train metric: 0.4932\n","Estimator 106/300, Train metric: 0.4932\n","Estimator 107/300, Train metric: 0.4932\n","Estimator 108/300, Train metric: 0.4932\n","Estimator 109/300, Train metric: 0.4932\n","Estimator 110/300, Train metric: 0.4932\n","Estimator 111/300, Train metric: 0.4932\n","Estimator 112/300, Train metric: 0.4932\n","Estimator 113/300, Train metric: 0.4932\n","Estimator 114/300, Train metric: 0.4932\n","Estimator 115/300, Train metric: 0.4932\n","Estimator 116/300, Train metric: 0.4932\n","Estimator 117/300, Train metric: 0.4932\n","Estimator 118/300, Train metric: 0.4932\n","Estimator 119/300, Train metric: 0.4932\n","Estimator 120/300, Train metric: 0.4932\n","Estimator 121/300, Train metric: 0.4932\n","Estimator 122/300, Train metric: 0.4932\n","Estimator 123/300, Train metric: 0.4932\n","Estimator 124/300, Train metric: 0.4932\n","Estimator 125/300, Train metric: 0.4932\n","Estimator 126/300, Train metric: 0.4932\n","Estimator 127/300, Train metric: 0.4932\n","Estimator 128/300, Train metric: 0.4932\n","Estimator 129/300, Train metric: 0.4932\n","Estimator 130/300, Train metric: 0.4932\n","Estimator 131/300, Train metric: 0.4932\n","Estimator 132/300, Train metric: 0.4932\n","Estimator 133/300, Train metric: 0.4932\n","Estimator 134/300, Train metric: 0.4932\n","Estimator 135/300, Train metric: 0.4932\n","Estimator 136/300, Train metric: 0.4932\n","Estimator 137/300, Train metric: 0.4932\n","Estimator 138/300, Train metric: 0.4932\n","Estimator 139/300, Train metric: 0.4932\n","Estimator 140/300, Train metric: 0.4932\n","Estimator 141/300, Train metric: 0.4932\n","Estimator 142/300, Train metric: 0.4932\n","Estimator 143/300, Train metric: 0.4932\n","Estimator 144/300, Train metric: 0.4932\n","Estimator 145/300, Train metric: 0.4932\n","Estimator 146/300, Train metric: 0.4932\n","Estimator 147/300, Train metric: 0.4932\n","Estimator 148/300, Train metric: 0.4932\n","Estimator 149/300, Train metric: 0.4932\n","Estimator 150/300, Train metric: 0.4932\n","Estimator 151/300, Train metric: 0.4932\n","Estimator 152/300, Train metric: 0.4932\n","Estimator 153/300, Train metric: 0.4932\n","Estimator 154/300, Train metric: 0.4932\n","Estimator 155/300, Train metric: 0.4932\n","Estimator 156/300, Train metric: 0.4932\n","Estimator 157/300, Train metric: 0.4932\n","Estimator 158/300, Train metric: 0.4932\n","Estimator 159/300, Train metric: 0.4932\n","Estimator 160/300, Train metric: 0.4932\n","Estimator 161/300, Train metric: 0.4932\n","Estimator 162/300, Train metric: 0.4932\n","Estimator 163/300, Train metric: 0.4932\n","Estimator 164/300, Train metric: 0.4932\n","Estimator 165/300, Train metric: 0.4932\n","Estimator 166/300, Train metric: 0.4932\n","Estimator 167/300, Train metric: 0.4932\n","Estimator 168/300, Train metric: 0.4932\n","Estimator 169/300, Train metric: 0.4932\n","Estimator 170/300, Train metric: 0.4932\n","Estimator 171/300, Train metric: 0.4932\n","Estimator 172/300, Train metric: 0.4932\n","Estimator 173/300, Train metric: 0.4932\n","Estimator 174/300, Train metric: 0.4932\n","Estimator 175/300, Train metric: 0.4932\n","Estimator 176/300, Train metric: 0.4932\n","Estimator 177/300, Train metric: 0.4932\n","Estimator 178/300, Train metric: 0.4932\n","Estimator 179/300, Train metric: 0.4932\n","Estimator 180/300, Train metric: 0.4932\n","Estimator 181/300, Train metric: 0.4932\n","Estimator 182/300, Train metric: 0.4932\n","Estimator 183/300, Train metric: 0.4932\n","Estimator 184/300, Train metric: 0.4932\n","Estimator 185/300, Train metric: 0.4932\n","Estimator 186/300, Train metric: 0.4932\n","Estimator 187/300, Train metric: 0.4932\n","Estimator 188/300, Train metric: 0.4932\n","Estimator 189/300, Train metric: 0.4932\n","Estimator 190/300, Train metric: 0.4932\n","Estimator 191/300, Train metric: 0.4932\n","Estimator 192/300, Train metric: 0.4932\n","Estimator 193/300, Train metric: 0.4932\n","Estimator 194/300, Train metric: 0.4932\n","Estimator 195/300, Train metric: 0.4932\n","Estimator 196/300, Train metric: 0.4932\n","Estimator 197/300, Train metric: 0.4932\n","Estimator 198/300, Train metric: 0.4932\n","Estimator 199/300, Train metric: 0.4932\n","Estimator 200/300, Train metric: 0.4932\n","Estimator 201/300, Train metric: 0.4932\n","Estimator 202/300, Train metric: 0.4932\n","Estimator 203/300, Train metric: 0.4932\n","Estimator 204/300, Train metric: 0.4932\n","Estimator 205/300, Train metric: 0.4932\n","Estimator 206/300, Train metric: 0.4932\n","Estimator 207/300, Train metric: 0.4932\n","Estimator 208/300, Train metric: 0.4932\n","Estimator 209/300, Train metric: 0.4932\n","Estimator 210/300, Train metric: 0.4932\n","Estimator 211/300, Train metric: 0.4932\n","Estimator 212/300, Train metric: 0.4932\n","Estimator 213/300, Train metric: 0.4932\n","Estimator 214/300, Train metric: 0.4932\n","Estimator 215/300, Train metric: 0.4932\n","Estimator 216/300, Train metric: 0.4932\n","Estimator 217/300, Train metric: 0.4932\n","Estimator 218/300, Train metric: 0.4932\n","Estimator 219/300, Train metric: 0.4932\n","Estimator 220/300, Train metric: 0.4932\n","Estimator 221/300, Train metric: 0.4932\n","Estimator 222/300, Train metric: 0.4932\n","Estimator 223/300, Train metric: 0.4932\n","Estimator 224/300, Train metric: 0.4932\n","Estimator 225/300, Train metric: 0.4932\n","Estimator 226/300, Train metric: 0.4932\n","Estimator 227/300, Train metric: 0.4932\n","Estimator 228/300, Train metric: 0.4932\n","Estimator 229/300, Train metric: 0.4932\n","Estimator 230/300, Train metric: 0.4932\n","Estimator 231/300, Train metric: 0.4932\n","Estimator 232/300, Train metric: 0.4932\n","Estimator 233/300, Train metric: 0.4932\n","Estimator 234/300, Train metric: 0.4932\n","Estimator 235/300, Train metric: 0.4932\n","Estimator 236/300, Train metric: 0.4932\n","Estimator 237/300, Train metric: 0.4932\n","Estimator 238/300, Train metric: 0.4932\n","Estimator 239/300, Train metric: 0.4932\n","Estimator 240/300, Train metric: 0.4932\n","Estimator 241/300, Train metric: 0.4932\n","Estimator 242/300, Train metric: 0.4932\n","Estimator 243/300, Train metric: 0.4932\n","Estimator 244/300, Train metric: 0.4932\n","Estimator 245/300, Train metric: 0.4932\n","Estimator 246/300, Train metric: 0.4932\n","Estimator 247/300, Train metric: 0.4932\n","Estimator 248/300, Train metric: 0.4932\n","Estimator 249/300, Train metric: 0.4932\n","Estimator 250/300, Train metric: 0.4932\n","Estimator 251/300, Train metric: 0.4932\n","Estimator 252/300, Train metric: 0.4932\n","Estimator 253/300, Train metric: 0.4932\n","Estimator 254/300, Train metric: 0.4932\n","Estimator 255/300, Train metric: 0.4932\n","Estimator 256/300, Train metric: 0.4932\n","Estimator 257/300, Train metric: 0.4932\n","Estimator 258/300, Train metric: 0.4932\n","Estimator 259/300, Train metric: 0.4932\n","Estimator 260/300, Train metric: 0.4932\n","Estimator 261/300, Train metric: 0.4932\n","Estimator 262/300, Train metric: 0.4932\n","Estimator 263/300, Train metric: 0.4932\n","Estimator 264/300, Train metric: 0.4932\n","Estimator 265/300, Train metric: 0.4932\n","Estimator 266/300, Train metric: 0.4932\n","Estimator 267/300, Train metric: 0.4932\n","Estimator 268/300, Train metric: 0.4932\n","Estimator 269/300, Train metric: 0.4932\n","Estimator 270/300, Train metric: 0.4932\n","Estimator 271/300, Train metric: 0.4932\n","Estimator 272/300, Train metric: 0.4932\n","Estimator 273/300, Train metric: 0.4932\n","Estimator 274/300, Train metric: 0.4932\n","Estimator 275/300, Train metric: 0.4932\n","Estimator 276/300, Train metric: 0.4932\n","Estimator 277/300, Train metric: 0.4932\n","Estimator 278/300, Train metric: 0.4932\n","Estimator 279/300, Train metric: 0.4932\n","Estimator 280/300, Train metric: 0.4932\n","Estimator 281/300, Train metric: 0.4932\n","Estimator 282/300, Train metric: 0.4932\n","Estimator 283/300, Train metric: 0.4932\n","Estimator 284/300, Train metric: 0.4932\n","Estimator 285/300, Train metric: 0.4932\n","Estimator 286/300, Train metric: 0.4932\n","Estimator 287/300, Train metric: 0.4932\n","Estimator 288/300, Train metric: 0.4932\n","Estimator 289/300, Train metric: 0.4932\n","Estimator 290/300, Train metric: 0.4932\n","Estimator 291/300, Train metric: 0.4932\n","Estimator 292/300, Train metric: 0.4932\n","Estimator 293/300, Train metric: 0.4932\n","Estimator 294/300, Train metric: 0.4932\n","Estimator 295/300, Train metric: 0.4932\n","Estimator 296/300, Train metric: 0.4932\n","Estimator 297/300, Train metric: 0.4932\n","Estimator 298/300, Train metric: 0.4932\n","Estimator 299/300, Train metric: 0.4932\n","Best MSE for PGBM with PercentilePruner: 0.1650769864545701 with params: {'n_estimators': 300, 'learning_rate': 0.15, 'max_leaves': 60, 'min_split_gain': 1.0, 'reg_lambda': 0.1, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'tree_correlation': 0.1, 'min_data_in_leaf': 10, 'max_bin': 128, 'distribution': 'normal'}\n","Best RMSE for PGBM with PercentilePruner: 0.4062966729553297\n","Correlation Coefficient for PGBM with PercentilePruner: 0.9578416038071123\n","Running Optuna for PGBM with SuccessiveHalvingPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/200, Train metric: 1.2887\n","Estimator 1/200, Train metric: 1.1890\n","Estimator 2/200, Train metric: 1.1118\n","Estimator 3/200, Train metric: 1.0337\n","Estimator 4/200, Train metric: 0.9629\n","Estimator 5/200, Train metric: 0.9052\n","Estimator 6/200, Train metric: 0.8544\n","Estimator 7/200, Train metric: 0.8079\n","Estimator 8/200, Train metric: 0.7543\n","Estimator 9/200, Train metric: 0.7083\n","Estimator 10/200, Train metric: 0.6815\n","Estimator 11/200, Train metric: 0.6465\n","Estimator 12/200, Train metric: 0.6111\n","Estimator 13/200, Train metric: 0.5894\n","Estimator 14/200, Train metric: 0.5628\n","Estimator 15/200, Train metric: 0.5468\n","Estimator 16/200, Train metric: 0.5274\n","Estimator 17/200, Train metric: 0.5109\n","Estimator 18/200, Train metric: 0.5018\n","Estimator 19/200, Train metric: 0.4967\n","Estimator 20/200, Train metric: 0.4851\n","Estimator 21/200, Train metric: 0.4698\n","Estimator 22/200, Train metric: 0.4657\n","Estimator 23/200, Train metric: 0.4466\n","Estimator 24/200, Train metric: 0.4327\n","Estimator 25/200, Train metric: 0.4284\n","Estimator 26/200, Train metric: 0.4243\n","Estimator 27/200, Train metric: 0.4213\n","Estimator 28/200, Train metric: 0.4213\n","Estimator 29/200, Train metric: 0.4112\n","Estimator 30/200, Train metric: 0.4112\n","Estimator 31/200, Train metric: 0.4113\n","Estimator 32/200, Train metric: 0.4082\n","Estimator 33/200, Train metric: 0.4082\n","Estimator 34/200, Train metric: 0.4081\n","Estimator 35/200, Train metric: 0.4053\n","Estimator 36/200, Train metric: 0.4052\n","Estimator 37/200, Train metric: 0.4052\n","Estimator 38/200, Train metric: 0.4052\n","Estimator 39/200, Train metric: 0.4052\n","Estimator 40/200, Train metric: 0.4052\n","Estimator 41/200, Train metric: 0.4052\n","Estimator 42/200, Train metric: 0.4052\n","Estimator 43/200, Train metric: 0.4052\n","Estimator 44/200, Train metric: 0.4052\n","Estimator 45/200, Train metric: 0.4030\n","Estimator 46/200, Train metric: 0.4030\n","Estimator 47/200, Train metric: 0.4030\n","Estimator 48/200, Train metric: 0.4030\n","Estimator 49/200, Train metric: 0.4030\n","Estimator 50/200, Train metric: 0.4030\n","Estimator 51/200, Train metric: 0.4030\n","Estimator 52/200, Train metric: 0.4030\n","Estimator 53/200, Train metric: 0.4030\n","Estimator 54/200, Train metric: 0.4030\n","Estimator 55/200, Train metric: 0.4030\n","Estimator 56/200, Train metric: 0.4030\n","Estimator 57/200, Train metric: 0.4030\n","Estimator 58/200, Train metric: 0.4030\n","Estimator 59/200, Train metric: 0.4030\n","Estimator 60/200, Train metric: 0.4030\n","Estimator 61/200, Train metric: 0.4030\n","Estimator 62/200, Train metric: 0.4030\n","Estimator 63/200, Train metric: 0.4030\n","Estimator 64/200, Train metric: 0.4030\n","Estimator 65/200, Train metric: 0.4030\n","Estimator 66/200, Train metric: 0.4030\n","Estimator 67/200, Train metric: 0.4030\n","Estimator 68/200, Train metric: 0.4030\n","Estimator 69/200, Train metric: 0.3996\n","Estimator 70/200, Train metric: 0.3996\n","Estimator 71/200, Train metric: 0.3973\n","Estimator 72/200, Train metric: 0.3973\n","Estimator 73/200, Train metric: 0.3973\n","Estimator 74/200, Train metric: 0.3973\n","Estimator 75/200, Train metric: 0.3973\n","Estimator 76/200, Train metric: 0.3973\n","Estimator 77/200, Train metric: 0.3973\n","Estimator 78/200, Train metric: 0.3973\n","Estimator 79/200, Train metric: 0.3973\n","Estimator 80/200, Train metric: 0.3973\n","Estimator 81/200, Train metric: 0.3973\n","Estimator 82/200, Train metric: 0.3973\n","Estimator 83/200, Train metric: 0.3973\n","Estimator 84/200, Train metric: 0.3973\n","Estimator 85/200, Train metric: 0.3973\n","Estimator 86/200, Train metric: 0.3973\n","Estimator 87/200, Train metric: 0.3973\n","Estimator 88/200, Train metric: 0.3973\n","Estimator 89/200, Train metric: 0.3973\n","Estimator 90/200, Train metric: 0.3973\n","Estimator 91/200, Train metric: 0.3973\n","Estimator 92/200, Train metric: 0.3973\n","Estimator 93/200, Train metric: 0.3973\n","Estimator 94/200, Train metric: 0.3973\n","Estimator 95/200, Train metric: 0.3973\n","Estimator 96/200, Train metric: 0.3973\n","Estimator 97/200, Train metric: 0.3973\n","Estimator 98/200, Train metric: 0.3973\n","Estimator 99/200, Train metric: 0.3973\n","Estimator 100/200, Train metric: 0.3973\n","Estimator 101/200, Train metric: 0.3973\n","Estimator 102/200, Train metric: 0.3974\n","Estimator 103/200, Train metric: 0.3974\n","Estimator 104/200, Train metric: 0.3974\n","Estimator 105/200, Train metric: 0.3974\n","Estimator 106/200, Train metric: 0.3973\n","Estimator 107/200, Train metric: 0.3974\n","Estimator 108/200, Train metric: 0.3973\n","Estimator 109/200, Train metric: 0.3973\n","Estimator 110/200, Train metric: 0.3973\n","Estimator 111/200, Train metric: 0.3974\n","Estimator 112/200, Train metric: 0.3973\n","Estimator 113/200, Train metric: 0.3973\n","Estimator 114/200, Train metric: 0.3973\n","Estimator 115/200, Train metric: 0.3973\n","Estimator 116/200, Train metric: 0.3974\n","Estimator 117/200, Train metric: 0.3973\n","Estimator 118/200, Train metric: 0.3973\n","Estimator 119/200, Train metric: 0.3973\n","Estimator 120/200, Train metric: 0.3973\n","Estimator 121/200, Train metric: 0.3973\n","Estimator 122/200, Train metric: 0.3973\n","Estimator 123/200, Train metric: 0.3973\n","Estimator 124/200, Train metric: 0.3973\n","Estimator 125/200, Train metric: 0.3973\n","Estimator 126/200, Train metric: 0.3973\n","Estimator 127/200, Train metric: 0.3973\n","Estimator 128/200, Train metric: 0.3973\n","Estimator 129/200, Train metric: 0.3973\n","Estimator 130/200, Train metric: 0.3973\n","Estimator 131/200, Train metric: 0.3973\n","Estimator 132/200, Train metric: 0.3973\n","Estimator 133/200, Train metric: 0.3973\n","Estimator 134/200, Train metric: 0.3973\n","Estimator 135/200, Train metric: 0.3973\n","Estimator 136/200, Train metric: 0.3973\n","Estimator 137/200, Train metric: 0.3973\n","Estimator 138/200, Train metric: 0.3973\n","Estimator 139/200, Train metric: 0.3973\n","Estimator 140/200, Train metric: 0.3953\n","Estimator 141/200, Train metric: 0.3953\n","Estimator 142/200, Train metric: 0.3953\n","Estimator 143/200, Train metric: 0.3953\n","Estimator 144/200, Train metric: 0.3953\n","Estimator 145/200, Train metric: 0.3953\n","Estimator 146/200, Train metric: 0.3953\n","Estimator 147/200, Train metric: 0.3953\n","Estimator 148/200, Train metric: 0.3953\n","Estimator 149/200, Train metric: 0.3953\n","Estimator 150/200, Train metric: 0.3953\n","Estimator 151/200, Train metric: 0.3953\n","Estimator 152/200, Train metric: 0.3953\n","Estimator 153/200, Train metric: 0.3953\n","Estimator 154/200, Train metric: 0.3953\n","Estimator 155/200, Train metric: 0.3953\n","Estimator 156/200, Train metric: 0.3953\n","Estimator 157/200, Train metric: 0.3953\n","Estimator 158/200, Train metric: 0.3953\n","Estimator 159/200, Train metric: 0.3953\n","Estimator 160/200, Train metric: 0.3953\n","Estimator 161/200, Train metric: 0.3953\n","Estimator 162/200, Train metric: 0.3953\n","Estimator 163/200, Train metric: 0.3953\n","Estimator 164/200, Train metric: 0.3953\n","Estimator 165/200, Train metric: 0.3953\n","Estimator 166/200, Train metric: 0.3953\n","Estimator 167/200, Train metric: 0.3953\n","Estimator 168/200, Train metric: 0.3953\n","Estimator 169/200, Train metric: 0.3953\n","Estimator 170/200, Train metric: 0.3953\n","Estimator 171/200, Train metric: 0.3953\n","Estimator 172/200, Train metric: 0.3953\n","Estimator 173/200, Train metric: 0.3953\n","Estimator 174/200, Train metric: 0.3953\n","Estimator 175/200, Train metric: 0.3953\n","Estimator 176/200, Train metric: 0.3953\n","Estimator 177/200, Train metric: 0.3953\n","Estimator 178/200, Train metric: 0.3954\n","Estimator 179/200, Train metric: 0.3953\n","Estimator 180/200, Train metric: 0.3953\n","Estimator 181/200, Train metric: 0.3953\n","Estimator 182/200, Train metric: 0.3953\n","Estimator 183/200, Train metric: 0.3953\n","Estimator 184/200, Train metric: 0.3953\n","Estimator 185/200, Train metric: 0.3953\n","Estimator 186/200, Train metric: 0.3953\n","Estimator 187/200, Train metric: 0.3953\n","Estimator 188/200, Train metric: 0.3953\n","Estimator 189/200, Train metric: 0.3953\n","Estimator 190/200, Train metric: 0.3953\n","Estimator 191/200, Train metric: 0.3953\n","Estimator 192/200, Train metric: 0.3953\n","Estimator 193/200, Train metric: 0.3953\n","Estimator 194/200, Train metric: 0.3953\n","Estimator 195/200, Train metric: 0.3953\n","Estimator 196/200, Train metric: 0.3953\n","Estimator 197/200, Train metric: 0.3953\n","Estimator 198/200, Train metric: 0.3953\n","Estimator 199/200, Train metric: 0.3953\n","Best MSE for PGBM with SuccessiveHalvingPruner: 0.17175091924260685 with params: {'n_estimators': 200, 'learning_rate': 0.1, 'max_leaves': 31, 'min_split_gain': 1.0, 'reg_lambda': 1.0, 'feature_fraction': 0.5, 'bagging_fraction': 0.9, 'tree_correlation': 0.3, 'min_data_in_leaf': 3, 'max_bin': 256, 'distribution': 'normal'}\n","Best RMSE for PGBM with SuccessiveHalvingPruner: 0.41442842475222047\n","Correlation Coefficient for PGBM with SuccessiveHalvingPruner: 0.9576307624183943\n","Running Optuna for PGBM with HyperbandPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/100, Train metric: 1.2862\n","Estimator 1/100, Train metric: 1.1831\n","Estimator 2/100, Train metric: 1.1098\n","Estimator 3/100, Train metric: 1.0296\n","Estimator 4/100, Train metric: 0.9613\n","Estimator 5/100, Train metric: 0.9099\n","Estimator 6/100, Train metric: 0.8687\n","Estimator 7/100, Train metric: 0.8325\n","Estimator 8/100, Train metric: 0.7859\n","Estimator 9/100, Train metric: 0.7461\n","Estimator 10/100, Train metric: 0.7256\n","Estimator 11/100, Train metric: 0.6940\n","Estimator 12/100, Train metric: 0.6753\n","Estimator 13/100, Train metric: 0.6557\n","Estimator 14/100, Train metric: 0.6324\n","Estimator 15/100, Train metric: 0.6164\n","Estimator 16/100, Train metric: 0.5984\n","Estimator 17/100, Train metric: 0.5826\n","Estimator 18/100, Train metric: 0.5727\n","Estimator 19/100, Train metric: 0.5672\n","Estimator 20/100, Train metric: 0.5590\n","Estimator 21/100, Train metric: 0.5502\n","Estimator 22/100, Train metric: 0.5455\n","Estimator 23/100, Train metric: 0.5407\n","Estimator 24/100, Train metric: 0.5338\n","Estimator 25/100, Train metric: 0.5291\n","Estimator 26/100, Train metric: 0.5248\n","Estimator 27/100, Train metric: 0.5209\n","Estimator 28/100, Train metric: 0.5209\n","Estimator 29/100, Train metric: 0.5173\n","Estimator 30/100, Train metric: 0.5174\n","Estimator 31/100, Train metric: 0.5175\n","Estimator 32/100, Train metric: 0.5174\n","Estimator 33/100, Train metric: 0.5174\n","Estimator 34/100, Train metric: 0.5172\n","Estimator 35/100, Train metric: 0.5132\n","Estimator 36/100, Train metric: 0.5132\n","Estimator 37/100, Train metric: 0.5132\n","Estimator 38/100, Train metric: 0.5132\n","Estimator 39/100, Train metric: 0.5132\n","Estimator 40/100, Train metric: 0.5132\n","Estimator 41/100, Train metric: 0.5132\n","Estimator 42/100, Train metric: 0.5132\n","Estimator 43/100, Train metric: 0.5132\n","Estimator 44/100, Train metric: 0.5132\n","Estimator 45/100, Train metric: 0.5132\n","Estimator 46/100, Train metric: 0.5132\n","Estimator 47/100, Train metric: 0.5101\n","Estimator 48/100, Train metric: 0.5101\n","Estimator 49/100, Train metric: 0.5102\n","Estimator 50/100, Train metric: 0.5102\n","Estimator 51/100, Train metric: 0.5101\n","Estimator 52/100, Train metric: 0.5102\n","Estimator 53/100, Train metric: 0.5102\n","Estimator 54/100, Train metric: 0.5101\n","Estimator 55/100, Train metric: 0.5101\n","Estimator 56/100, Train metric: 0.5101\n","Estimator 57/100, Train metric: 0.5102\n","Estimator 58/100, Train metric: 0.5101\n","Estimator 59/100, Train metric: 0.5101\n","Estimator 60/100, Train metric: 0.5101\n","Estimator 61/100, Train metric: 0.5101\n","Estimator 62/100, Train metric: 0.5101\n","Estimator 63/100, Train metric: 0.5101\n","Estimator 64/100, Train metric: 0.5101\n","Estimator 65/100, Train metric: 0.5101\n","Estimator 66/100, Train metric: 0.5101\n","Estimator 67/100, Train metric: 0.5101\n","Estimator 68/100, Train metric: 0.5101\n","Estimator 69/100, Train metric: 0.5067\n","Estimator 70/100, Train metric: 0.5067\n","Estimator 71/100, Train metric: 0.5067\n","Estimator 72/100, Train metric: 0.5067\n","Estimator 73/100, Train metric: 0.5067\n","Estimator 74/100, Train metric: 0.5068\n","Estimator 75/100, Train metric: 0.5068\n","Estimator 76/100, Train metric: 0.5068\n","Estimator 77/100, Train metric: 0.5068\n","Estimator 78/100, Train metric: 0.5067\n","Estimator 79/100, Train metric: 0.5068\n","Estimator 80/100, Train metric: 0.5067\n","Estimator 81/100, Train metric: 0.5067\n","Estimator 82/100, Train metric: 0.5067\n","Estimator 83/100, Train metric: 0.5067\n","Estimator 84/100, Train metric: 0.5067\n","Estimator 85/100, Train metric: 0.5068\n","Estimator 86/100, Train metric: 0.5068\n","Estimator 87/100, Train metric: 0.5067\n","Estimator 88/100, Train metric: 0.5068\n","Estimator 89/100, Train metric: 0.5068\n","Estimator 90/100, Train metric: 0.5067\n","Estimator 91/100, Train metric: 0.5067\n","Estimator 92/100, Train metric: 0.5067\n","Estimator 93/100, Train metric: 0.5067\n","Estimator 94/100, Train metric: 0.5067\n","Estimator 95/100, Train metric: 0.5067\n","Estimator 96/100, Train metric: 0.5067\n","Estimator 97/100, Train metric: 0.5067\n","Estimator 98/100, Train metric: 0.5067\n","Estimator 99/100, Train metric: 0.5068\n","Best MSE for PGBM with HyperbandPruner: 0.1716273503321355 with params: {'n_estimators': 100, 'learning_rate': 0.15, 'max_leaves': 21, 'min_split_gain': 1.0, 'reg_lambda': 10.0, 'feature_fraction': 0.5, 'bagging_fraction': 0.9, 'tree_correlation': 0.2, 'min_data_in_leaf': 3, 'max_bin': 128, 'distribution': 'studentt'}\n","Best RMSE for PGBM with HyperbandPruner: 0.4142793143908292\n","Correlation Coefficient for PGBM with HyperbandPruner: 0.9578613917333262\n","Running Optuna for PGBM with ThresholdPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/100, Train metric: 1.3215\n","Estimator 1/100, Train metric: 1.2500\n","Estimator 2/100, Train metric: 1.1965\n","Estimator 3/100, Train metric: 1.1360\n","Estimator 4/100, Train metric: 1.0823\n","Estimator 5/100, Train metric: 1.0407\n","Estimator 6/100, Train metric: 1.0030\n","Estimator 7/100, Train metric: 0.9673\n","Estimator 8/100, Train metric: 0.9247\n","Estimator 9/100, Train metric: 0.8867\n","Estimator 10/100, Train metric: 0.8616\n","Estimator 11/100, Train metric: 0.8270\n","Estimator 12/100, Train metric: 0.8003\n","Estimator 13/100, Train metric: 0.7786\n","Estimator 14/100, Train metric: 0.7506\n","Estimator 15/100, Train metric: 0.7290\n","Estimator 16/100, Train metric: 0.7061\n","Estimator 17/100, Train metric: 0.6845\n","Estimator 18/100, Train metric: 0.6700\n","Estimator 19/100, Train metric: 0.6573\n","Estimator 20/100, Train metric: 0.6400\n","Estimator 21/100, Train metric: 0.6221\n","Estimator 22/100, Train metric: 0.6128\n","Estimator 23/100, Train metric: 0.6009\n","Estimator 24/100, Train metric: 0.5902\n","Estimator 25/100, Train metric: 0.5805\n","Estimator 26/100, Train metric: 0.5729\n","Estimator 27/100, Train metric: 0.5675\n","Estimator 28/100, Train metric: 0.5569\n","Estimator 29/100, Train metric: 0.5503\n","Estimator 30/100, Train metric: 0.5432\n","Estimator 31/100, Train metric: 0.5404\n","Estimator 32/100, Train metric: 0.5367\n","Estimator 33/100, Train metric: 0.5300\n","Estimator 34/100, Train metric: 0.5270\n","Estimator 35/100, Train metric: 0.5238\n","Estimator 36/100, Train metric: 0.5172\n","Estimator 37/100, Train metric: 0.5112\n","Estimator 38/100, Train metric: 0.5092\n","Estimator 39/100, Train metric: 0.5070\n","Estimator 40/100, Train metric: 0.4998\n","Estimator 41/100, Train metric: 0.4981\n","Estimator 42/100, Train metric: 0.4896\n","Estimator 43/100, Train metric: 0.4878\n","Estimator 44/100, Train metric: 0.4848\n","Estimator 45/100, Train metric: 0.4830\n","Estimator 46/100, Train metric: 0.4760\n","Estimator 47/100, Train metric: 0.4744\n","Estimator 48/100, Train metric: 0.4710\n","Estimator 49/100, Train metric: 0.4682\n","Estimator 50/100, Train metric: 0.4614\n","Estimator 51/100, Train metric: 0.4613\n","Estimator 52/100, Train metric: 0.4548\n","Estimator 53/100, Train metric: 0.4489\n","Estimator 54/100, Train metric: 0.4487\n","Estimator 55/100, Train metric: 0.4486\n","Estimator 56/100, Train metric: 0.4485\n","Estimator 57/100, Train metric: 0.4472\n","Estimator 58/100, Train metric: 0.4472\n","Estimator 59/100, Train metric: 0.4472\n","Estimator 60/100, Train metric: 0.4472\n","Estimator 61/100, Train metric: 0.4458\n","Estimator 62/100, Train metric: 0.4457\n","Estimator 63/100, Train metric: 0.4458\n","Estimator 64/100, Train metric: 0.4458\n","Estimator 65/100, Train metric: 0.4457\n","Estimator 66/100, Train metric: 0.4445\n","Estimator 67/100, Train metric: 0.4445\n","Estimator 68/100, Train metric: 0.4445\n","Estimator 69/100, Train metric: 0.4427\n","Estimator 70/100, Train metric: 0.4427\n","Estimator 71/100, Train metric: 0.4400\n","Estimator 72/100, Train metric: 0.4400\n","Estimator 73/100, Train metric: 0.4374\n","Estimator 74/100, Train metric: 0.4374\n","Estimator 75/100, Train metric: 0.4374\n","Estimator 76/100, Train metric: 0.4363\n","Estimator 77/100, Train metric: 0.4363\n","Estimator 78/100, Train metric: 0.4363\n","Estimator 79/100, Train metric: 0.4363\n","Estimator 80/100, Train metric: 0.4363\n","Estimator 81/100, Train metric: 0.4363\n","Estimator 82/100, Train metric: 0.4363\n","Estimator 83/100, Train metric: 0.4363\n","Estimator 84/100, Train metric: 0.4363\n","Estimator 85/100, Train metric: 0.4363\n","Estimator 86/100, Train metric: 0.4363\n","Estimator 87/100, Train metric: 0.4363\n","Estimator 88/100, Train metric: 0.4363\n","Estimator 89/100, Train metric: 0.4363\n","Estimator 90/100, Train metric: 0.4363\n","Estimator 91/100, Train metric: 0.4363\n","Estimator 92/100, Train metric: 0.4363\n","Estimator 93/100, Train metric: 0.4353\n","Estimator 94/100, Train metric: 0.4353\n","Estimator 95/100, Train metric: 0.4353\n","Estimator 96/100, Train metric: 0.4353\n","Estimator 97/100, Train metric: 0.4353\n","Estimator 98/100, Train metric: 0.4353\n","Estimator 99/100, Train metric: 0.4353\n","Best MSE for PGBM with ThresholdPruner: 0.19552682861046522 with params: {'n_estimators': 100, 'learning_rate': 0.1, 'max_leaves': 34, 'min_split_gain': 0.5, 'reg_lambda': 10.0, 'feature_fraction': 0.5, 'bagging_fraction': 0.9, 'tree_correlation': 0.2, 'min_data_in_leaf': 5, 'max_bin': 128, 'distribution': 'laplace'}\n","Best RMSE for PGBM with ThresholdPruner: 0.4421841568967224\n","Correlation Coefficient for PGBM with ThresholdPruner: 0.9540042092051298\n","Running Optuna for PGBM with WilcoxonPruner...\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Training on CPU\n","Estimator 0/300, Train metric: 1.2562\n","Estimator 1/300, Train metric: 1.1420\n","Estimator 2/300, Train metric: 1.0525\n","Estimator 3/300, Train metric: 0.9666\n","Estimator 4/300, Train metric: 0.8866\n","Estimator 5/300, Train metric: 0.8191\n","Estimator 6/300, Train metric: 0.7729\n","Estimator 7/300, Train metric: 0.7319\n","Estimator 8/300, Train metric: 0.6895\n","Estimator 9/300, Train metric: 0.6508\n","Estimator 10/300, Train metric: 0.6265\n","Estimator 11/300, Train metric: 0.5984\n","Estimator 12/300, Train metric: 0.5759\n","Estimator 13/300, Train metric: 0.5589\n","Estimator 14/300, Train metric: 0.5438\n","Estimator 15/300, Train metric: 0.5273\n","Estimator 16/300, Train metric: 0.5163\n","Estimator 17/300, Train metric: 0.5074\n","Estimator 18/300, Train metric: 0.5029\n","Estimator 19/300, Train metric: 0.4995\n","Estimator 20/300, Train metric: 0.4950\n","Estimator 21/300, Train metric: 0.4915\n","Estimator 22/300, Train metric: 0.4849\n","Estimator 23/300, Train metric: 0.4822\n","Estimator 24/300, Train metric: 0.4774\n","Estimator 25/300, Train metric: 0.4754\n","Estimator 26/300, Train metric: 0.4681\n","Estimator 27/300, Train metric: 0.4681\n","Estimator 28/300, Train metric: 0.4681\n","Estimator 29/300, Train metric: 0.4681\n","Estimator 30/300, Train metric: 0.4681\n","Estimator 31/300, Train metric: 0.4681\n","Estimator 32/300, Train metric: 0.4681\n","Estimator 33/300, Train metric: 0.4681\n","Estimator 34/300, Train metric: 0.4681\n","Estimator 35/300, Train metric: 0.4681\n","Estimator 36/300, Train metric: 0.4681\n","Estimator 37/300, Train metric: 0.4681\n","Estimator 38/300, Train metric: 0.4681\n","Estimator 39/300, Train metric: 0.4681\n","Estimator 40/300, Train metric: 0.4681\n","Estimator 41/300, Train metric: 0.4681\n","Estimator 42/300, Train metric: 0.4681\n","Estimator 43/300, Train metric: 0.4681\n","Estimator 44/300, Train metric: 0.4681\n","Estimator 45/300, Train metric: 0.4681\n","Estimator 46/300, Train metric: 0.4681\n","Estimator 47/300, Train metric: 0.4681\n","Estimator 48/300, Train metric: 0.4681\n","Estimator 49/300, Train metric: 0.4681\n","Estimator 50/300, Train metric: 0.4681\n","Estimator 51/300, Train metric: 0.4681\n","Estimator 52/300, Train metric: 0.4681\n","Estimator 53/300, Train metric: 0.4681\n","Estimator 54/300, Train metric: 0.4681\n","Estimator 55/300, Train metric: 0.4681\n","Estimator 56/300, Train metric: 0.4681\n","Estimator 57/300, Train metric: 0.4681\n","Estimator 58/300, Train metric: 0.4681\n","Estimator 59/300, Train metric: 0.4681\n","Estimator 60/300, Train metric: 0.4681\n","Estimator 61/300, Train metric: 0.4681\n","Estimator 62/300, Train metric: 0.4681\n","Estimator 63/300, Train metric: 0.4681\n","Estimator 64/300, Train metric: 0.4681\n","Estimator 65/300, Train metric: 0.4681\n","Estimator 66/300, Train metric: 0.4681\n","Estimator 67/300, Train metric: 0.4681\n","Estimator 68/300, Train metric: 0.4681\n","Estimator 69/300, Train metric: 0.4681\n","Estimator 70/300, Train metric: 0.4681\n","Estimator 71/300, Train metric: 0.4681\n","Estimator 72/300, Train metric: 0.4681\n","Estimator 73/300, Train metric: 0.4681\n","Estimator 74/300, Train metric: 0.4681\n","Estimator 75/300, Train metric: 0.4681\n","Estimator 76/300, Train metric: 0.4681\n","Estimator 77/300, Train metric: 0.4681\n","Estimator 78/300, Train metric: 0.4681\n","Estimator 79/300, Train metric: 0.4681\n","Estimator 80/300, Train metric: 0.4681\n","Estimator 81/300, Train metric: 0.4681\n","Estimator 82/300, Train metric: 0.4681\n","Estimator 83/300, Train metric: 0.4681\n","Estimator 84/300, Train metric: 0.4681\n","Estimator 85/300, Train metric: 0.4681\n","Estimator 86/300, Train metric: 0.4681\n","Estimator 87/300, Train metric: 0.4681\n","Estimator 88/300, Train metric: 0.4681\n","Estimator 89/300, Train metric: 0.4681\n","Estimator 90/300, Train metric: 0.4681\n","Estimator 91/300, Train metric: 0.4681\n","Estimator 92/300, Train metric: 0.4681\n","Estimator 93/300, Train metric: 0.4681\n","Estimator 94/300, Train metric: 0.4681\n","Estimator 95/300, Train metric: 0.4681\n","Estimator 96/300, Train metric: 0.4681\n","Estimator 97/300, Train metric: 0.4681\n","Estimator 98/300, Train metric: 0.4681\n","Estimator 99/300, Train metric: 0.4681\n","Estimator 100/300, Train metric: 0.4681\n","Estimator 101/300, Train metric: 0.4681\n","Estimator 102/300, Train metric: 0.4681\n","Estimator 103/300, Train metric: 0.4681\n","Estimator 104/300, Train metric: 0.4681\n","Estimator 105/300, Train metric: 0.4681\n","Estimator 106/300, Train metric: 0.4681\n","Estimator 107/300, Train metric: 0.4681\n","Estimator 108/300, Train metric: 0.4681\n","Estimator 109/300, Train metric: 0.4681\n","Estimator 110/300, Train metric: 0.4681\n","Estimator 111/300, Train metric: 0.4681\n","Estimator 112/300, Train metric: 0.4681\n","Estimator 113/300, Train metric: 0.4681\n","Estimator 114/300, Train metric: 0.4681\n","Estimator 115/300, Train metric: 0.4681\n","Estimator 116/300, Train metric: 0.4681\n","Estimator 117/300, Train metric: 0.4681\n","Estimator 118/300, Train metric: 0.4681\n","Estimator 119/300, Train metric: 0.4681\n","Estimator 120/300, Train metric: 0.4681\n","Estimator 121/300, Train metric: 0.4681\n","Estimator 122/300, Train metric: 0.4681\n","Estimator 123/300, Train metric: 0.4681\n","Estimator 124/300, Train metric: 0.4681\n","Estimator 125/300, Train metric: 0.4681\n","Estimator 126/300, Train metric: 0.4681\n","Estimator 127/300, Train metric: 0.4681\n","Estimator 128/300, Train metric: 0.4681\n","Estimator 129/300, Train metric: 0.4681\n","Estimator 130/300, Train metric: 0.4681\n","Estimator 131/300, Train metric: 0.4681\n","Estimator 132/300, Train metric: 0.4681\n","Estimator 133/300, Train metric: 0.4681\n","Estimator 134/300, Train metric: 0.4681\n","Estimator 135/300, Train metric: 0.4681\n","Estimator 136/300, Train metric: 0.4681\n","Estimator 137/300, Train metric: 0.4681\n","Estimator 138/300, Train metric: 0.4681\n","Estimator 139/300, Train metric: 0.4681\n","Estimator 140/300, Train metric: 0.4681\n","Estimator 141/300, Train metric: 0.4681\n","Estimator 142/300, Train metric: 0.4681\n","Estimator 143/300, Train metric: 0.4681\n","Estimator 144/300, Train metric: 0.4681\n","Estimator 145/300, Train metric: 0.4681\n","Estimator 146/300, Train metric: 0.4681\n","Estimator 147/300, Train metric: 0.4681\n","Estimator 148/300, Train metric: 0.4681\n","Estimator 149/300, Train metric: 0.4681\n","Estimator 150/300, Train metric: 0.4681\n","Estimator 151/300, Train metric: 0.4681\n","Estimator 152/300, Train metric: 0.4681\n","Estimator 153/300, Train metric: 0.4681\n","Estimator 154/300, Train metric: 0.4681\n","Estimator 155/300, Train metric: 0.4681\n","Estimator 156/300, Train metric: 0.4681\n","Estimator 157/300, Train metric: 0.4681\n","Estimator 158/300, Train metric: 0.4681\n","Estimator 159/300, Train metric: 0.4681\n","Estimator 160/300, Train metric: 0.4681\n","Estimator 161/300, Train metric: 0.4681\n","Estimator 162/300, Train metric: 0.4681\n","Estimator 163/300, Train metric: 0.4681\n","Estimator 164/300, Train metric: 0.4681\n","Estimator 165/300, Train metric: 0.4681\n","Estimator 166/300, Train metric: 0.4681\n","Estimator 167/300, Train metric: 0.4681\n","Estimator 168/300, Train metric: 0.4681\n","Estimator 169/300, Train metric: 0.4681\n","Estimator 170/300, Train metric: 0.4681\n","Estimator 171/300, Train metric: 0.4681\n","Estimator 172/300, Train metric: 0.4681\n","Estimator 173/300, Train metric: 0.4681\n","Estimator 174/300, Train metric: 0.4681\n","Estimator 175/300, Train metric: 0.4681\n","Estimator 176/300, Train metric: 0.4681\n","Estimator 177/300, Train metric: 0.4681\n","Estimator 178/300, Train metric: 0.4681\n","Estimator 179/300, Train metric: 0.4681\n","Estimator 180/300, Train metric: 0.4681\n","Estimator 181/300, Train metric: 0.4681\n","Estimator 182/300, Train metric: 0.4681\n","Estimator 183/300, Train metric: 0.4681\n","Estimator 184/300, Train metric: 0.4681\n","Estimator 185/300, Train metric: 0.4681\n","Estimator 186/300, Train metric: 0.4681\n","Estimator 187/300, Train metric: 0.4681\n","Estimator 188/300, Train metric: 0.4681\n","Estimator 189/300, Train metric: 0.4681\n","Estimator 190/300, Train metric: 0.4681\n","Estimator 191/300, Train metric: 0.4681\n","Estimator 192/300, Train metric: 0.4681\n","Estimator 193/300, Train metric: 0.4681\n","Estimator 194/300, Train metric: 0.4681\n","Estimator 195/300, Train metric: 0.4681\n","Estimator 196/300, Train metric: 0.4681\n","Estimator 197/300, Train metric: 0.4681\n","Estimator 198/300, Train metric: 0.4681\n","Estimator 199/300, Train metric: 0.4681\n","Estimator 200/300, Train metric: 0.4681\n","Estimator 201/300, Train metric: 0.4681\n","Estimator 202/300, Train metric: 0.4681\n","Estimator 203/300, Train metric: 0.4681\n","Estimator 204/300, Train metric: 0.4681\n","Estimator 205/300, Train metric: 0.4681\n","Estimator 206/300, Train metric: 0.4681\n","Estimator 207/300, Train metric: 0.4681\n","Estimator 208/300, Train metric: 0.4681\n","Estimator 209/300, Train metric: 0.4681\n","Estimator 210/300, Train metric: 0.4681\n","Estimator 211/300, Train metric: 0.4681\n","Estimator 212/300, Train metric: 0.4681\n","Estimator 213/300, Train metric: 0.4681\n","Estimator 214/300, Train metric: 0.4681\n","Estimator 215/300, Train metric: 0.4681\n","Estimator 216/300, Train metric: 0.4681\n","Estimator 217/300, Train metric: 0.4681\n","Estimator 218/300, Train metric: 0.4681\n","Estimator 219/300, Train metric: 0.4681\n","Estimator 220/300, Train metric: 0.4681\n","Estimator 221/300, Train metric: 0.4681\n","Estimator 222/300, Train metric: 0.4681\n","Estimator 223/300, Train metric: 0.4681\n","Estimator 224/300, Train metric: 0.4681\n","Estimator 225/300, Train metric: 0.4681\n","Estimator 226/300, Train metric: 0.4681\n","Estimator 227/300, Train metric: 0.4681\n","Estimator 228/300, Train metric: 0.4681\n","Estimator 229/300, Train metric: 0.4681\n","Estimator 230/300, Train metric: 0.4681\n","Estimator 231/300, Train metric: 0.4681\n","Estimator 232/300, Train metric: 0.4681\n","Estimator 233/300, Train metric: 0.4681\n","Estimator 234/300, Train metric: 0.4681\n","Estimator 235/300, Train metric: 0.4681\n","Estimator 236/300, Train metric: 0.4681\n","Estimator 237/300, Train metric: 0.4681\n","Estimator 238/300, Train metric: 0.4681\n","Estimator 239/300, Train metric: 0.4681\n","Estimator 240/300, Train metric: 0.4681\n","Estimator 241/300, Train metric: 0.4681\n","Estimator 242/300, Train metric: 0.4681\n","Estimator 243/300, Train metric: 0.4681\n","Estimator 244/300, Train metric: 0.4681\n","Estimator 245/300, Train metric: 0.4681\n","Estimator 246/300, Train metric: 0.4681\n","Estimator 247/300, Train metric: 0.4681\n","Estimator 248/300, Train metric: 0.4681\n","Estimator 249/300, Train metric: 0.4681\n","Estimator 250/300, Train metric: 0.4681\n","Estimator 251/300, Train metric: 0.4681\n","Estimator 252/300, Train metric: 0.4681\n","Estimator 253/300, Train metric: 0.4681\n","Estimator 254/300, Train metric: 0.4681\n","Estimator 255/300, Train metric: 0.4681\n","Estimator 256/300, Train metric: 0.4681\n","Estimator 257/300, Train metric: 0.4681\n","Estimator 258/300, Train metric: 0.4681\n","Estimator 259/300, Train metric: 0.4681\n","Estimator 260/300, Train metric: 0.4681\n","Estimator 261/300, Train metric: 0.4681\n","Estimator 262/300, Train metric: 0.4681\n","Estimator 263/300, Train metric: 0.4681\n","Estimator 264/300, Train metric: 0.4681\n","Estimator 265/300, Train metric: 0.4681\n","Estimator 266/300, Train metric: 0.4681\n","Estimator 267/300, Train metric: 0.4681\n","Estimator 268/300, Train metric: 0.4681\n","Estimator 269/300, Train metric: 0.4681\n","Estimator 270/300, Train metric: 0.4681\n","Estimator 271/300, Train metric: 0.4681\n","Estimator 272/300, Train metric: 0.4681\n","Estimator 273/300, Train metric: 0.4681\n","Estimator 274/300, Train metric: 0.4681\n","Estimator 275/300, Train metric: 0.4681\n","Estimator 276/300, Train metric: 0.4681\n","Estimator 277/300, Train metric: 0.4681\n","Estimator 278/300, Train metric: 0.4681\n","Estimator 279/300, Train metric: 0.4681\n","Estimator 280/300, Train metric: 0.4681\n","Estimator 281/300, Train metric: 0.4681\n","Estimator 282/300, Train metric: 0.4681\n","Estimator 283/300, Train metric: 0.4681\n","Estimator 284/300, Train metric: 0.4681\n","Estimator 285/300, Train metric: 0.4681\n","Estimator 286/300, Train metric: 0.4681\n","Estimator 287/300, Train metric: 0.4681\n","Estimator 288/300, Train metric: 0.4681\n","Estimator 289/300, Train metric: 0.4681\n","Estimator 290/300, Train metric: 0.4681\n","Estimator 291/300, Train metric: 0.4681\n","Estimator 292/300, Train metric: 0.4681\n","Estimator 293/300, Train metric: 0.4681\n","Estimator 294/300, Train metric: 0.4681\n","Estimator 295/300, Train metric: 0.4681\n","Estimator 296/300, Train metric: 0.4681\n","Estimator 297/300, Train metric: 0.4681\n","Estimator 298/300, Train metric: 0.4681\n","Estimator 299/300, Train metric: 0.4681\n","Best MSE for PGBM with WilcoxonPruner: 0.17270380035294597 with params: {'n_estimators': 300, 'learning_rate': 0.15, 'max_leaves': 23, 'min_split_gain': 0.5, 'reg_lambda': 5.0, 'feature_fraction': 0.5, 'bagging_fraction': 1.0, 'tree_correlation': 0.3, 'min_data_in_leaf': 10, 'max_bin': 256, 'distribution': 'laplace'}\n","Best RMSE for PGBM with WilcoxonPruner: 0.4155764675158424\n","Correlation Coefficient for PGBM with WilcoxonPruner: 0.9558650240359587\n","\n","Best model on test data: NGBoost with MedianPruner\n","Test MSE: 0.09504486262561934\n","Test RMSE: 0.3082934683473189\n","Correlation Coefficient: 0.9728706600673735\n","Best Parameters: {'n_estimators': 500, 'learning_rate': 0.1, 'natural_gradient': False, 'minibatch_frac': 0.7, 'col_sample': 0.9, 'Dist': <class 'ngboost.distns.normal.Normal'>, 'Score': <class 'ngboost.scores.LogScore'>, 'random_state': 42, 'verbose': 0}\n","Pruner Used: MedianPruner\n"]}]},{"cell_type":"code","source":["best_scores_autosampler"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AdWxwbpGUSf1","executionInfo":{"status":"ok","timestamp":1750418890711,"user_tz":-330,"elapsed":166,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}},"outputId":"c4fc254a-003a-4a3e-aafc-ff8b9242e68a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{('Random Forest', 'MedianPruner'): {'best_score': 0.1277468464583334,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'absolute_error',\n","   'max_depth': 20,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 0.3,\n","   'max_leaf_nodes': 50,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.05},\n","  'test_mse': 0.1277468464583334,\n","  'test_rmse': 0.3574169084673155,\n","  'test_corr_coef': 0.9707276604980959,\n","  'pruner': 'MedianPruner'},\n"," ('Random Forest', 'NopPruner'): {'best_score': 0.14842459697916685,\n","  'best_params': {'n_estimators': 300,\n","   'criterion': 'absolute_error',\n","   'max_depth': 10,\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.1,\n","   'max_features': 'sqrt',\n","   'max_leaf_nodes': None,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.14842459697916685,\n","  'test_rmse': 0.3852591296506377,\n","  'test_corr_coef': 0.9629339388824938,\n","  'pruner': 'NopPruner'},\n"," ('Random Forest', 'PatientPruner'): {'best_score': 0.12419639091145714,\n","  'best_params': {'n_estimators': 200,\n","   'criterion': 'absolute_error',\n","   'max_depth': None,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.05},\n","  'test_mse': 0.12419639091145714,\n","  'test_rmse': 0.3524150832632694,\n","  'test_corr_coef': 0.9705007038236941,\n","  'pruner': 'PatientPruner'},\n"," ('Random Forest', 'PercentilePruner'): {'best_score': 0.12408228778645725,\n","  'best_params': {'n_estimators': 200,\n","   'criterion': 'absolute_error',\n","   'max_depth': 20,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_features': 'sqrt',\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.0,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.05},\n","  'test_mse': 0.12408228778645725,\n","  'test_rmse': 0.3522531586607241,\n","  'test_corr_coef': 0.9705179528060743,\n","  'pruner': 'PercentilePruner'},\n"," ('Random Forest',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.12957015505833472, 'best_params': {'n_estimators': 500,\n","   'criterion': 'absolute_error',\n","   'max_depth': 40,\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'log2',\n","   'max_leaf_nodes': 200,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.05}, 'test_mse': 0.12957015505833472, 'test_rmse': 0.35995854630545265, 'test_corr_coef': 0.9695351089387991, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('Random Forest', 'HyperbandPruner'): {'best_score': 0.14123529690104086,\n","  'best_params': {'n_estimators': 200,\n","   'criterion': 'absolute_error',\n","   'max_depth': 30,\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 5,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'sqrt',\n","   'max_leaf_nodes': 50,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.14123529690104086,\n","  'test_rmse': 0.3758128482383763,\n","  'test_corr_coef': 0.9650032328189053,\n","  'pruner': 'HyperbandPruner'},\n"," ('Random Forest', 'ThresholdPruner'): {'best_score': 0.12605156197916648,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'absolute_error',\n","   'max_depth': 20,\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'sqrt',\n","   'max_leaf_nodes': 100,\n","   'min_impurity_decrease': 0.01,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.12605156197916648,\n","  'test_rmse': 0.3550374092672017,\n","  'test_corr_coef': 0.9709542703717455,\n","  'pruner': 'ThresholdPruner'},\n"," ('Random Forest', 'WilcoxonPruner'): {'best_score': 0.16566976091278687,\n","  'best_params': {'n_estimators': 100,\n","   'criterion': 'squared_error',\n","   'max_depth': 20,\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 0.01,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_features': 'sqrt',\n","   'max_leaf_nodes': None,\n","   'min_impurity_decrease': 0.1,\n","   'n_jobs': -1,\n","   'random_state': 42,\n","   'verbose': 0,\n","   'warm_start': False,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.16566976091278687,\n","  'test_rmse': 0.4070255040077794,\n","  'test_corr_coef': 0.9596894196995167,\n","  'pruner': 'WilcoxonPruner'},\n"," ('Gradient Boosting', 'MedianPruner'): {'best_score': 0.1475531564605347,\n","  'best_params': {'loss': 'huber',\n","   'learning_rate': 0.1,\n","   'n_estimators': 500,\n","   'subsample': 0.5,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 5,\n","   'min_weight_fraction_leaf': 0.05,\n","   'max_depth': 7,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': None,\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': 30,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.1475531564605347,\n","  'test_rmse': 0.3841264849766737,\n","  'test_corr_coef': 0.9594576979885481,\n","  'pruner': 'MedianPruner'},\n"," ('Gradient Boosting', 'NopPruner'): {'best_score': 0.11611736736385432,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.05,\n","   'n_estimators': 700,\n","   'subsample': 0.7,\n","   'criterion': 'squared_error',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.1,\n","   'max_depth': 3,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 30,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.11611736736385432,\n","  'test_rmse': 0.34075998498041743,\n","  'test_corr_coef': 0.970092988116921,\n","  'pruner': 'NopPruner'},\n"," ('Gradient Boosting', 'PatientPruner'): {'best_score': 0.11598078071820765,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.05,\n","   'n_estimators': 100,\n","   'subsample': 0.9,\n","   'criterion': 'squared_error',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 1,\n","   'min_weight_fraction_leaf': 0.1,\n","   'max_depth': 10,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.11598078071820765,\n","  'test_rmse': 0.340559511272564,\n","  'test_corr_coef': 0.9738912032521678,\n","  'pruner': 'PatientPruner'},\n"," ('Gradient Boosting', 'PercentilePruner'): {'best_score': 0.12843508528943917,\n","  'best_params': {'loss': 'quantile',\n","   'learning_rate': 0.01,\n","   'n_estimators': 300,\n","   'subsample': 0.5,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.1,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': None,\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 10,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.12843508528943917,\n","  'test_rmse': 0.3583784107468517,\n","  'test_corr_coef': 0.9760374747143572,\n","  'pruner': 'PercentilePruner'},\n"," ('Gradient Boosting',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.11506432498369613, 'best_params': {'loss': 'quantile',\n","   'learning_rate': 0.01,\n","   'n_estimators': 700,\n","   'subsample': 0.7,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.01,\n","   'max_depth': 3,\n","   'min_impurity_decrease': 0.1,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 30,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 20,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.001}, 'test_mse': 0.11506432498369613, 'test_rmse': 0.3392113279118139, 'test_corr_coef': 0.9712848440118512, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('Gradient Boosting', 'HyperbandPruner'): {'best_score': 0.11364424292251485,\n","  'best_params': {'loss': 'huber',\n","   'learning_rate': 0.01,\n","   'n_estimators': 500,\n","   'subsample': 0.7,\n","   'criterion': 'squared_error',\n","   'min_samples_split': 2,\n","   'min_samples_leaf': 5,\n","   'min_weight_fraction_leaf': 0.0,\n","   'max_depth': 10,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 0.5,\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': None,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': None,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.001},\n","  'test_mse': 0.11364424292251485,\n","  'test_rmse': 0.33711161789904964,\n","  'test_corr_coef': 0.9720469551788173,\n","  'pruner': 'HyperbandPruner'},\n"," ('Gradient Boosting', 'ThresholdPruner'): {'best_score': 0.1230870944926456,\n","  'best_params': {'loss': 'absolute_error',\n","   'learning_rate': 0.1,\n","   'n_estimators': 300,\n","   'subsample': 0.9,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 10,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.1,\n","   'max_depth': 5,\n","   'min_impurity_decrease': 0.0,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'sqrt',\n","   'alpha': 0.5,\n","   'verbose': 0,\n","   'max_leaf_nodes': 50,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.0001,\n","   'ccp_alpha': 0.01},\n","  'test_mse': 0.1230870944926456,\n","  'test_rmse': 0.35083770392112307,\n","  'test_corr_coef': 0.9689207287958194,\n","  'pruner': 'ThresholdPruner'},\n"," ('Gradient Boosting', 'WilcoxonPruner'): {'best_score': 0.12440493626931852,\n","  'best_params': {'loss': 'huber',\n","   'learning_rate': 0.1,\n","   'n_estimators': 200,\n","   'subsample': 0.5,\n","   'criterion': 'friedman_mse',\n","   'min_samples_split': 0.01,\n","   'min_samples_leaf': 3,\n","   'min_weight_fraction_leaf': 0.1,\n","   'max_depth': 10,\n","   'min_impurity_decrease': 0.01,\n","   'init': None,\n","   'random_state': 42,\n","   'max_features': 'log2',\n","   'alpha': 0.9,\n","   'verbose': 0,\n","   'max_leaf_nodes': 10,\n","   'warm_start': False,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 10,\n","   'tol': 0.001,\n","   'ccp_alpha': 0.0},\n","  'test_mse': 0.12440493626931852,\n","  'test_rmse': 0.35271083945537957,\n","  'test_corr_coef': 0.9690633574264977,\n","  'pruner': 'WilcoxonPruner'},\n"," ('XGBoost', 'MedianPruner'): {'best_score': 0.17170419710177898,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'max_depth': 7,\n","   'min_child_weight': 3,\n","   'gamma': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.5,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 10,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.17170419710177898,\n","  'test_rmse': 0.4143720515452013,\n","  'test_corr_coef': 0.9607256474135085,\n","  'pruner': 'MedianPruner'},\n"," ('XGBoost', 'NopPruner'): {'best_score': 0.18490542743528735,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0.1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 10,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.18490542743528735,\n","  'test_rmse': 0.430006310924953,\n","  'test_corr_coef': 0.9568726100915124,\n","  'pruner': 'NopPruner'},\n"," ('XGBoost', 'PatientPruner'): {'best_score': 0.17995853590726996,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_depth': 3,\n","   'min_child_weight': 5,\n","   'gamma': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 1,\n","   'reg_lambda': 10,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.17995853590726996,\n","  'test_rmse': 0.42421519999555646,\n","  'test_corr_coef': 0.956980205204565,\n","  'pruner': 'PatientPruner'},\n"," ('XGBoost', 'PercentilePruner'): {'best_score': 0.20558211819201722,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.05,\n","   'max_depth': 3,\n","   'min_child_weight': 1,\n","   'gamma': 1,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.5,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 5,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.20558211819201722,\n","  'test_rmse': 0.45341164320296984,\n","  'test_corr_coef': 0.9511658209169824,\n","  'pruner': 'PercentilePruner'},\n"," ('XGBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.1969894230295611,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.01,\n","   'max_depth': 7,\n","   'min_child_weight': 1,\n","   'gamma': 0.1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.5,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 1,\n","   'reg_lambda': 0.1,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.1969894230295611,\n","  'test_rmse': 0.44383490515005813,\n","  'test_corr_coef': 0.9547894948664724,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('XGBoost', 'HyperbandPruner'): {'best_score': 0.18140968628433582,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'max_depth': 5,\n","   'min_child_weight': 3,\n","   'gamma': 0.1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.5,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 5,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.18140968628433582,\n","  'test_rmse': 0.4259221598887945,\n","  'test_corr_coef': 0.9572801854066274,\n","  'pruner': 'HyperbandPruner'},\n"," ('XGBoost', 'ThresholdPruner'): {'best_score': 0.18764774972827566,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'max_depth': 3,\n","   'min_child_weight': 5,\n","   'gamma': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'colsample_bylevel': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 10,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.18764774972827566,\n","  'test_rmse': 0.43318327498678394,\n","  'test_corr_coef': 0.9566386914670973,\n","  'pruner': 'ThresholdPruner'},\n"," ('XGBoost', 'WilcoxonPruner'): {'best_score': 0.18603178163690948,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'max_depth': 3,\n","   'min_child_weight': 1,\n","   'gamma': 0.5,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.7,\n","   'colsample_bylevel': 0.5,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 5,\n","   'objective': 'reg:squarederror',\n","   'random_state': 42,\n","   'n_jobs': -1},\n","  'test_mse': 0.18603178163690948,\n","  'test_rmse': 0.43131401743614767,\n","  'test_corr_coef': 0.9572878786872289,\n","  'pruner': 'WilcoxonPruner'},\n"," ('LightGBM', 'MedianPruner'): {'best_score': 0.2083364060730614,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.01,\n","   'num_leaves': 15,\n","   'max_depth': -1,\n","   'min_child_samples': 10,\n","   'subsample': 0.7,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.1,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.2083364060730614,\n","  'test_rmse': 0.4564388305929518,\n","  'test_corr_coef': 0.9498750983478396,\n","  'pruner': 'MedianPruner'},\n"," ('LightGBM', 'NopPruner'): {'best_score': 0.193068876020293,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'num_leaves': 31,\n","   'max_depth': 7,\n","   'min_child_samples': 1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0,\n","   'reg_lambda': 10,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.193068876020293,\n","  'test_rmse': 0.4393960355081655,\n","  'test_corr_coef': 0.9548082997434436,\n","  'pruner': 'NopPruner'},\n"," ('LightGBM', 'PatientPruner'): {'best_score': 0.1953962186539332,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'num_leaves': 15,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 1,\n","   'reg_lambda': 10,\n","   'min_child_weight': 1e-05,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.1953962186539332,\n","  'test_rmse': 0.44203644493857425,\n","  'test_corr_coef': 0.9508141956595607,\n","  'pruner': 'PatientPruner'},\n"," ('LightGBM', 'PercentilePruner'): {'best_score': 0.2460844970001943,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'num_leaves': 31,\n","   'max_depth': 3,\n","   'min_child_samples': 20,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 0.01,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 0,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.2460844970001943,\n","  'test_rmse': 0.496069044589757,\n","  'test_corr_coef': 0.9312533658049154,\n","  'pruner': 'PercentilePruner'},\n"," ('LightGBM', 'SuccessiveHalvingPruner'): {'best_score': 0.2036941580271234,\n","  'best_params': {'n_estimators': 400,\n","   'learning_rate': 0.01,\n","   'num_leaves': 15,\n","   'max_depth': 5,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 10,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.2036941580271234,\n","  'test_rmse': 0.45132489187626623,\n","  'test_corr_coef': 0.9514856189721617,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('LightGBM', 'HyperbandPruner'): {'best_score': 0.21148179615800702,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.01,\n","   'num_leaves': 63,\n","   'max_depth': -1,\n","   'min_child_samples': 10,\n","   'subsample': 0.9,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'bagging_freq': 5,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.21148179615800702,\n","  'test_rmse': 0.4598714996148457,\n","  'test_corr_coef': 0.949662555232054,\n","  'pruner': 'HyperbandPruner'},\n"," ('LightGBM', 'ThresholdPruner'): {'best_score': 0.19382677405571272,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'num_leaves': 15,\n","   'max_depth': 7,\n","   'min_child_samples': 1,\n","   'subsample': 0.6,\n","   'colsample_bytree': 0.7,\n","   'reg_alpha': 1,\n","   'reg_lambda': 10,\n","   'min_child_weight': 0.1,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.19382677405571272,\n","  'test_rmse': 0.44025762237093946,\n","  'test_corr_coef': 0.9527311939790231,\n","  'pruner': 'ThresholdPruner'},\n"," ('LightGBM', 'WilcoxonPruner'): {'best_score': 0.19441841092141496,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'num_leaves': 31,\n","   'max_depth': -1,\n","   'min_child_samples': 5,\n","   'subsample': 0.7,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 1,\n","   'reg_lambda': 10,\n","   'min_child_weight': 1e-05,\n","   'bagging_freq': 1,\n","   'objective': 'regression',\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.19441841092141496,\n","  'test_rmse': 0.4409290316155367,\n","  'test_corr_coef': 0.9504497189384022,\n","  'pruner': 'WilcoxonPruner'},\n"," ('GPBoost', 'MedianPruner'): {'best_score': 0.24538762445047077,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': 7,\n","   'num_leaves': 63,\n","   'min_child_samples': 20,\n","   'subsample': 1.0,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.01,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.24538762445047077,\n","  'test_rmse': 0.495366151902278,\n","  'test_corr_coef': 0.9315384098485758,\n","  'pruner': 'MedianPruner'},\n"," ('GPBoost', 'NopPruner'): {'best_score': 0.2458047001956276,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.01,\n","   'max_depth': 3,\n","   'num_leaves': 63,\n","   'min_child_samples': 20,\n","   'subsample': 0.8,\n","   'colsample_bytree': 1.0,\n","   'reg_alpha': 0.1,\n","   'reg_lambda': 0,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.2458047001956276,\n","  'test_rmse': 0.49578695040876947,\n","  'test_corr_coef': 0.9312589640936391,\n","  'pruner': 'NopPruner'},\n"," ('GPBoost', 'PatientPruner'): {'best_score': 0.23924970633895856,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'max_depth': 7,\n","   'num_leaves': 63,\n","   'min_child_samples': 20,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 0.001,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.23924970633895856,\n","  'test_rmse': 0.4891315838697789,\n","  'test_corr_coef': 0.9335047827151202,\n","  'pruner': 'PatientPruner'},\n"," ('GPBoost', 'PercentilePruner'): {'best_score': 0.21410524780675688,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.01,\n","   'max_depth': 7,\n","   'num_leaves': 31,\n","   'min_child_samples': 10,\n","   'subsample': 0.7,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.5,\n","   'reg_lambda': 0.5,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.21410524780675688,\n","  'test_rmse': 0.46271508275261236,\n","  'test_corr_coef': 0.9482169600842357,\n","  'pruner': 'PercentilePruner'},\n"," ('GPBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.21432952386392556,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.01,\n","   'max_depth': 5,\n","   'num_leaves': 31,\n","   'min_child_samples': 10,\n","   'subsample': 0.7,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.5,\n","   'reg_lambda': 0,\n","   'min_child_weight': 0.1,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.21432952386392556,\n","  'test_rmse': 0.4629573672207038,\n","  'test_corr_coef': 0.9482138594080257,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('GPBoost', 'HyperbandPruner'): {'best_score': 0.21341642160636554,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.01,\n","   'max_depth': 5,\n","   'num_leaves': 31,\n","   'min_child_samples': 10,\n","   'subsample': 0.7,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 0.5,\n","   'reg_lambda': 1.0,\n","   'min_child_weight': 0.01,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.21341642160636554,\n","  'test_rmse': 0.4619701522894802,\n","  'test_corr_coef': 0.9485463939108688,\n","  'pruner': 'HyperbandPruner'},\n"," ('GPBoost', 'ThresholdPruner'): {'best_score': 0.25151641817016107,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 20,\n","   'subsample': 0.5,\n","   'colsample_bytree': 0.5,\n","   'reg_alpha': 1.0,\n","   'reg_lambda': 0,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.25151641817016107,\n","  'test_rmse': 0.5015141255938471,\n","  'test_corr_coef': 0.929405761058553,\n","  'pruner': 'ThresholdPruner'},\n"," ('GPBoost', 'WilcoxonPruner'): {'best_score': 0.2318601807817072,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.01,\n","   'max_depth': 3,\n","   'num_leaves': 15,\n","   'min_child_samples': 10,\n","   'subsample': 0.8,\n","   'colsample_bytree': 0.9,\n","   'reg_alpha': 1.0,\n","   'reg_lambda': 0.1,\n","   'min_child_weight': 1e-05,\n","   'random_state': 42,\n","   'n_jobs': -1,\n","   'verbose': -1},\n","  'test_mse': 0.2318601807817072,\n","  'test_rmse': 0.4815186193510145,\n","  'test_corr_coef': 0.9428019827117433,\n","  'pruner': 'WilcoxonPruner'},\n"," ('CatBoost', 'MedianPruner'): {'best_score': 0.1876633039227785,\n","  'best_params': {'iterations': 500,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 1.0,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1876633039227785,\n","  'test_rmse': 0.4332012279793058,\n","  'test_corr_coef': 0.9505985870988952,\n","  'pruner': 'MedianPruner'},\n"," ('CatBoost', 'NopPruner'): {'best_score': 0.20786129556860278,\n","  'best_params': {'iterations': 500,\n","   'learning_rate': 0.01,\n","   'depth': 6,\n","   'l2_leaf_reg': 5,\n","   'border_count': 128,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.20786129556860278,\n","  'test_rmse': 0.45591807988782673,\n","  'test_corr_coef': 0.9431902327536595,\n","  'pruner': 'NopPruner'},\n"," ('CatBoost', 'PatientPruner'): {'best_score': 0.21136792731806056,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.03,\n","   'depth': 4,\n","   'l2_leaf_reg': 9,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 0.6,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.21136792731806056,\n","  'test_rmse': 0.4597476778821842,\n","  'test_corr_coef': 0.9442624292857775,\n","  'pruner': 'PatientPruner'},\n"," ('CatBoost', 'PercentilePruner'): {'best_score': 0.1876633039227785,\n","  'best_params': {'iterations': 500,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 32,\n","   'min_data_in_leaf': 20,\n","   'rsm': 1.0,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1876633039227785,\n","  'test_rmse': 0.4332012279793058,\n","  'test_corr_coef': 0.9505985870988952,\n","  'pruner': 'PercentilePruner'},\n"," ('CatBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.16955476359331176,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 64,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.8,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.16955476359331176,\n","  'test_rmse': 0.411770280123896,\n","  'test_corr_coef': 0.9545229535961917,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('CatBoost', 'HyperbandPruner'): {'best_score': 0.18766330467457562,\n","  'best_params': {'iterations': 1000,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 32,\n","   'min_data_in_leaf': 1,\n","   'rsm': 1.0,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.18766330467457562,\n","  'test_rmse': 0.43320122884702855,\n","  'test_corr_coef': 0.9505985837797406,\n","  'pruner': 'HyperbandPruner'},\n"," ('CatBoost', 'ThresholdPruner'): {'best_score': 0.16958500552464362,\n","  'best_params': {'iterations': 500,\n","   'learning_rate': 0.1,\n","   'depth': 10,\n","   'l2_leaf_reg': 1,\n","   'border_count': 64,\n","   'min_data_in_leaf': 20,\n","   'rsm': 0.8,\n","   'bagging_temperature': 0,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.16958500552464362,\n","  'test_rmse': 0.4118070003346757,\n","  'test_corr_coef': 0.9545297513334484,\n","  'pruner': 'ThresholdPruner'},\n"," ('CatBoost', 'WilcoxonPruner'): {'best_score': 0.2185595484526247,\n","  'best_params': {'iterations': 200,\n","   'learning_rate': 0.03,\n","   'depth': 8,\n","   'l2_leaf_reg': 3,\n","   'border_count': 64,\n","   'min_data_in_leaf': 20,\n","   'rsm': 1.0,\n","   'bagging_temperature': 10,\n","   'random_seed': 42,\n","   'verbose': 0},\n","  'test_mse': 0.2185595484526247,\n","  'test_rmse': 0.46750352774350773,\n","  'test_corr_coef': 0.9392465923252853,\n","  'pruner': 'WilcoxonPruner'},\n"," ('NGBoost', 'MedianPruner'): {'best_score': 0.09504486262561934,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.09504486262561934,\n","  'test_rmse': 0.3082934683473189,\n","  'test_corr_coef': 0.9728706600673735,\n","  'pruner': 'MedianPruner'},\n"," ('NGBoost', 'NopPruner'): {'best_score': 0.13749530079773292,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.13749530079773292,\n","  'test_rmse': 0.37080358789759965,\n","  'test_corr_coef': 0.9634991101104033,\n","  'pruner': 'NopPruner'},\n"," ('NGBoost', 'PatientPruner'): {'best_score': 0.1190552270631217,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.1190552270631217,\n","  'test_rmse': 0.3450438045569312,\n","  'test_corr_coef': 0.9679534662898801,\n","  'pruner': 'PatientPruner'},\n"," ('NGBoost', 'PercentilePruner'): {'best_score': 0.10889296232715207,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10889296232715207,\n","  'test_rmse': 0.3299893366870391,\n","  'test_corr_coef': 0.9720818248033533,\n","  'pruner': 'PercentilePruner'},\n"," ('NGBoost', 'SuccessiveHalvingPruner'): {'best_score': 0.10532323931129806,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10532323931129806,\n","  'test_rmse': 0.32453542073446784,\n","  'test_corr_coef': 0.9732927978429206,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('NGBoost', 'HyperbandPruner'): {'best_score': 0.11685799834435291,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.05,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.11685799834435291,\n","  'test_rmse': 0.3418449916911946,\n","  'test_corr_coef': 0.9747460538503312,\n","  'pruner': 'HyperbandPruner'},\n"," ('NGBoost', 'ThresholdPruner'): {'best_score': 0.11273045675857192,\n","  'best_params': {'n_estimators': 1000,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.11273045675857192,\n","  'test_rmse': 0.3357535655187774,\n","  'test_corr_coef': 0.9715119083891562,\n","  'pruner': 'ThresholdPruner'},\n"," ('NGBoost', 'WilcoxonPruner'): {'best_score': 0.10902047014845206,\n","  'best_params': {'n_estimators': 500,\n","   'learning_rate': 0.1,\n","   'natural_gradient': False,\n","   'minibatch_frac': 0.7,\n","   'col_sample': 0.9,\n","   'Dist': ngboost.distns.normal.Normal,\n","   'Score': ngboost.scores.LogScore,\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.10902047014845206,\n","  'test_rmse': 0.3301824800749611,\n","  'test_corr_coef': 0.9702968236904361,\n","  'pruner': 'WilcoxonPruner'},\n"," ('HistGradientBoosting', 'MedianPruner'): {'best_score': 0.20339129262913583,\n","  'best_params': {'learning_rate': 0.01,\n","   'max_iter': 200,\n","   'max_depth': 5,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 63,\n","   'l2_regularization': 0.0,\n","   'max_bins': 128,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.20339129262913583,\n","  'test_rmse': 0.45098923781963557,\n","  'test_corr_coef': 0.9531686203054556,\n","  'pruner': 'MedianPruner'},\n"," ('HistGradientBoosting', 'NopPruner'): {'best_score': 0.21131535430654258,\n","  'best_params': {'learning_rate': 0.01,\n","   'max_iter': 200,\n","   'max_depth': 5,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.5,\n","   'max_bins': 255,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.21131535430654258,\n","  'test_rmse': 0.45969049838618875,\n","  'test_corr_coef': 0.9511371258201152,\n","  'pruner': 'NopPruner'},\n"," ('HistGradientBoosting', 'PatientPruner'): {'best_score': 0.22025310759770758,\n","  'best_params': {'learning_rate': 0.01,\n","   'max_iter': 300,\n","   'max_depth': 7,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.1,\n","   'max_bins': 255,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 10,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0},\n","  'test_mse': 0.22025310759770758,\n","  'test_rmse': 0.46931131202828213,\n","  'test_corr_coef': 0.9525247884036877,\n","  'pruner': 'PatientPruner'},\n"," ('HistGradientBoosting',\n","  'PercentilePruner'): {'best_score': 0.2052831927048833, 'best_params': {'learning_rate': 0.01,\n","   'max_iter': 400,\n","   'max_depth': 3,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.0,\n","   'max_bins': 255,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.2052831927048833, 'test_rmse': 0.4530818830022707, 'test_corr_coef': 0.9541777770389761, 'pruner': 'PercentilePruner'},\n"," ('HistGradientBoosting',\n","  'SuccessiveHalvingPruner'): {'best_score': 0.20339129262913583, 'best_params': {'learning_rate': 0.01,\n","   'max_iter': 200,\n","   'max_depth': 7,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 0.0,\n","   'max_bins': 128,\n","   'early_stopping': True,\n","   'validation_fraction': 0.1,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.20339129262913583, 'test_rmse': 0.45098923781963557, 'test_corr_coef': 0.9531686203054556, 'pruner': 'SuccessiveHalvingPruner'},\n"," ('HistGradientBoosting',\n","  'HyperbandPruner'): {'best_score': 0.22459983108232093, 'best_params': {'learning_rate': 0.1,\n","   'max_iter': 500,\n","   'max_depth': 7,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': None,\n","   'l2_regularization': 0.1,\n","   'max_bins': 255,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.22459983108232093, 'test_rmse': 0.4739196462295279, 'test_corr_coef': 0.950340907988903, 'pruner': 'HyperbandPruner'},\n"," ('HistGradientBoosting',\n","  'ThresholdPruner'): {'best_score': 0.2111932525133927, 'best_params': {'learning_rate': 0.01,\n","   'max_iter': 200,\n","   'max_depth': None,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 15,\n","   'l2_regularization': 0.0,\n","   'max_bins': 64,\n","   'early_stopping': False,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.2111932525133927, 'test_rmse': 0.45955767049783064, 'test_corr_coef': 0.9484835964617143, 'pruner': 'ThresholdPruner'},\n"," ('HistGradientBoosting',\n","  'WilcoxonPruner'): {'best_score': 0.20961745590758593, 'best_params': {'learning_rate': 0.01,\n","   'max_iter': 300,\n","   'max_depth': 3,\n","   'min_samples_leaf': 10,\n","   'max_leaf_nodes': 31,\n","   'l2_regularization': 1.0,\n","   'max_bins': 128,\n","   'early_stopping': True,\n","   'validation_fraction': 0.2,\n","   'n_iter_no_change': 5,\n","   'loss': 'squared_error',\n","   'random_state': 42,\n","   'verbose': 0}, 'test_mse': 0.20961745590758593, 'test_rmse': 0.45783998941506404, 'test_corr_coef': 0.9531114281829953, 'pruner': 'WilcoxonPruner'},\n"," ('PGBM', 'MedianPruner'): {'best_score': 0.18817443349630766,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.15,\n","   'max_leaves': 37,\n","   'min_split_gain': 1.0,\n","   'reg_lambda': 10.0,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 0.9,\n","   'tree_correlation': 0.1,\n","   'min_data_in_leaf': 5,\n","   'max_bin': 64,\n","   'distribution': 'normal'},\n","  'test_mse': 0.18817443349630766,\n","  'test_rmse': 0.43379077156655566,\n","  'test_corr_coef': 0.9550325886698825,\n","  'pruner': 'MedianPruner'},\n"," ('PGBM', 'NopPruner'): {'best_score': 0.18733663750305285,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.05,\n","   'max_leaves': 45,\n","   'min_split_gain': 1.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.9,\n","   'bagging_fraction': 0.9,\n","   'tree_correlation': 0.0,\n","   'min_data_in_leaf': 10,\n","   'max_bin': 256,\n","   'distribution': 'normal'},\n","  'test_mse': 0.18733663750305285,\n","  'test_rmse': 0.4328240260233399,\n","  'test_corr_coef': 0.9545861333357423,\n","  'pruner': 'NopPruner'},\n"," ('PGBM', 'PatientPruner'): {'best_score': 0.16692777023205455,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_leaves': 36,\n","   'min_split_gain': 1.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 10,\n","   'max_bin': 128,\n","   'distribution': 'normal'},\n","  'test_mse': 0.16692777023205455,\n","  'test_rmse': 0.40856795056887973,\n","  'test_corr_coef': 0.9566086213516656,\n","  'pruner': 'PatientPruner'},\n"," ('PGBM', 'PercentilePruner'): {'best_score': 0.1650769864545701,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.15,\n","   'max_leaves': 60,\n","   'min_split_gain': 1.0,\n","   'reg_lambda': 0.1,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.1,\n","   'min_data_in_leaf': 10,\n","   'max_bin': 128,\n","   'distribution': 'normal'},\n","  'test_mse': 0.1650769864545701,\n","  'test_rmse': 0.4062966729553297,\n","  'test_corr_coef': 0.9578416038071123,\n","  'pruner': 'PercentilePruner'},\n"," ('PGBM', 'SuccessiveHalvingPruner'): {'best_score': 0.17175091924260685,\n","  'best_params': {'n_estimators': 200,\n","   'learning_rate': 0.1,\n","   'max_leaves': 31,\n","   'min_split_gain': 1.0,\n","   'reg_lambda': 1.0,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 0.9,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 256,\n","   'distribution': 'normal'},\n","  'test_mse': 0.17175091924260685,\n","  'test_rmse': 0.41442842475222047,\n","  'test_corr_coef': 0.9576307624183943,\n","  'pruner': 'SuccessiveHalvingPruner'},\n"," ('PGBM', 'HyperbandPruner'): {'best_score': 0.1716273503321355,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.15,\n","   'max_leaves': 21,\n","   'min_split_gain': 1.0,\n","   'reg_lambda': 10.0,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 0.9,\n","   'tree_correlation': 0.2,\n","   'min_data_in_leaf': 3,\n","   'max_bin': 128,\n","   'distribution': 'studentt'},\n","  'test_mse': 0.1716273503321355,\n","  'test_rmse': 0.4142793143908292,\n","  'test_corr_coef': 0.9578613917333262,\n","  'pruner': 'HyperbandPruner'},\n"," ('PGBM', 'ThresholdPruner'): {'best_score': 0.19552682861046522,\n","  'best_params': {'n_estimators': 100,\n","   'learning_rate': 0.1,\n","   'max_leaves': 34,\n","   'min_split_gain': 0.5,\n","   'reg_lambda': 10.0,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 0.9,\n","   'tree_correlation': 0.2,\n","   'min_data_in_leaf': 5,\n","   'max_bin': 128,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.19552682861046522,\n","  'test_rmse': 0.4421841568967224,\n","  'test_corr_coef': 0.9540042092051298,\n","  'pruner': 'ThresholdPruner'},\n"," ('PGBM', 'WilcoxonPruner'): {'best_score': 0.17270380035294597,\n","  'best_params': {'n_estimators': 300,\n","   'learning_rate': 0.15,\n","   'max_leaves': 23,\n","   'min_split_gain': 0.5,\n","   'reg_lambda': 5.0,\n","   'feature_fraction': 0.5,\n","   'bagging_fraction': 1.0,\n","   'tree_correlation': 0.3,\n","   'min_data_in_leaf': 10,\n","   'max_bin': 256,\n","   'distribution': 'laplace'},\n","  'test_mse': 0.17270380035294597,\n","  'test_rmse': 0.4155764675158424,\n","  'test_corr_coef': 0.9558650240359587,\n","  'pruner': 'WilcoxonPruner'}}"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","metadata":{"id":"N9uWqgUD3pKn"},"source":["# **Best Model Analysis**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QifO8ipK2ZdZ","executionInfo":{"status":"ok","timestamp":1750418899020,"user_tz":-330,"elapsed":8309,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d652f5cd-3d5c-4c4f-d5e4-2daa1be3d44c"},"outputs":[{"output_type":"stream","name":"stdout","text":["0:\tlearn: 1.2955313\ttotal: 13.3ms\tremaining: 2.65s\n","1:\tlearn: 1.2058519\ttotal: 16.2ms\tremaining: 1.6s\n","2:\tlearn: 1.1312129\ttotal: 16.4ms\tremaining: 1.08s\n","3:\tlearn: 1.0551979\ttotal: 16.6ms\tremaining: 812ms\n","4:\tlearn: 0.9818826\ttotal: 19.1ms\tremaining: 743ms\n","5:\tlearn: 0.9225493\ttotal: 21.3ms\tremaining: 688ms\n","6:\tlearn: 0.8620153\ttotal: 23.6ms\tremaining: 650ms\n","7:\tlearn: 0.8132285\ttotal: 24.3ms\tremaining: 583ms\n","8:\tlearn: 0.7799708\ttotal: 24.4ms\tremaining: 518ms\n","9:\tlearn: 0.7418039\ttotal: 26.8ms\tremaining: 509ms\n","10:\tlearn: 0.7012939\ttotal: 29.1ms\tremaining: 500ms\n","11:\tlearn: 0.6644196\ttotal: 31.2ms\tremaining: 489ms\n","12:\tlearn: 0.6230984\ttotal: 33.9ms\tremaining: 487ms\n","13:\tlearn: 0.5879711\ttotal: 34.5ms\tremaining: 459ms\n","14:\tlearn: 0.5573846\ttotal: 36.6ms\tremaining: 451ms\n","15:\tlearn: 0.5308579\ttotal: 37.8ms\tremaining: 434ms\n","16:\tlearn: 0.5054668\ttotal: 39.7ms\tremaining: 428ms\n","17:\tlearn: 0.4801889\ttotal: 42ms\tremaining: 424ms\n","18:\tlearn: 0.4573243\ttotal: 42.4ms\tremaining: 404ms\n","19:\tlearn: 0.4350941\ttotal: 42.9ms\tremaining: 386ms\n","20:\tlearn: 0.4134359\ttotal: 45.6ms\tremaining: 389ms\n","21:\tlearn: 0.3955072\ttotal: 47.7ms\tremaining: 386ms\n","22:\tlearn: 0.3793472\ttotal: 48ms\tremaining: 369ms\n","23:\tlearn: 0.3616199\ttotal: 50.5ms\tremaining: 370ms\n","24:\tlearn: 0.3459902\ttotal: 52.8ms\tremaining: 370ms\n","25:\tlearn: 0.3316608\ttotal: 54.9ms\tremaining: 368ms\n","26:\tlearn: 0.3184717\ttotal: 57.5ms\tremaining: 369ms\n","27:\tlearn: 0.3041561\ttotal: 59.9ms\tremaining: 368ms\n","28:\tlearn: 0.2917670\ttotal: 60.7ms\tremaining: 358ms\n","29:\tlearn: 0.2800414\ttotal: 63ms\tremaining: 357ms\n","30:\tlearn: 0.2658969\ttotal: 65.4ms\tremaining: 357ms\n","31:\tlearn: 0.2536077\ttotal: 67.5ms\tremaining: 355ms\n","32:\tlearn: 0.2431892\ttotal: 70ms\tremaining: 354ms\n","33:\tlearn: 0.2347889\ttotal: 72.1ms\tremaining: 352ms\n","34:\tlearn: 0.2245274\ttotal: 74ms\tremaining: 349ms\n","35:\tlearn: 0.2160892\ttotal: 76.2ms\tremaining: 347ms\n","36:\tlearn: 0.2059659\ttotal: 78ms\tremaining: 344ms\n","37:\tlearn: 0.1991439\ttotal: 80.3ms\tremaining: 342ms\n","38:\tlearn: 0.1909001\ttotal: 82.6ms\tremaining: 341ms\n","39:\tlearn: 0.1846352\ttotal: 84.6ms\tremaining: 338ms\n","40:\tlearn: 0.1785812\ttotal: 86.6ms\tremaining: 336ms\n","41:\tlearn: 0.1734449\ttotal: 88.3ms\tremaining: 332ms\n","42:\tlearn: 0.1665515\ttotal: 90.7ms\tremaining: 331ms\n","43:\tlearn: 0.1595165\ttotal: 92.6ms\tremaining: 328ms\n","44:\tlearn: 0.1539533\ttotal: 94.6ms\tremaining: 326ms\n","45:\tlearn: 0.1475368\ttotal: 96.3ms\tremaining: 322ms\n","46:\tlearn: 0.1426584\ttotal: 98.3ms\tremaining: 320ms\n","47:\tlearn: 0.1388226\ttotal: 99.1ms\tremaining: 314ms\n","48:\tlearn: 0.1347486\ttotal: 101ms\tremaining: 312ms\n","49:\tlearn: 0.1299161\ttotal: 103ms\tremaining: 310ms\n","50:\tlearn: 0.1252432\ttotal: 106ms\tremaining: 308ms\n","51:\tlearn: 0.1211457\ttotal: 108ms\tremaining: 306ms\n","52:\tlearn: 0.1172439\ttotal: 110ms\tremaining: 304ms\n","53:\tlearn: 0.1128198\ttotal: 112ms\tremaining: 303ms\n","54:\tlearn: 0.1093017\ttotal: 114ms\tremaining: 301ms\n","55:\tlearn: 0.1062802\ttotal: 116ms\tremaining: 299ms\n","56:\tlearn: 0.1044317\ttotal: 117ms\tremaining: 293ms\n","57:\tlearn: 0.1005209\ttotal: 119ms\tremaining: 292ms\n","58:\tlearn: 0.0972738\ttotal: 121ms\tremaining: 289ms\n","59:\tlearn: 0.0938871\ttotal: 123ms\tremaining: 288ms\n","60:\tlearn: 0.0907945\ttotal: 126ms\tremaining: 287ms\n","61:\tlearn: 0.0873568\ttotal: 128ms\tremaining: 285ms\n","62:\tlearn: 0.0842606\ttotal: 130ms\tremaining: 283ms\n","63:\tlearn: 0.0816560\ttotal: 132ms\tremaining: 281ms\n","64:\tlearn: 0.0788282\ttotal: 134ms\tremaining: 279ms\n","65:\tlearn: 0.0762939\ttotal: 136ms\tremaining: 276ms\n","66:\tlearn: 0.0740397\ttotal: 138ms\tremaining: 273ms\n","67:\tlearn: 0.0718291\ttotal: 141ms\tremaining: 274ms\n","68:\tlearn: 0.0697449\ttotal: 143ms\tremaining: 271ms\n","69:\tlearn: 0.0676674\ttotal: 145ms\tremaining: 270ms\n","70:\tlearn: 0.0653490\ttotal: 147ms\tremaining: 268ms\n","71:\tlearn: 0.0636601\ttotal: 149ms\tremaining: 266ms\n","72:\tlearn: 0.0614132\ttotal: 152ms\tremaining: 264ms\n","73:\tlearn: 0.0597030\ttotal: 153ms\tremaining: 261ms\n","74:\tlearn: 0.0582792\ttotal: 155ms\tremaining: 258ms\n","75:\tlearn: 0.0562115\ttotal: 157ms\tremaining: 256ms\n","76:\tlearn: 0.0541220\ttotal: 160ms\tremaining: 256ms\n","77:\tlearn: 0.0526712\ttotal: 163ms\tremaining: 255ms\n","78:\tlearn: 0.0511434\ttotal: 165ms\tremaining: 253ms\n","79:\tlearn: 0.0497955\ttotal: 168ms\tremaining: 252ms\n","80:\tlearn: 0.0482532\ttotal: 171ms\tremaining: 251ms\n","81:\tlearn: 0.0466378\ttotal: 173ms\tremaining: 249ms\n","82:\tlearn: 0.0452035\ttotal: 175ms\tremaining: 247ms\n","83:\tlearn: 0.0441101\ttotal: 178ms\tremaining: 246ms\n","84:\tlearn: 0.0427526\ttotal: 180ms\tremaining: 244ms\n","85:\tlearn: 0.0419242\ttotal: 181ms\tremaining: 240ms\n","86:\tlearn: 0.0410929\ttotal: 183ms\tremaining: 238ms\n","87:\tlearn: 0.0397223\ttotal: 186ms\tremaining: 236ms\n","88:\tlearn: 0.0386415\ttotal: 188ms\tremaining: 234ms\n","89:\tlearn: 0.0374915\ttotal: 190ms\tremaining: 232ms\n","90:\tlearn: 0.0358634\ttotal: 192ms\tremaining: 230ms\n","91:\tlearn: 0.0349152\ttotal: 194ms\tremaining: 228ms\n","92:\tlearn: 0.0338991\ttotal: 196ms\tremaining: 226ms\n","93:\tlearn: 0.0328616\ttotal: 198ms\tremaining: 224ms\n","94:\tlearn: 0.0322452\ttotal: 200ms\tremaining: 221ms\n","95:\tlearn: 0.0315611\ttotal: 202ms\tremaining: 219ms\n","96:\tlearn: 0.0311975\ttotal: 203ms\tremaining: 215ms\n","97:\tlearn: 0.0307210\ttotal: 204ms\tremaining: 213ms\n","98:\tlearn: 0.0298477\ttotal: 209ms\tremaining: 214ms\n","99:\tlearn: 0.0291300\ttotal: 212ms\tremaining: 212ms\n","100:\tlearn: 0.0282332\ttotal: 214ms\tremaining: 210ms\n","101:\tlearn: 0.0275709\ttotal: 217ms\tremaining: 208ms\n","102:\tlearn: 0.0267862\ttotal: 219ms\tremaining: 207ms\n","103:\tlearn: 0.0260617\ttotal: 221ms\tremaining: 204ms\n","104:\tlearn: 0.0253979\ttotal: 224ms\tremaining: 202ms\n","105:\tlearn: 0.0249518\ttotal: 226ms\tremaining: 201ms\n","106:\tlearn: 0.0242314\ttotal: 228ms\tremaining: 198ms\n","107:\tlearn: 0.0237618\ttotal: 232ms\tremaining: 198ms\n","108:\tlearn: 0.0230263\ttotal: 240ms\tremaining: 200ms\n","109:\tlearn: 0.0223255\ttotal: 244ms\tremaining: 199ms\n","110:\tlearn: 0.0214878\ttotal: 254ms\tremaining: 204ms\n","111:\tlearn: 0.0207610\ttotal: 259ms\tremaining: 204ms\n","112:\tlearn: 0.0201613\ttotal: 262ms\tremaining: 202ms\n","113:\tlearn: 0.0196400\ttotal: 264ms\tremaining: 199ms\n","114:\tlearn: 0.0191648\ttotal: 266ms\tremaining: 196ms\n","115:\tlearn: 0.0184925\ttotal: 268ms\tremaining: 194ms\n","116:\tlearn: 0.0179343\ttotal: 270ms\tremaining: 192ms\n","117:\tlearn: 0.0173883\ttotal: 272ms\tremaining: 189ms\n","118:\tlearn: 0.0168813\ttotal: 275ms\tremaining: 187ms\n","119:\tlearn: 0.0163873\ttotal: 277ms\tremaining: 184ms\n","120:\tlearn: 0.0160620\ttotal: 278ms\tremaining: 182ms\n","121:\tlearn: 0.0155687\ttotal: 281ms\tremaining: 179ms\n","122:\tlearn: 0.0151287\ttotal: 283ms\tremaining: 177ms\n","123:\tlearn: 0.0146118\ttotal: 285ms\tremaining: 175ms\n","124:\tlearn: 0.0140687\ttotal: 287ms\tremaining: 172ms\n","125:\tlearn: 0.0136720\ttotal: 290ms\tremaining: 170ms\n","126:\tlearn: 0.0133207\ttotal: 292ms\tremaining: 168ms\n","127:\tlearn: 0.0129912\ttotal: 294ms\tremaining: 165ms\n","128:\tlearn: 0.0125568\ttotal: 296ms\tremaining: 163ms\n","129:\tlearn: 0.0121524\ttotal: 299ms\tremaining: 161ms\n","130:\tlearn: 0.0117285\ttotal: 301ms\tremaining: 158ms\n","131:\tlearn: 0.0116315\ttotal: 301ms\tremaining: 155ms\n","132:\tlearn: 0.0113512\ttotal: 303ms\tremaining: 153ms\n","133:\tlearn: 0.0110449\ttotal: 305ms\tremaining: 150ms\n","134:\tlearn: 0.0107524\ttotal: 307ms\tremaining: 148ms\n","135:\tlearn: 0.0105540\ttotal: 310ms\tremaining: 146ms\n","136:\tlearn: 0.0102503\ttotal: 312ms\tremaining: 143ms\n","137:\tlearn: 0.0100260\ttotal: 314ms\tremaining: 141ms\n","138:\tlearn: 0.0097491\ttotal: 317ms\tremaining: 139ms\n","139:\tlearn: 0.0094980\ttotal: 319ms\tremaining: 137ms\n","140:\tlearn: 0.0093094\ttotal: 322ms\tremaining: 135ms\n","141:\tlearn: 0.0090880\ttotal: 325ms\tremaining: 133ms\n","142:\tlearn: 0.0089173\ttotal: 327ms\tremaining: 130ms\n","143:\tlearn: 0.0086720\ttotal: 330ms\tremaining: 128ms\n","144:\tlearn: 0.0084960\ttotal: 332ms\tremaining: 126ms\n","145:\tlearn: 0.0083128\ttotal: 334ms\tremaining: 124ms\n","146:\tlearn: 0.0080064\ttotal: 336ms\tremaining: 121ms\n","147:\tlearn: 0.0078575\ttotal: 339ms\tremaining: 119ms\n","148:\tlearn: 0.0076984\ttotal: 341ms\tremaining: 117ms\n","149:\tlearn: 0.0074002\ttotal: 344ms\tremaining: 115ms\n","150:\tlearn: 0.0072372\ttotal: 347ms\tremaining: 112ms\n","151:\tlearn: 0.0070572\ttotal: 349ms\tremaining: 110ms\n","152:\tlearn: 0.0068745\ttotal: 352ms\tremaining: 108ms\n","153:\tlearn: 0.0067312\ttotal: 354ms\tremaining: 106ms\n","154:\tlearn: 0.0066182\ttotal: 356ms\tremaining: 103ms\n","155:\tlearn: 0.0064577\ttotal: 358ms\tremaining: 101ms\n","156:\tlearn: 0.0062761\ttotal: 359ms\tremaining: 98.4ms\n","157:\tlearn: 0.0061442\ttotal: 362ms\tremaining: 96.2ms\n","158:\tlearn: 0.0060399\ttotal: 364ms\tremaining: 93.9ms\n","159:\tlearn: 0.0059067\ttotal: 366ms\tremaining: 91.5ms\n","160:\tlearn: 0.0058557\ttotal: 367ms\tremaining: 88.8ms\n","161:\tlearn: 0.0057379\ttotal: 369ms\tremaining: 86.5ms\n","162:\tlearn: 0.0055531\ttotal: 370ms\tremaining: 84.1ms\n","163:\tlearn: 0.0055165\ttotal: 371ms\tremaining: 81.4ms\n","164:\tlearn: 0.0053480\ttotal: 373ms\tremaining: 79.1ms\n","165:\tlearn: 0.0052145\ttotal: 375ms\tremaining: 76.8ms\n","166:\tlearn: 0.0051836\ttotal: 375ms\tremaining: 74.1ms\n","167:\tlearn: 0.0050494\ttotal: 377ms\tremaining: 71.8ms\n","168:\tlearn: 0.0049346\ttotal: 379ms\tremaining: 69.5ms\n","169:\tlearn: 0.0047679\ttotal: 381ms\tremaining: 67.3ms\n","170:\tlearn: 0.0046938\ttotal: 383ms\tremaining: 65ms\n","171:\tlearn: 0.0045225\ttotal: 386ms\tremaining: 62.8ms\n","172:\tlearn: 0.0044401\ttotal: 387ms\tremaining: 60.4ms\n","173:\tlearn: 0.0043786\ttotal: 389ms\tremaining: 58.1ms\n","174:\tlearn: 0.0043085\ttotal: 391ms\tremaining: 55.9ms\n","175:\tlearn: 0.0042458\ttotal: 393ms\tremaining: 53.7ms\n","176:\tlearn: 0.0042122\ttotal: 394ms\tremaining: 51.2ms\n","177:\tlearn: 0.0041221\ttotal: 397ms\tremaining: 49.1ms\n","178:\tlearn: 0.0040149\ttotal: 402ms\tremaining: 47.1ms\n","179:\tlearn: 0.0039371\ttotal: 403ms\tremaining: 44.7ms\n","180:\tlearn: 0.0038562\ttotal: 408ms\tremaining: 42.9ms\n","181:\tlearn: 0.0037214\ttotal: 411ms\tremaining: 40.6ms\n","182:\tlearn: 0.0036279\ttotal: 412ms\tremaining: 38.3ms\n","183:\tlearn: 0.0035369\ttotal: 414ms\tremaining: 36ms\n","184:\tlearn: 0.0034559\ttotal: 416ms\tremaining: 33.7ms\n","185:\tlearn: 0.0033471\ttotal: 418ms\tremaining: 31.5ms\n","186:\tlearn: 0.0032352\ttotal: 420ms\tremaining: 29.2ms\n","187:\tlearn: 0.0031304\ttotal: 422ms\tremaining: 27ms\n","188:\tlearn: 0.0030399\ttotal: 425ms\tremaining: 24.7ms\n","189:\tlearn: 0.0029998\ttotal: 426ms\tremaining: 22.4ms\n","190:\tlearn: 0.0029335\ttotal: 428ms\tremaining: 20.1ms\n","191:\tlearn: 0.0028664\ttotal: 429ms\tremaining: 17.9ms\n","192:\tlearn: 0.0027988\ttotal: 431ms\tremaining: 15.6ms\n","193:\tlearn: 0.0027246\ttotal: 432ms\tremaining: 13.4ms\n","194:\tlearn: 0.0026285\ttotal: 435ms\tremaining: 11.1ms\n","195:\tlearn: 0.0025663\ttotal: 437ms\tremaining: 8.92ms\n","196:\tlearn: 0.0025111\ttotal: 439ms\tremaining: 6.69ms\n","197:\tlearn: 0.0024565\ttotal: 442ms\tremaining: 4.46ms\n","198:\tlearn: 0.0023952\ttotal: 444ms\tremaining: 2.23ms\n","199:\tlearn: 0.0023285\ttotal: 446ms\tremaining: 0us\n","Training on CPU\n","Estimator 0/300, Train metric: 1.2225\n","Estimator 1/300, Train metric: 1.0857\n","Estimator 2/300, Train metric: 0.9782\n","Estimator 3/300, Train metric: 0.8797\n","Estimator 4/300, Train metric: 0.7961\n","Estimator 5/300, Train metric: 0.7315\n","Estimator 6/300, Train metric: 0.6861\n","Estimator 7/300, Train metric: 0.6459\n","Estimator 8/300, Train metric: 0.6103\n","Estimator 9/300, Train metric: 0.5789\n","Estimator 10/300, Train metric: 0.5643\n","Estimator 11/300, Train metric: 0.5441\n","Estimator 12/300, Train metric: 0.5290\n","Estimator 13/300, Train metric: 0.5169\n","Estimator 14/300, Train metric: 0.5102\n","Estimator 15/300, Train metric: 0.5049\n","Estimator 16/300, Train metric: 0.5003\n","Estimator 17/300, Train metric: 0.4967\n","Estimator 18/300, Train metric: 0.4967\n","Estimator 19/300, Train metric: 0.4932\n","Estimator 20/300, Train metric: 0.4932\n","Estimator 21/300, Train metric: 0.4932\n","Estimator 22/300, Train metric: 0.4932\n","Estimator 23/300, Train metric: 0.4932\n","Estimator 24/300, Train metric: 0.4932\n","Estimator 25/300, Train metric: 0.4932\n","Estimator 26/300, Train metric: 0.4932\n","Estimator 27/300, Train metric: 0.4932\n","Estimator 28/300, Train metric: 0.4932\n","Estimator 29/300, Train metric: 0.4932\n","Estimator 30/300, Train metric: 0.4932\n","Estimator 31/300, Train metric: 0.4932\n","Estimator 32/300, Train metric: 0.4932\n","Estimator 33/300, Train metric: 0.4932\n","Estimator 34/300, Train metric: 0.4932\n","Estimator 35/300, Train metric: 0.4932\n","Estimator 36/300, Train metric: 0.4932\n","Estimator 37/300, Train metric: 0.4932\n","Estimator 38/300, Train metric: 0.4932\n","Estimator 39/300, Train metric: 0.4932\n","Estimator 40/300, Train metric: 0.4932\n","Estimator 41/300, Train metric: 0.4932\n","Estimator 42/300, Train metric: 0.4932\n","Estimator 43/300, Train metric: 0.4932\n","Estimator 44/300, Train metric: 0.4932\n","Estimator 45/300, Train metric: 0.4932\n","Estimator 46/300, Train metric: 0.4932\n","Estimator 47/300, Train metric: 0.4932\n","Estimator 48/300, Train metric: 0.4932\n","Estimator 49/300, Train metric: 0.4932\n","Estimator 50/300, Train metric: 0.4932\n","Estimator 51/300, Train metric: 0.4932\n","Estimator 52/300, Train metric: 0.4932\n","Estimator 53/300, Train metric: 0.4932\n","Estimator 54/300, Train metric: 0.4932\n","Estimator 55/300, Train metric: 0.4932\n","Estimator 56/300, Train metric: 0.4932\n","Estimator 57/300, Train metric: 0.4932\n","Estimator 58/300, Train metric: 0.4932\n","Estimator 59/300, Train metric: 0.4932\n","Estimator 60/300, Train metric: 0.4932\n","Estimator 61/300, Train metric: 0.4932\n","Estimator 62/300, Train metric: 0.4932\n","Estimator 63/300, Train metric: 0.4932\n","Estimator 64/300, Train metric: 0.4932\n","Estimator 65/300, Train metric: 0.4932\n","Estimator 66/300, Train metric: 0.4932\n","Estimator 67/300, Train metric: 0.4932\n","Estimator 68/300, Train metric: 0.4932\n","Estimator 69/300, Train metric: 0.4932\n","Estimator 70/300, Train metric: 0.4932\n","Estimator 71/300, Train metric: 0.4932\n","Estimator 72/300, Train metric: 0.4932\n","Estimator 73/300, Train metric: 0.4932\n","Estimator 74/300, Train metric: 0.4932\n","Estimator 75/300, Train metric: 0.4932\n","Estimator 76/300, Train metric: 0.4932\n","Estimator 77/300, Train metric: 0.4932\n","Estimator 78/300, Train metric: 0.4932\n","Estimator 79/300, Train metric: 0.4932\n","Estimator 80/300, Train metric: 0.4932\n","Estimator 81/300, Train metric: 0.4932\n","Estimator 82/300, Train metric: 0.4932\n","Estimator 83/300, Train metric: 0.4932\n","Estimator 84/300, Train metric: 0.4932\n","Estimator 85/300, Train metric: 0.4932\n","Estimator 86/300, Train metric: 0.4932\n","Estimator 87/300, Train metric: 0.4932\n","Estimator 88/300, Train metric: 0.4932\n","Estimator 89/300, Train metric: 0.4932\n","Estimator 90/300, Train metric: 0.4932\n","Estimator 91/300, Train metric: 0.4932\n","Estimator 92/300, Train metric: 0.4932\n","Estimator 93/300, Train metric: 0.4932\n","Estimator 94/300, Train metric: 0.4932\n","Estimator 95/300, Train metric: 0.4932\n","Estimator 96/300, Train metric: 0.4932\n","Estimator 97/300, Train metric: 0.4932\n","Estimator 98/300, Train metric: 0.4932\n","Estimator 99/300, Train metric: 0.4932\n","Estimator 100/300, Train metric: 0.4932\n","Estimator 101/300, Train metric: 0.4932\n","Estimator 102/300, Train metric: 0.4932\n","Estimator 103/300, Train metric: 0.4932\n","Estimator 104/300, Train metric: 0.4932\n","Estimator 105/300, Train metric: 0.4932\n","Estimator 106/300, Train metric: 0.4932\n","Estimator 107/300, Train metric: 0.4932\n","Estimator 108/300, Train metric: 0.4932\n","Estimator 109/300, Train metric: 0.4932\n","Estimator 110/300, Train metric: 0.4932\n","Estimator 111/300, Train metric: 0.4932\n","Estimator 112/300, Train metric: 0.4932\n","Estimator 113/300, Train metric: 0.4932\n","Estimator 114/300, Train metric: 0.4932\n","Estimator 115/300, Train metric: 0.4932\n","Estimator 116/300, Train metric: 0.4932\n","Estimator 117/300, Train metric: 0.4932\n","Estimator 118/300, Train metric: 0.4932\n","Estimator 119/300, Train metric: 0.4932\n","Estimator 120/300, Train metric: 0.4932\n","Estimator 121/300, Train metric: 0.4932\n","Estimator 122/300, Train metric: 0.4932\n","Estimator 123/300, Train metric: 0.4932\n","Estimator 124/300, Train metric: 0.4932\n","Estimator 125/300, Train metric: 0.4932\n","Estimator 126/300, Train metric: 0.4932\n","Estimator 127/300, Train metric: 0.4932\n","Estimator 128/300, Train metric: 0.4932\n","Estimator 129/300, Train metric: 0.4932\n","Estimator 130/300, Train metric: 0.4932\n","Estimator 131/300, Train metric: 0.4932\n","Estimator 132/300, Train metric: 0.4932\n","Estimator 133/300, Train metric: 0.4932\n","Estimator 134/300, Train metric: 0.4932\n","Estimator 135/300, Train metric: 0.4932\n","Estimator 136/300, Train metric: 0.4932\n","Estimator 137/300, Train metric: 0.4932\n","Estimator 138/300, Train metric: 0.4932\n","Estimator 139/300, Train metric: 0.4932\n","Estimator 140/300, Train metric: 0.4932\n","Estimator 141/300, Train metric: 0.4932\n","Estimator 142/300, Train metric: 0.4932\n","Estimator 143/300, Train metric: 0.4932\n","Estimator 144/300, Train metric: 0.4932\n","Estimator 145/300, Train metric: 0.4932\n","Estimator 146/300, Train metric: 0.4932\n","Estimator 147/300, Train metric: 0.4932\n","Estimator 148/300, Train metric: 0.4932\n","Estimator 149/300, Train metric: 0.4932\n","Estimator 150/300, Train metric: 0.4932\n","Estimator 151/300, Train metric: 0.4932\n","Estimator 152/300, Train metric: 0.4932\n","Estimator 153/300, Train metric: 0.4932\n","Estimator 154/300, Train metric: 0.4932\n","Estimator 155/300, Train metric: 0.4932\n","Estimator 156/300, Train metric: 0.4932\n","Estimator 157/300, Train metric: 0.4932\n","Estimator 158/300, Train metric: 0.4932\n","Estimator 159/300, Train metric: 0.4932\n","Estimator 160/300, Train metric: 0.4932\n","Estimator 161/300, Train metric: 0.4932\n","Estimator 162/300, Train metric: 0.4932\n","Estimator 163/300, Train metric: 0.4932\n","Estimator 164/300, Train metric: 0.4932\n","Estimator 165/300, Train metric: 0.4932\n","Estimator 166/300, Train metric: 0.4932\n","Estimator 167/300, Train metric: 0.4932\n","Estimator 168/300, Train metric: 0.4932\n","Estimator 169/300, Train metric: 0.4932\n","Estimator 170/300, Train metric: 0.4932\n","Estimator 171/300, Train metric: 0.4932\n","Estimator 172/300, Train metric: 0.4932\n","Estimator 173/300, Train metric: 0.4932\n","Estimator 174/300, Train metric: 0.4932\n","Estimator 175/300, Train metric: 0.4932\n","Estimator 176/300, Train metric: 0.4932\n","Estimator 177/300, Train metric: 0.4932\n","Estimator 178/300, Train metric: 0.4932\n","Estimator 179/300, Train metric: 0.4932\n","Estimator 180/300, Train metric: 0.4932\n","Estimator 181/300, Train metric: 0.4932\n","Estimator 182/300, Train metric: 0.4932\n","Estimator 183/300, Train metric: 0.4932\n","Estimator 184/300, Train metric: 0.4932\n","Estimator 185/300, Train metric: 0.4932\n","Estimator 186/300, Train metric: 0.4932\n","Estimator 187/300, Train metric: 0.4932\n","Estimator 188/300, Train metric: 0.4932\n","Estimator 189/300, Train metric: 0.4932\n","Estimator 190/300, Train metric: 0.4932\n","Estimator 191/300, Train metric: 0.4932\n","Estimator 192/300, Train metric: 0.4932\n","Estimator 193/300, Train metric: 0.4932\n","Estimator 194/300, Train metric: 0.4932\n","Estimator 195/300, Train metric: 0.4932\n","Estimator 196/300, Train metric: 0.4932\n","Estimator 197/300, Train metric: 0.4932\n","Estimator 198/300, Train metric: 0.4932\n","Estimator 199/300, Train metric: 0.4932\n","Estimator 200/300, Train metric: 0.4932\n","Estimator 201/300, Train metric: 0.4932\n","Estimator 202/300, Train metric: 0.4932\n","Estimator 203/300, Train metric: 0.4932\n","Estimator 204/300, Train metric: 0.4932\n","Estimator 205/300, Train metric: 0.4932\n","Estimator 206/300, Train metric: 0.4932\n","Estimator 207/300, Train metric: 0.4932\n","Estimator 208/300, Train metric: 0.4932\n","Estimator 209/300, Train metric: 0.4932\n","Estimator 210/300, Train metric: 0.4932\n","Estimator 211/300, Train metric: 0.4932\n","Estimator 212/300, Train metric: 0.4932\n","Estimator 213/300, Train metric: 0.4932\n","Estimator 214/300, Train metric: 0.4932\n","Estimator 215/300, Train metric: 0.4932\n","Estimator 216/300, Train metric: 0.4932\n","Estimator 217/300, Train metric: 0.4932\n","Estimator 218/300, Train metric: 0.4932\n","Estimator 219/300, Train metric: 0.4932\n","Estimator 220/300, Train metric: 0.4932\n","Estimator 221/300, Train metric: 0.4932\n","Estimator 222/300, Train metric: 0.4932\n","Estimator 223/300, Train metric: 0.4932\n","Estimator 224/300, Train metric: 0.4932\n","Estimator 225/300, Train metric: 0.4932\n","Estimator 226/300, Train metric: 0.4932\n","Estimator 227/300, Train metric: 0.4932\n","Estimator 228/300, Train metric: 0.4932\n","Estimator 229/300, Train metric: 0.4932\n","Estimator 230/300, Train metric: 0.4932\n","Estimator 231/300, Train metric: 0.4932\n","Estimator 232/300, Train metric: 0.4932\n","Estimator 233/300, Train metric: 0.4932\n","Estimator 234/300, Train metric: 0.4932\n","Estimator 235/300, Train metric: 0.4932\n","Estimator 236/300, Train metric: 0.4932\n","Estimator 237/300, Train metric: 0.4932\n","Estimator 238/300, Train metric: 0.4932\n","Estimator 239/300, Train metric: 0.4932\n","Estimator 240/300, Train metric: 0.4932\n","Estimator 241/300, Train metric: 0.4932\n","Estimator 242/300, Train metric: 0.4932\n","Estimator 243/300, Train metric: 0.4932\n","Estimator 244/300, Train metric: 0.4932\n","Estimator 245/300, Train metric: 0.4932\n","Estimator 246/300, Train metric: 0.4932\n","Estimator 247/300, Train metric: 0.4932\n","Estimator 248/300, Train metric: 0.4932\n","Estimator 249/300, Train metric: 0.4932\n","Estimator 250/300, Train metric: 0.4932\n","Estimator 251/300, Train metric: 0.4932\n","Estimator 252/300, Train metric: 0.4932\n","Estimator 253/300, Train metric: 0.4932\n","Estimator 254/300, Train metric: 0.4932\n","Estimator 255/300, Train metric: 0.4932\n","Estimator 256/300, Train metric: 0.4932\n","Estimator 257/300, Train metric: 0.4932\n","Estimator 258/300, Train metric: 0.4932\n","Estimator 259/300, Train metric: 0.4932\n","Estimator 260/300, Train metric: 0.4932\n","Estimator 261/300, Train metric: 0.4932\n","Estimator 262/300, Train metric: 0.4932\n","Estimator 263/300, Train metric: 0.4932\n","Estimator 264/300, Train metric: 0.4932\n","Estimator 265/300, Train metric: 0.4932\n","Estimator 266/300, Train metric: 0.4932\n","Estimator 267/300, Train metric: 0.4932\n","Estimator 268/300, Train metric: 0.4932\n","Estimator 269/300, Train metric: 0.4932\n","Estimator 270/300, Train metric: 0.4932\n","Estimator 271/300, Train metric: 0.4932\n","Estimator 272/300, Train metric: 0.4932\n","Estimator 273/300, Train metric: 0.4932\n","Estimator 274/300, Train metric: 0.4932\n","Estimator 275/300, Train metric: 0.4932\n","Estimator 276/300, Train metric: 0.4932\n","Estimator 277/300, Train metric: 0.4932\n","Estimator 278/300, Train metric: 0.4932\n","Estimator 279/300, Train metric: 0.4932\n","Estimator 280/300, Train metric: 0.4932\n","Estimator 281/300, Train metric: 0.4932\n","Estimator 282/300, Train metric: 0.4932\n","Estimator 283/300, Train metric: 0.4932\n","Estimator 284/300, Train metric: 0.4932\n","Estimator 285/300, Train metric: 0.4932\n","Estimator 286/300, Train metric: 0.4932\n","Estimator 287/300, Train metric: 0.4932\n","Estimator 288/300, Train metric: 0.4932\n","Estimator 289/300, Train metric: 0.4932\n","Estimator 290/300, Train metric: 0.4932\n","Estimator 291/300, Train metric: 0.4932\n","Estimator 292/300, Train metric: 0.4932\n","Estimator 293/300, Train metric: 0.4932\n","Estimator 294/300, Train metric: 0.4932\n","Estimator 295/300, Train metric: 0.4932\n","Estimator 296/300, Train metric: 0.4932\n","Estimator 297/300, Train metric: 0.4932\n","Estimator 298/300, Train metric: 0.4932\n","Estimator 299/300, Train metric: 0.4932\n"]}],"source":["def get_best_models_and_predict(best_scores_autosampler, X_train, y_train, X_test, y_test, file_path):\n","    # Convert input data to NumPy arrays\n","    X_train = np.array(X_train)\n","    y_train = np.array(y_train)\n","    X_test = np.array(X_test)\n","    y_test = np.array(y_test)\n","\n","    # Mapping for model creation based on dictionary keys\n","    model_mapping = {\n","        'Random Forest': RandomForestRegressor,\n","        'Gradient Boosting': GradientBoostingRegressor,\n","        'XGBoost': XGBRegressor,\n","        'LightGBM': LGBMRegressor,\n","        'CatBoost': CatBoostRegressor,\n","        'GPBoost': GPBoostRegressor,\n","        'NGBoost': NGBRegressor,\n","        'HistGradientBoosting': HistGradientBoostingRegressor,\n","        'PGBM': PGBM  # PGBM is handled separately\n","    }\n","\n","    # Dictionary to store the best model for each type\n","    best_models = {}\n","\n","    # Iterate over the dictionary to find the best pruner for each model type\n","    for (model_name, pruner), params in best_scores_autosampler.items():\n","        current_score = params.get('test_mse', np.inf)\n","        if model_name not in best_models or current_score < best_models[model_name]['score']:\n","            best_models[model_name] = {\n","                'score': current_score,\n","                'params': params['best_params'],\n","                'pruner': pruner\n","            }\n","\n","    # Prepare a DataFrame to store predictions\n","    df = pd.read_csv(file_path)\n","\n","    # Iterate over the best models to train and predict\n","    for model_name, model_info in best_models.items():\n","        best_params = model_info['params']\n","        model_class = model_mapping.get(model_name)\n","\n","        if model_class is None:\n","            print(f\"Model {model_name} is not supported or not available.\")\n","            continue\n","\n","        # Handle specific parameters or settings for model if needed\n","        if model_name == 'CatBoost':\n","            best_params.pop('verbose', None)  # Remove 'verbose' for CatBoost\n","\n","        # Create an instance of the best model with the best parameters\n","        if model_name == 'PGBM':\n","            model = model_class()\n","            model.train((X_train, y_train), objective=mseloss_objective, metric=rmseloss_metric, params=best_params)\n","            predictions = model.predict(X_test)\n","        else:\n","            model = model_class(**best_params)\n","            model.fit(X_train, y_train)\n","            predictions = model.predict(X_test)\n","\n","        # Add predictions to the DataFrame\n","        df[f'{model_name} Predictions'] = predictions\n","\n","        # Plot actual vs. predicted\n","        plt.figure(figsize=(10, 6))\n","        plt.scatter(y_test, predictions, alpha=0.6)\n","        plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', color='red', lw=2)\n","        plt.xlabel(\"Actual\")\n","        plt.ylabel(\"Predicted\")\n","        plt.title(f\"Actual vs. Predicted Values ({model_name})\")\n","        plt.grid(True)\n","        plt.tight_layout()\n","\n","        # Save the plot temporarily\n","        plot_path = f'temp_plot_{model_name}.png'\n","        plt.savefig(plot_path)\n","        plt.close()\n","\n","    # Save predictions and plots to Excel\n","    with pd.ExcelWriter(file_path.replace('.csv', '_results.xlsx'), engine='xlsxwriter') as writer:\n","        # Write data to Excel\n","        df.to_excel(writer, sheet_name='Data', index=False)\n","\n","        # Get the xlsxwriter objects\n","        workbook = writer.book\n","\n","        # Insert each plot into a separate worksheet\n","        for model_name in best_models.keys():\n","            # Shorten the worksheet name to fit within Excel's 31 character limit\n","            short_model_name = ''.join([word[0] for word in model_name.split()])  # e.g., 'RF' for 'Random Forest'\n","            sheet_name = f'{short_model_name}_Plot'\n","\n","            worksheet = workbook.add_worksheet(sheet_name)\n","            writer.sheets[sheet_name] = worksheet\n","            plot_path = f'temp_plot_{model_name}.png'\n","            worksheet.insert_image('A1', plot_path)\n","\n","    # Clean up temporary plot files\n","    for model_name in best_models.keys():\n","        os.remove(f'temp_plot_{model_name}.png')\n","\n","    return df, best_models\n","\n","# Call the function\n","df, best_models = get_best_models_and_predict(best_scores_autosampler, X_train, y_train, X_test, y_test, \"./drive/MyDrive/pile_capacity_LOK/full/test.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WiVmP0QP3pKn"},"outputs":[],"source":["plot_best_scores(best_scores_autosampler,\"./drive/MyDrive/pile_capacity_LOK/full/full_ml/HyperParameter_Tuning/test_results.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ynnJWQRA3pKn","colab":{"base_uri":"https://localhost:8080/","height":276,"referenced_widgets":["f43701d8e483487b8da732ecb374cd3c","cb590335db334f939d5ee00d77856ead","84cbb017954a4d96a124b2f4185e75dd","14152f69b0fe431291d2e9821a71b603","747e7a6b4d294ef09ad5199e58560f78","6ec6f0ae646a4ce5a1aca43948498b60","461d7995be364d92ae3028bec6ae9bcf","06b6533708674712b7aa754d7b09a341","e100c2d819f2401b9de8f3ccdbc73723","d73489f9acb44130b76ddeea28843de9","f52ddd9c20c34b809bd588cd0e3f2e0d","dd38eaf19b9243dcade9f5664cf5ac5b","bdb31e0eede1429aa124209c50f3f67f","cff019d13c0f4f66a0b9ab1e52bad183","b18d92919a3d4fe4972bfa25cc8e24a9","fcec9371ea834d468ff59c37a885d201","e6cd4b19e9ec466196a5522f581fa7f2","1c88b99cf17840b49e99676ca29e338d","7fcd29d810384d63ae0edaea9372ea7a","424e281ea34a42fbaad8f09e5d06f02a","72476ca9e99544938a0a37e286a7a9cd","bc5e7501b5b34df0ab3d6d99c190dd6c","ed359d4d20dc4c42ae2a35cf6c3d0dd7","72d13ef3ea30475898ffd69569df4f90","4491b49446b64d38a60c46f7613b2898","d4c09db525ba4ecab36af44849bde397","a1e372700a6a414ca676dee1b8405b8b","085f17492a874793b301f54d6d42c703","3c86a3f3c03747938ed354141acfce3b","eb8f9aacb8b449b19055fc3b2dff5dca","7a81a66af01443d9a757c4f4f094eab0","d2cc29109e1d43ef90582758c7c714f1","d36500c1545c470d99f13f065207914b","26733808bd124e71a504f9376f7fe756","55224ef847194a028d60e63c8a078a8c","7a64052329a44db0a25bf807e7c5ef95","642660cbedd949508b61df46ecf4aeab","0b2d339352274039bd307029d840e8f9","089d10026e4e48679abe8b8572a9aaec","a76e1b4d992c4c738487c4925cb96a53","4e3a69e09ef74cbca36929c486e6af47","a4e6aa11bc4944c980458520351fc675","5c911d7195854789af6f12ae43f42b69","490e958911634a9c92d391439b854291","0ccb7cc2011843f3be80f321e2711058","3f1feb41abcb4eefb98ba368ded363e7","86db18768938428288067c7158c93660","830db485717248b48db2014cb5a56774","5988c1f11ee845d8a7cbe718e0b12fa0","8010f710e71d429c83e40067143d9f25","4f88aefb325c4fedacc1a1790ae4215d","bacfe36388954704be531ed57ebaf6cf","b9fd155d895a4c6c931eaad1699d797b","741ec0cfb0014770b9912356899496b0","c756fec0f2da4392989e6788d2fb1548","155c4881ccf6446eb3f0a12be15c0296","689fa4088dff465ab0d0082d90a3f9fd","1da0d3d4c4c54bd69fece9e966f71709","8865b068a6dd4099ae1744d2ba20fcca","31c5271f77de41b9851d9c95e2261d15","57e26f8fbf764c208734c0793cb22317","0cc44b1da26646d7bec9c216c42ec86a","904a8c54d67148f3897ef36eee4bcf50","b8f9ba2f56a34139991b403e073d8e0e","c44fff369392413eafac970c8e118774","74c8e5b080c5421fb50f9498f1443335","136d5c0e90fd4c03b8e12eeb7d82df48","39045bfbbca8401d960e2c0d400c090c","98541251bc554a39964c27e58be352e2","f9c3275775c94ef0ac8ef7e8148e4a00","88518a554c76457ab8f7e98f2099e219","a7788459ea534c9f9f4165ded409d55e","4d38a70107ea4e08ba520c11d99d9908","6866162d54f94aacb5f685742ae10518","61de7ad600244664a8282467231fdc86","d37e60c879bf4df3b4364254397665bc","4b55693c7e0f4d3289b3116219630c9a"]},"executionInfo":{"status":"ok","timestamp":1750419482082,"user_tz":-330,"elapsed":67613,"user":{"displayName":"Mahesh Pal","userId":"08757421473100740410"}},"outputId":"7b665f2d-a8fc-4f53-8e8e-f963088d6f55"},"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f43701d8e483487b8da732ecb374cd3c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dd38eaf19b9243dcade9f5664cf5ac5b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ed359d4d20dc4c42ae2a35cf6c3d0dd7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26733808bd124e71a504f9376f7fe756"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0ccb7cc2011843f3be80f321e2711058"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"155c4881ccf6446eb3f0a12be15c0296"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/24 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"136d5c0e90fd4c03b8e12eeb7d82df48"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model HistGradientBoosting is not supported or not available.\n","Model PGBM is not supported or not available.\n"]}],"source":["generate_interpretml_explanations_summary_pruners(best_scores_autosampler, X_train, y_train, x_test, feature_names,excel_file_path = \"./drive/MyDrive/pile_capacity_LOK/full/full_ml/HyperParameter_Tuning/test_results.xlsx\")"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.7"},"widgets":{"application/vnd.jupyter.widget-state+json":{"f43701d8e483487b8da732ecb374cd3c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_cb590335db334f939d5ee00d77856ead","IPY_MODEL_84cbb017954a4d96a124b2f4185e75dd","IPY_MODEL_14152f69b0fe431291d2e9821a71b603"],"layout":"IPY_MODEL_747e7a6b4d294ef09ad5199e58560f78"}},"cb590335db334f939d5ee00d77856ead":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6ec6f0ae646a4ce5a1aca43948498b60","placeholder":"​","style":"IPY_MODEL_461d7995be364d92ae3028bec6ae9bcf","value":"100%"}},"84cbb017954a4d96a124b2f4185e75dd":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_06b6533708674712b7aa754d7b09a341","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e100c2d819f2401b9de8f3ccdbc73723","value":24}},"14152f69b0fe431291d2e9821a71b603":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d73489f9acb44130b76ddeea28843de9","placeholder":"​","style":"IPY_MODEL_f52ddd9c20c34b809bd588cd0e3f2e0d","value":" 24/24 [00:03&lt;00:00,  7.93it/s]"}},"747e7a6b4d294ef09ad5199e58560f78":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6ec6f0ae646a4ce5a1aca43948498b60":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"461d7995be364d92ae3028bec6ae9bcf":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"06b6533708674712b7aa754d7b09a341":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e100c2d819f2401b9de8f3ccdbc73723":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d73489f9acb44130b76ddeea28843de9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f52ddd9c20c34b809bd588cd0e3f2e0d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"dd38eaf19b9243dcade9f5664cf5ac5b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bdb31e0eede1429aa124209c50f3f67f","IPY_MODEL_cff019d13c0f4f66a0b9ab1e52bad183","IPY_MODEL_b18d92919a3d4fe4972bfa25cc8e24a9"],"layout":"IPY_MODEL_fcec9371ea834d468ff59c37a885d201"}},"bdb31e0eede1429aa124209c50f3f67f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6cd4b19e9ec466196a5522f581fa7f2","placeholder":"​","style":"IPY_MODEL_1c88b99cf17840b49e99676ca29e338d","value":"100%"}},"cff019d13c0f4f66a0b9ab1e52bad183":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7fcd29d810384d63ae0edaea9372ea7a","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_424e281ea34a42fbaad8f09e5d06f02a","value":24}},"b18d92919a3d4fe4972bfa25cc8e24a9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_72476ca9e99544938a0a37e286a7a9cd","placeholder":"​","style":"IPY_MODEL_bc5e7501b5b34df0ab3d6d99c190dd6c","value":" 24/24 [00:00&lt;00:00, 40.00it/s]"}},"fcec9371ea834d468ff59c37a885d201":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6cd4b19e9ec466196a5522f581fa7f2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c88b99cf17840b49e99676ca29e338d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7fcd29d810384d63ae0edaea9372ea7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"424e281ea34a42fbaad8f09e5d06f02a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"72476ca9e99544938a0a37e286a7a9cd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc5e7501b5b34df0ab3d6d99c190dd6c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ed359d4d20dc4c42ae2a35cf6c3d0dd7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_72d13ef3ea30475898ffd69569df4f90","IPY_MODEL_4491b49446b64d38a60c46f7613b2898","IPY_MODEL_d4c09db525ba4ecab36af44849bde397"],"layout":"IPY_MODEL_a1e372700a6a414ca676dee1b8405b8b"}},"72d13ef3ea30475898ffd69569df4f90":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_085f17492a874793b301f54d6d42c703","placeholder":"​","style":"IPY_MODEL_3c86a3f3c03747938ed354141acfce3b","value":"100%"}},"4491b49446b64d38a60c46f7613b2898":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_eb8f9aacb8b449b19055fc3b2dff5dca","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7a81a66af01443d9a757c4f4f094eab0","value":24}},"d4c09db525ba4ecab36af44849bde397":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2cc29109e1d43ef90582758c7c714f1","placeholder":"​","style":"IPY_MODEL_d36500c1545c470d99f13f065207914b","value":" 24/24 [00:00&lt;00:00, 77.47it/s]"}},"a1e372700a6a414ca676dee1b8405b8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"085f17492a874793b301f54d6d42c703":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3c86a3f3c03747938ed354141acfce3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"eb8f9aacb8b449b19055fc3b2dff5dca":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a81a66af01443d9a757c4f4f094eab0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d2cc29109e1d43ef90582758c7c714f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d36500c1545c470d99f13f065207914b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26733808bd124e71a504f9376f7fe756":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_55224ef847194a028d60e63c8a078a8c","IPY_MODEL_7a64052329a44db0a25bf807e7c5ef95","IPY_MODEL_642660cbedd949508b61df46ecf4aeab"],"layout":"IPY_MODEL_0b2d339352274039bd307029d840e8f9"}},"55224ef847194a028d60e63c8a078a8c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_089d10026e4e48679abe8b8572a9aaec","placeholder":"​","style":"IPY_MODEL_a76e1b4d992c4c738487c4925cb96a53","value":"100%"}},"7a64052329a44db0a25bf807e7c5ef95":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4e3a69e09ef74cbca36929c486e6af47","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a4e6aa11bc4944c980458520351fc675","value":24}},"642660cbedd949508b61df46ecf4aeab":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c911d7195854789af6f12ae43f42b69","placeholder":"​","style":"IPY_MODEL_490e958911634a9c92d391439b854291","value":" 24/24 [00:04&lt;00:00,  5.48it/s]"}},"0b2d339352274039bd307029d840e8f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"089d10026e4e48679abe8b8572a9aaec":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a76e1b4d992c4c738487c4925cb96a53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4e3a69e09ef74cbca36929c486e6af47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4e6aa11bc4944c980458520351fc675":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5c911d7195854789af6f12ae43f42b69":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"490e958911634a9c92d391439b854291":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0ccb7cc2011843f3be80f321e2711058":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3f1feb41abcb4eefb98ba368ded363e7","IPY_MODEL_86db18768938428288067c7158c93660","IPY_MODEL_830db485717248b48db2014cb5a56774"],"layout":"IPY_MODEL_5988c1f11ee845d8a7cbe718e0b12fa0"}},"3f1feb41abcb4eefb98ba368ded363e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8010f710e71d429c83e40067143d9f25","placeholder":"​","style":"IPY_MODEL_4f88aefb325c4fedacc1a1790ae4215d","value":"100%"}},"86db18768938428288067c7158c93660":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_bacfe36388954704be531ed57ebaf6cf","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b9fd155d895a4c6c931eaad1699d797b","value":24}},"830db485717248b48db2014cb5a56774":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_741ec0cfb0014770b9912356899496b0","placeholder":"​","style":"IPY_MODEL_c756fec0f2da4392989e6788d2fb1548","value":" 24/24 [00:01&lt;00:00, 16.44it/s]"}},"5988c1f11ee845d8a7cbe718e0b12fa0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8010f710e71d429c83e40067143d9f25":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4f88aefb325c4fedacc1a1790ae4215d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"bacfe36388954704be531ed57ebaf6cf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b9fd155d895a4c6c931eaad1699d797b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"741ec0cfb0014770b9912356899496b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c756fec0f2da4392989e6788d2fb1548":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"155c4881ccf6446eb3f0a12be15c0296":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_689fa4088dff465ab0d0082d90a3f9fd","IPY_MODEL_1da0d3d4c4c54bd69fece9e966f71709","IPY_MODEL_8865b068a6dd4099ae1744d2ba20fcca"],"layout":"IPY_MODEL_31c5271f77de41b9851d9c95e2261d15"}},"689fa4088dff465ab0d0082d90a3f9fd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_57e26f8fbf764c208734c0793cb22317","placeholder":"​","style":"IPY_MODEL_0cc44b1da26646d7bec9c216c42ec86a","value":"100%"}},"1da0d3d4c4c54bd69fece9e966f71709":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_904a8c54d67148f3897ef36eee4bcf50","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8f9ba2f56a34139991b403e073d8e0e","value":24}},"8865b068a6dd4099ae1744d2ba20fcca":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c44fff369392413eafac970c8e118774","placeholder":"​","style":"IPY_MODEL_74c8e5b080c5421fb50f9498f1443335","value":" 24/24 [00:00&lt;00:00, 30.17it/s]"}},"31c5271f77de41b9851d9c95e2261d15":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57e26f8fbf764c208734c0793cb22317":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0cc44b1da26646d7bec9c216c42ec86a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"904a8c54d67148f3897ef36eee4bcf50":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b8f9ba2f56a34139991b403e073d8e0e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c44fff369392413eafac970c8e118774":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"74c8e5b080c5421fb50f9498f1443335":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"136d5c0e90fd4c03b8e12eeb7d82df48":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_39045bfbbca8401d960e2c0d400c090c","IPY_MODEL_98541251bc554a39964c27e58be352e2","IPY_MODEL_f9c3275775c94ef0ac8ef7e8148e4a00"],"layout":"IPY_MODEL_88518a554c76457ab8f7e98f2099e219"}},"39045bfbbca8401d960e2c0d400c090c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a7788459ea534c9f9f4165ded409d55e","placeholder":"​","style":"IPY_MODEL_4d38a70107ea4e08ba520c11d99d9908","value":"100%"}},"98541251bc554a39964c27e58be352e2":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_6866162d54f94aacb5f685742ae10518","max":24,"min":0,"orientation":"horizontal","style":"IPY_MODEL_61de7ad600244664a8282467231fdc86","value":24}},"f9c3275775c94ef0ac8ef7e8148e4a00":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d37e60c879bf4df3b4364254397665bc","placeholder":"​","style":"IPY_MODEL_4b55693c7e0f4d3289b3116219630c9a","value":" 24/24 [00:14&lt;00:00,  1.73it/s]"}},"88518a554c76457ab8f7e98f2099e219":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7788459ea534c9f9f4165ded409d55e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d38a70107ea4e08ba520c11d99d9908":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6866162d54f94aacb5f685742ae10518":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"61de7ad600244664a8282467231fdc86":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d37e60c879bf4df3b4364254397665bc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b55693c7e0f4d3289b3116219630c9a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}